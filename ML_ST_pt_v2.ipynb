{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782e8f80-78a9-4e0b-9384-896f365185cf",
   "metadata": {},
   "source": [
    "# Stack Traces Project (Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a41de-13d2-4941-9052-73ce7bf06242",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce22b98e-8698-4c40-8ca0-245c1f8adf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Union, Tuple\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "import string\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from itertools import permutations\n",
    "import heapq\n",
    "import csv\n",
    "import pickle\n",
    "import matplotlib.ticker as mtick\n",
    "import collections\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# pd.options.display.max_colwidth = 500\n",
    "# pd.options.display.max_columns = None\n",
    "# pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b157d41-f766-4a5a-9cd5-432ea3a66f90",
   "metadata": {},
   "source": [
    "## Setting up the project environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33fcc34-2081-48b3-8cb7-817b87d3fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .csv configuration\n",
    "encoding = \"utf-8\"\n",
    "delimiter = None\n",
    "working_directory_path = \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db601c52-486a-4b70-815c-b1fcff507c96",
   "metadata": {},
   "source": [
    "## Loading the question dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c9e24a-26aa-454f-a424-5a667d25817f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"question_tag.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_sotorrent = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1401237b-1dd9-49ba-ad91-50929602772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163194, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sotorrent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c616d9ac-5921-465c-aaf3-f2578e4864c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sotorrent['Source'] = 'old'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770c6df-6be3-4ad0-b3ec-28e60b9660c7",
   "metadata": {},
   "source": [
    "Update the DB"
   ]
  },
  {
   "cell_type": "raw",
   "id": "200ded48-ed67-4d87-bf88-17ba1c93f48c",
   "metadata": {},
   "source": [
    "Ref: https://data.stackexchange.com/stackoverflow/query/edit/1769158\n",
    "\n",
    "SELECT \n",
    "      Id, \n",
    "      PostTypeId, \n",
    "      AcceptedAnswerId, \n",
    "      CreationDate, \n",
    "      ViewCount, \n",
    "      AnswerCount, \n",
    "      CommentCount, \n",
    "      Score,\n",
    "      Title,\n",
    "      Body,\n",
    "      Tags\n",
    "FROM Posts \n",
    "WHERE (tags like '%tensorflow%' OR\n",
    "      tags LIKE '%pytorch%' OR\n",
    "      tags LIKE '%scikit-learn%' OR\n",
    "      tags LIKE '%keras%' OR\n",
    "      tags LIKE '%nltk%' OR\n",
    "      tags LIKE '%huggingface%' OR\n",
    "      tags LIKE '%spark-ml%') AND\n",
    "      creationDate > '2021-01-25 00:00:00' AND\n",
    "      PostTypeId=1\n",
    "ORDER BY [creationDate] DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e538f7-e9e5-4dab-ac00-7c179f4892ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"proj1_update_qst.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_remained = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5b336b-1fe2-4bc6-a99c-837f3f672283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49918, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "300bd414-ed1e-4bff-80f8-c3f6894c1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remained['source'] = 'new'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7d82a-d825-49bc-bc32-2ea8b163397c",
   "metadata": {},
   "source": [
    "Concat two data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f69893-e004-497d-a407-0dc3cc3bb0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213112, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_sotorrent, df_remained])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8311d4f5-9748-465f-b6f4-023dde556a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates([\"Id\", \"PostTypeId\", \"AcceptedAnswerId\", \"ViewCount\", \"AnswerCount\", \"CommentCount\", \"Score\", \"Title\", 'Body', 'Tags'], ignore_index=False, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3f69f7-987e-4076-b1e1-0e345ff45fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records (w/o considering specific tag set) : 171114\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of records (w/o considering specific tag set) :\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e408693",
   "metadata": {},
   "source": [
    "## Answering the first research question (RQ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a6e6e-46f4-432b-81c6-a5f646d6dd08",
   "metadata": {},
   "source": [
    "### Filtering the specific tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1d276-5b01-482b-b244-cd89bef86bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_filter(pref_tags: List, tags: str) -> bool:\n",
    "    regex = \"\"\n",
    "    for tag in pref_tags:\n",
    "        regex += '(?=.*\\\\b'+ tag +'([+-]?([0-9]*[.])?[0-9]*)\\\\b)'\n",
    "    regex = r\"^\" + regex + \".*$\"\n",
    "    tags = tags.strip().lower()\n",
    "    match_result = re.match(regex, tags, re.MULTILINE | re.IGNORECASE)\n",
    "    if match_result is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b05dfaf-8a60-4a86-b341-b78d16a32226",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"pytorch\", \"python\"]\n",
    "df['HasPreferableTags'] = df['Tags'].apply(lambda row_tags: tag_filter(tags, row_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b740ac-83e0-45f1-a2be-e8825609ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags = df[df['HasPreferableTags']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2d3ed2-b450-4151-8856-352d7e8a2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags = df_w_pt_tags.drop(['HasPreferableTags'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32db8e0e-ad52-40ee-aab0-229a72267751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13838, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pt_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb0623-d6d8-4261-90f3-c3eace22e119",
   "metadata": {},
   "source": [
    "We found there are some duplocated rows in our DB, so we eleminate those based on some columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8b23cc-bffd-4fc3-a8c6-1fae9798336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags.drop_duplicates([\"Id\", \"PostTypeId\", \"AcceptedAnswerId\", \"ViewCount\", \"AnswerCount\", \"CommentCount\", \"Score\", \"Title\"], ignore_index=False, inplace=True)\n",
    "df_w_pt_tags = df_w_pt_tags.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b79a315e-28a4-4ae4-8fb7-dcfb510a291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13838, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pt_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c96c84-dedb-4f7f-a464-f8c8e8607970",
   "metadata": {
    "tags": []
   },
   "source": [
    "The new dataset that has a specific tag/s is reduced to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15fdfa92-2d73-4f6c-af4d-4a814b7d11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The orginal DB:  171114\n",
      "The new DB (sp):  13838\n",
      "The difference is:  157276\n"
     ]
    }
   ],
   "source": [
    "print(\"The orginal DB: \", df.shape[0])\n",
    "print(\"The new DB (sp): \", df_w_pt_tags.shape[0])\n",
    "print(\"The difference is: \", df.shape[0] - df_w_pt_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2050397c-ca76-4c95-843d-71fbd9940991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Source</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63831906</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-10 14:30:09</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Reading from cuda array in torch c++ without t...</td>\n",
       "      <td>&lt;p&gt;I am trying to read cuda array located in G...</td>\n",
       "      <td>&lt;c++&gt;&lt;python-3.x&gt;&lt;pytorch&gt;&lt;torch&gt;&lt;libtorch&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52948410</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-23 11:51:54</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Frequently getting CUDA error out of memory?</td>\n",
       "      <td>&lt;p&gt;I have written a code for training a deep l...</td>\n",
       "      <td>&lt;python-3.x&gt;&lt;deep-learning&gt;&lt;pytorch&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63522070</td>\n",
       "      <td>1</td>\n",
       "      <td>63523010.0</td>\n",
       "      <td>2020-08-21 11:29:49</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Value error while converting tensor to numpy a...</td>\n",
       "      <td>&lt;p&gt;I'm using the following code to extract the...</td>\n",
       "      <td>&lt;python&gt;&lt;numpy&gt;&lt;pytorch&gt;&lt;torch&gt;&lt;resnet&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53588623</td>\n",
       "      <td>1</td>\n",
       "      <td>53592537.0</td>\n",
       "      <td>2018-12-03 06:35:18</td>\n",
       "      <td>5508</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pytorch - TypeError: 'torch.Size' object canno...</td>\n",
       "      <td>&lt;p&gt;Hi I am training a PyTorch model and occurr...</td>\n",
       "      <td>&lt;python&gt;&lt;pytorch&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57788412</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-09-04 12:28:53</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mask first k elements in a 3D tensor in PyTorc...</td>\n",
       "      <td>&lt;p&gt;I have a tensor &lt;code&gt;M&lt;/code&gt; of dimension...</td>\n",
       "      <td>&lt;python&gt;&lt;pytorch&gt;&lt;tensor&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  PostTypeId  AcceptedAnswerId         CreationDate  ViewCount  AnswerCount  CommentCount  Score                                              Title                                               Body                                         Tags Source source\n",
       "0  63831906           1               NaN  2020-09-10 14:30:09         73            0             2      0  Reading from cuda array in torch c++ without t...  <p>I am trying to read cuda array located in G...  <c++><python-3.x><pytorch><torch><libtorch>    old    NaN\n",
       "1  52948410           1               NaN  2018-10-23 11:51:54        226            1             2     -1       Frequently getting CUDA error out of memory?  <p>I have written a code for training a deep l...         <python-3.x><deep-learning><pytorch>    old    NaN\n",
       "2  63522070           1        63523010.0  2020-08-21 11:29:49         62            2             1      0  Value error while converting tensor to numpy a...  <p>I'm using the following code to extract the...      <python><numpy><pytorch><torch><resnet>    old    NaN\n",
       "3  53588623           1        53592537.0  2018-12-03 06:35:18       5508            1             0      2  Pytorch - TypeError: 'torch.Size' object canno...  <p>Hi I am training a PyTorch model and occurr...                            <python><pytorch>    old    NaN\n",
       "4  57788412           1               NaN  2019-09-04 12:28:53         70            1             0      0  mask first k elements in a 3D tensor in PyTorc...  <p>I have a tensor <code>M</code> of dimension...                    <python><pytorch><tensor>    old    NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pt_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28990026-83cc-4af5-94f6-5b2a75eb41f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting the code parts from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23057f26-0779-428d-885f-7b166ea7ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_blocks(body: str, _id: int) -> List:\n",
    "    global index\n",
    "    # regex = r\"<pre><code>((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>)\"\n",
    "    # regex = r\"(<pre>|(<pre((.*?)|(\\n)*)*><code>))((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>|</pre>)\"\n",
    "    regex = r\"<pre(><code>|>|(((.*?)|(\\n)*)><code>)|((.*?)|(\\n)*)>)((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>|</pre>)\"\n",
    "    matches = re.finditer(regex, body, re.MULTILINE | re.IGNORECASE)\n",
    "    result = []\n",
    "    \n",
    "    try:\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            code = match.group()\n",
    "            code = re.sub('<pre(><code>|>|(((.*?)|(\\n)*)><code>)|((.*?)|(\\n)*)>)', '', code)\n",
    "            code = code.replace(\"<pre><code>\", \"\")\n",
    "            code = code.replace(\"</pre></code>\", \"\")\n",
    "            code = code.replace(\"</code></pre>\", \"\")\n",
    "            result.append(code)\n",
    "    except:\n",
    "        print(\"\\n Error(1): \", _id)\n",
    "        print(body)\n",
    "        return None\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f87db6b2-b24a-45d5-a7d2-e234bc3f0f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_w_pt_tags['Code'] = df_w_pt_tags.apply(lambda row: extract_code_blocks(row.Body, row.Id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25534f29-f886-4366-9c74-366cb41becd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_w_tags.iloc[7]['Body'])\n",
    "# print(type(extract_code_blocks(df_w_tags.iloc[7]['Body'])))\n",
    "# print(len(extract_code_blocks(df_w_tags.iloc[7]['Body'])))\n",
    "# print(extract_code_blocks(df_w_tags.iloc[7]['Body'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b1e27-61be-4359-9b1c-c80828413913",
   "metadata": {},
   "source": [
    "Reset the index of dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e700b0aa-2f79-43c5-90e8-f969379e8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags = df_w_pt_tags.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbd611",
   "metadata": {},
   "source": [
    "#### Finding the number of questions that have a code or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "717748e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count__question_w_code  = 0\n",
    "count__question_wo_code = 0\n",
    "count__num_codes = 0\n",
    "\n",
    "def counting_w_or_wo_code(row_code: List) -> bool:\n",
    "    global count__question_w_code, count__question_wo_code, count__num_codes\n",
    "    \n",
    "    if row_code:\n",
    "        count__question_w_code = count__question_w_code + 1\n",
    "        count__num_codes += len(row_code)\n",
    "        return True\n",
    "    else:\n",
    "        count__question_wo_code = count__question_wo_code + 1\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a723e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Has_code'] = df_w_pt_tags['Code'].apply(lambda row_code: counting_w_or_wo_code(row_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8547f91-ce63-4b34-a349-f13a0815fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 13838 records in our DB, including 11753 posts that have code block in themselve and 2085 w/o any code block.\n",
      "We have 26000 number of code blocks including stacktrace, snippet code, error message.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {df_w_pt_tags.shape[0]} records in our DB, including {count__question_w_code} posts that have code block in themselve and {count__question_wo_code} w/o any code block.\")\n",
    "print(f\"We have {count__num_codes} number of code blocks including stacktrace, snippet code, error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd63ed7-eb63-42e3-b2a5-bc9641a5de68",
   "metadata": {},
   "source": [
    "### Define two lists for storing the information of the questions w or w/o Code Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42393cac-4d55-40c3-91b4-ff5b0c46e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_w_code_info = []\n",
    "Question_wo_code_info = []\n",
    "\n",
    "def counting_w_or_wo_code(row_id: int, \n",
    "                           row_cr: object, \n",
    "                           row_vc: int, \n",
    "                           row_ac: int, \n",
    "                           row_cc: int, \n",
    "                           row_sc: int, \n",
    "                           row_ac_an_id: float, \n",
    "                           has_code: bool) -> None:\n",
    "    \n",
    "    global Question_w_code_info, Question_wo_code_info\n",
    "\n",
    "    if has_code:\n",
    "        Question_w_code_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))\n",
    "\n",
    "    else:\n",
    "        Question_wo_code_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c31a72a-d990-42d1-b705-71effe848de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_w_pt_tags.apply(lambda row: counting_w_or_wo_code(row.Id, \n",
    "                                                           row.CreationDate, \n",
    "                                                           row.ViewCount,\n",
    "                                                           row.AnswerCount,\n",
    "                                                           row.CommentCount,\n",
    "                                                           row.Score,\n",
    "                                                           row.AcceptedAnswerId,\n",
    "                                                           row.Has_code), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf8b7c-8416-4244-b9f5-c12fdeceb912",
   "metadata": {},
   "source": [
    "Create dfs based on the two lists, Question_w_code_info and Question_wo_code_info and filled their answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0eb8b89-f84e-4931-b5fd-15b2b72d1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_w_code_v1 = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_q_w_code_v1[\"Q_info\"] = Question_w_code_info\n",
    "\n",
    "df_q_w_code_v1[\"Q_id\"]          = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_q_w_code_v1[\"Q_create_time\"] = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_q_w_code_v1[\"View_count\"]    = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_q_w_code_v1[\"Answer_count\"]  = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_q_w_code_v1[\"Comment_count\"] = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_q_w_code_v1[\"Score\"]         = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_q_w_code_v1[\"Accepted_Answer_id\"] = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[6])\n",
    "df_q_w_code_v1 = df_q_w_code_v1.drop(['Q_info'], axis='columns')\n",
    "df_q_w_code_v1[\"Q_create_time\"]      = pd.to_datetime(df_q_w_code_v1[\"Q_create_time\"])\n",
    "df_q_w_code_v1[\"First_acc_ans_time\"] = pd.to_datetime(df_q_w_code_v1[\"First_acc_ans_time\"])\n",
    "df_q_w_code_v1[\"First_ans_time\"]     = pd.to_datetime(df_q_w_code_v1[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db0993fa-176d-4a6b-b2dc-c8544072047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "df_q_w_code_v1[\"Q_id\"].to_csv('../code_output_csv/df_pt_q_w_code.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6986107d-0813-4c97-842f-9d39e842b4c7",
   "metadata": {},
   "source": [
    "SELECT df_pt_q_w_code.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_pt_q_w_code\n",
    "INNER JOIN all_results\n",
    "ON df_pt_q_w_code.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "raw",
   "id": "800bb43f-cd1e-4398-a619-2fc7701ba311",
   "metadata": {},
   "source": [
    "with cte1 as (\n",
    "SELECT\n",
    "        p.Id, \n",
    "        p.PostTypeId, \n",
    "        p.AcceptedAnswerId, \n",
    "        p.CreationDate, \n",
    "        p.ViewCount, \n",
    "        p.AnswerCount, \n",
    "        p.CommentCount, \n",
    "        p.Score,\n",
    "        p.Title,\n",
    "        p.Body,\n",
    "        p.Tags,\n",
    "        p.parentid\n",
    "\n",
    "FROM Posts as p\n",
    "inner join posts q \n",
    "        on q.id = coalesce(p.parentid, p.id) -- only questions have tags\n",
    "\n",
    "WHERE \n",
    "      p.PostTypeId=1 AND                     -- Just answers\n",
    "      --(p.Tags LIKE '%tensorflow%' OR\n",
    "       p.Tags LIKE '%pytorch%' AND\n",
    "       -- p.Tags LIKE '%scikit-learn%' AND\n",
    "       -- p.Tags LIKE '%keras%' OR\n",
    "       -- p.Tags LIKE '%nltk%' OR\n",
    "       -- p.Tags LIKE '%huggingface%' AND\n",
    "       -- p.Tags LIKE '%spark-ml%' AND\n",
    "       p.Tags LIKE '%python%'\n",
    ")\n",
    "select\n",
    "        r.parentid as Q_id,\n",
    "        r.parentid as ParentId,\n",
    "        r.Id, \n",
    "        --r.AcceptedAnswerId, \n",
    "        --r.PostTypeId,\n",
    "        --cte1.Id, \n",
    "        --cte1.PostTypeId,\n",
    "        r.CreationDate\n",
    "        --cte1.CreationDate as Q_CreationDate\n",
    "        --r.Score,\n",
    "        --cte1.AcceptedAnswerId\n",
    "        --cte1.ViewCount, \n",
    "        --cte1.AnswerCount,\n",
    "        --cte1.CommentCount, \n",
    "        --cte1.Score\n",
    "        --cte1.Title,\n",
    "        --cte1.Body,\n",
    "        --cte1.Tags,\n",
    "from posts r \n",
    "inner join cte1\n",
    "       on cte1.id = r.parentid\n",
    "where\n",
    "      r.PostTypeId = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7682b-36c0-4bad-95eb-a4747cdc950c",
   "metadata": {},
   "source": [
    "The below csv file is the result of the top query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6083e25-0e4d-473f-bf71-a8e9b1fc427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"pt_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0351daab-7864-430c-abb9-cc648bdf3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_w = pd.merge(df_q_w_code_v1, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new2_w = pd_tmp_new_w[pd_tmp_new_w.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7deae95b-6535-4428-aae9-c5a27c10510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!:  42480111 12.0 [(42616812.0, '2017-03-06 02:55:05'), (45528544.0, '2017-08-06 04:33:58'), (48659275.0, '2018-02-07 08:39:25'), (49989438.0, '2018-04-23 20:26:57'), (54581226.0, '2019-02-07 19:50:57'), (56762410.0, '2019-06-25 21:43:16'), (59696639.0, '2020-01-11 17:03:02'), (63372506.0, '2020-08-12 08:15:30'), (66984386.0, '2021-04-07 10:41:01'), (67019430.0, '2021-04-09 10:29:39'), (71290001.0, '2022-02-28 02:19:01')]\n",
      "Warning!:  44429199 4.0 [(44475689.0, '2017-06-10 16:40:30'), (56499814.0, '2019-06-07 18:51:38'), (59661024.0, '2020-01-09 09:38:56')]\n",
      "Warning!:  48831131 6.0 [(48833399.0, '2018-02-16 19:13:15'), (48842999.0, '2018-02-17 15:42:27'), (50607116.0, '2018-05-30 14:21:26'), (59127845.0, '2019-12-01 17:00:49'), (59998607.0, '2020-01-31 05:57:16')]\n",
      "Warning!:  51605893 2.0 [(51606286.0, '2018-07-31 05:57:34')]\n",
      "Warning!:  57248098 2.0 [(60574502.0, '2020-03-07 04:51:25')]\n",
      "Warning!:  59484501 2.0 [(nan, nan)]\n",
      "Warning!:  64088157 2.0 [(64146071.0, '2020-09-30 21:35:00')]\n"
     ]
    }
   ],
   "source": [
    "def checker_ans_and_ans_tup(q_id: int, ans_count: int, ans_list: list) -> None:\n",
    "    if len(ans_list) < ans_count:\n",
    "        print(\"Warning!: \", int(q_id), ans_count, ans_list)\n",
    "\n",
    "_ = pd_tmp_new2_w.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99f6e7ec-3c49-40c7-91b1-aa22af8b4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_acc_ans_time', np.nan)\n",
    "pd_tmp_new3_w = pd_tmp_new2_w.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8a77995-f0dc-4c9e-b2ef-34b28ed28de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_w.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_w.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_w.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = acc_time\n",
    "pd_tmp_new3_w[\"Duration_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_acc_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a61694-5e65-4c88-9153-70c7ff197b2a",
   "metadata": {},
   "source": [
    "We did the same behaviour for the Question_wo_code_info list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6e57dad-db68-4579-bfb2-aaa08da7881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_wo_code_v1 = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_q_wo_code_v1[\"Q_info\"] = Question_wo_code_info\n",
    "\n",
    "df_q_wo_code_v1[\"Q_id\"]          = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_q_wo_code_v1[\"Q_create_time\"] = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_q_wo_code_v1[\"View_count\"]    = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_q_wo_code_v1[\"Answer_count\"]  = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_q_wo_code_v1[\"Comment_count\"] = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_q_wo_code_v1[\"Score\"]         = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_q_wo_code_v1[\"Accepted_Answer_id\"] = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[6])\n",
    "df_q_wo_code_v1 = df_q_wo_code_v1.drop(['Q_info'], axis='columns')\n",
    "df_q_wo_code_v1[\"Q_create_time\"] = pd.to_datetime(df_q_wo_code_v1[\"Q_create_time\"])\n",
    "df_q_wo_code_v1[\"First_acc_ans_time\"] = pd.to_datetime(df_q_wo_code_v1[\"First_acc_ans_time\"])\n",
    "df_q_wo_code_v1[\"First_ans_time\"]     = pd.to_datetime(df_q_wo_code_v1[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5cd96bf-f82f-44c8-ab02-3b6125816f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "df_q_wo_code_v1[\"Q_id\"].to_csv('../code_output_csv/df_pt_q_wo_code.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3c41fc5-ade4-4b12-9368-7262b638af3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "SELECT df_pt_q_wo_code.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_pt_q_wo_code\n",
    "INNER JOIN all_results\n",
    "ON df_pt_q_wo_code.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936c6c3-4be0-4e37-abdc-a6aae7d45209",
   "metadata": {},
   "source": [
    "We used the all answers csv file again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd685334-11a6-4cee-93f2-df19e1c13617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"pt_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night_wo = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f593db9d-944d-49ef-8f51-29226b2c11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo = df_night_wo.reset_index(drop=True)\n",
    "df_q_wo_code_v1['Answers'] = df_q_wo_code_v1.apply(lambda x: [], axis=1)\n",
    "\n",
    "pd_tmp_wo = pd.merge(df_q_wo_code_v1, df_night_wo, how='left',left_on=['Q_id'],right_on=['ParentId']).reset_index(drop=True)\n",
    "\n",
    "pd_tmp_wo[\"Answer_tup\"] = pd_tmp_wo.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_wo = pd_tmp_wo.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new2_wo = pd_tmp_new_wo[pd_tmp_new_wo.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bfda529-4f8a-4508-9ffd-a9a6084612be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!:  49283435 2 [(49293872.0, '2018-03-15 07:38:34')]\n",
      "Warning!:  59856930 2 [(59858804.0, '2020-01-22 11:32:21')]\n",
      "Warning!:  63185157 2 [(63205764.0, '2020-08-01 13:32:53')]\n",
      "Warning!:  64644745 2 [(64644999.0, '2020-11-02 11:47:03')]\n"
     ]
    }
   ],
   "source": [
    "_ = pd_tmp_new2_wo.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1807a5b-a7b2-45ee-944a-7f0a6d61c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_acc_ans_time', np.nan)\n",
    "pd_tmp_new3_wo = pd_tmp_new2_wo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7741c7cc-9ed9-4b7b-8af6-7c3c577d3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_wo.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_wo.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_wo.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = acc_time\n",
    "    \n",
    "pd_tmp_new3_wo[\"Duration_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_wo[\"Duration_acc_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0c12b70-92ba-4c99-8315-a2e5212bb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "pd_tmp_new3_w.to_csv('./CSV_data/plt_pt_q_w_code.csv', encoding='utf-8')\n",
    "pd_tmp_new3_wo.to_csv('./CSV_data/plt_pt_q_wo_code.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76009349",
   "metadata": {},
   "source": [
    "### Extracting the text parts from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "426b615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_blocks(id: int, body: str) -> Optional[List]:\n",
    "    # It's bug\n",
    "    if id in [10005, 14212, 21959, 26677, 53279]: \n",
    "        body = body + \"</p>\"\n",
    "\n",
    "    regex = r\"(<p>((.*?)|(\\n)*)*<\\/p>)|(<ul>((.*?)|(\\n)*)*<\\/ul>)|(<ol>((.*?)|(\\n)*)*<\\/ol>)\"\n",
    "    matches = re.finditer(regex, body, re.MULTILINE | re.IGNORECASE)\n",
    "    result = []\n",
    "    \n",
    "    # if id in [18397]:\n",
    "    #     return result\n",
    "\n",
    "    try:\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            text = match.group()\n",
    "            text = text.replace(\"<p>\", \"\")\n",
    "            text = text.replace(\"<strong>\", \"\")\n",
    "            text = text.replace(\"<br>\", \"\")\n",
    "            text = text.replace(\"<ol>\", \"\")\n",
    "            text = text.replace(\"<ul>\", \"\")\n",
    "            text = text.replace(\"<li>\", \"\")\n",
    "            text = text.replace(\"</p>\", \"\")\n",
    "            text = text.replace(\"</strong>\", \"\")\n",
    "            text = text.replace(\"</ol>\", \"\")\n",
    "            text = text.replace(\"</ul>\", \"\")\n",
    "            text = text.replace(\"</li>\", \"\")\n",
    "            result.append(text)\n",
    "        return result\n",
    "    except:\n",
    "        print(\"Error(1): \", id)\n",
    "        print(body)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96ff4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Text'] = df_w_pt_tags.apply(lambda row: extract_text_blocks(row.name, row.Body), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bb294",
   "metadata": {},
   "source": [
    "#### Finding the number of body words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18933061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_text_words(text_list: List) -> int:\n",
    "    word_count = 0\n",
    "    for text in text_list:\n",
    "        word_count += sum([i.strip(string.punctuation).isalpha() for i in text.split()])\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15bc8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Q_text_words_num'] = df_w_pt_tags[\"Text\"].apply(lambda text_list: find_q_text_words(text_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d4e61-0992-43cf-bfc4-83cebb7d1bbf",
   "metadata": {},
   "source": [
    "Save the dataframe as csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d8f131a-19f7-46b8-b8e3-399ba5537607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_w_Tens_tags.to_csv('./amin_result_v1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5ff90-afcd-45a3-9d2d-a2b58de44dd9",
   "metadata": {},
   "source": [
    "### Find the Regular Expressions for Unix and Windows base Pathnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3406a54-9a09-4255-8287-d16fab93833d",
   "metadata": {},
   "source": [
    "#### 1) Absolute and Relative Pathnames in UNIX OS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c90be3-66df-4290-972f-940233a71e7c",
   "metadata": {},
   "source": [
    "Stack/trace example: https://stackoverflow.com/questions/37337728/tensorflow-internalerror-blas-sgemm-launch-failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9d6c0-8adb-4939-9f06-329b036eb875",
   "metadata": {},
   "source": [
    "Find the restrictions and limitations related to the Unix pathnames: https://www.cyberciti.biz/faq/linuxunix-rules-for-naming-file-and-directory-names/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32c563-d1db-4f0a-9820-62fd42a6591e",
   "metadata": {},
   "source": [
    "Online regular expression environment for testing: https://regex101.com/r/ZyEx5u/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9456a-4c9e-4a8f-bee5-86a5be847e82",
   "metadata": {},
   "source": [
    "> Regular Expression: \"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb6875-32a5-4f52-b33a-9cb522a49f72",
   "metadata": {},
   "source": [
    "#### 1) Pathnames in Windows OS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9c86a-e55e-4200-85ff-ed3033b4ee64",
   "metadata": {},
   "source": [
    "Stack/trace example: https://stackoverflow.com/questions/49434031/tensorflow-on-windows-cpu-version-importerror-no-module-named-pywrap-tensorf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd40a8-d970-435c-a06d-6a32130d3055",
   "metadata": {},
   "source": [
    "Find the restrictions and limitations related to the Windows pathnames: <br /> \n",
    "https://docs.microsoft.com/en-us/dotnet/standard/io/file-path-formats <br />\n",
    "https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5ffa1-d9f8-4e8c-b9a8-8f438af95a1a",
   "metadata": {},
   "source": [
    "Online regular expression environment for testing: https://regex101.com/r/L6xmCa/1 , https://regex101.com/r/wz1WqW/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1be13-b32c-4d50-9ea2-490eafe5b139",
   "metadata": {},
   "source": [
    "> Regular Expression: \"[a-zA-Z]:\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc401c12-44a2-402c-9e4a-1de67941e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pathnames_from_code_column(code_sec: List, _id: int) -> Tuple[str, List]: \n",
    "    try:\n",
    "        result_post_file_names = []\n",
    "        OS_flag = None\n",
    "        error_index = None\n",
    "        error_code = None\n",
    "        regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/\\\\]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\s\\W*\\d*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?\\/?([^\\<\\>\\:\\\"\\\\\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        \n",
    "        for idx, code in enumerate(code_sec):\n",
    "            pattern_unix  = re.compile(regex_unix)\n",
    "            pattern_windows  = re.compile(regex_windows)\n",
    "            if pattern_unix.search(code):\n",
    "                OS_flag = \"unix\"\n",
    "                break\n",
    "            elif pattern_windows.search(code):\n",
    "                OS_flag = \"windows\"\n",
    "                break\n",
    "                \n",
    "        if OS_flag == \"unix\":\n",
    "            for idx, code in enumerate(code_sec):\n",
    "                error_index = idx\n",
    "                code = code.replace(\"\\\\n\", \"\\n\")\n",
    "                code = code.replace('&lt;', '<')\n",
    "                code = code.replace('&gt;', '>')\n",
    "                code = code.replace('&quot;', '\"')\n",
    "                error_code = code\n",
    "                matches = re.finditer(regex_unix, code, re.MULTILINE)\n",
    "                file_names_for_each_code_part = []\n",
    "                \n",
    "                for matchNum, match in enumerate(matches, start=1):\n",
    "                    file_names_for_each_code_part.append((match.groups()[1].strip(), match.groups()[4].strip()))\n",
    "#                     file_names_for_each_code_part.append(match.groups()[1].strip())\n",
    "                    # print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "                    # for groupNum in range(0, len(match.groups())):\n",
    "                        # groupNum = groupNum + 1\n",
    "                        # print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n",
    "#                 print(file_names_for_each_code_part)\n",
    "#                 file_names_for_each_code_part = list(set(file_names_for_each_code_part))            # Create a unique list\n",
    "#                 print(file_names_for_each_code_part)\n",
    "                \n",
    "                if file_names_for_each_code_part:                                                   # Ignore the empty list\n",
    "                    result_post_file_names.append(file_names_for_each_code_part)\n",
    "                    \n",
    "        elif OS_flag == \"windows\":\n",
    "            for idx, code in enumerate(code_sec):\n",
    "                code = code.replace('&lt;', '<')\n",
    "                code = code.replace('&gt;', '>')\n",
    "                code = code.replace('&quot;', '\"')\n",
    "                error_code = code\n",
    "                matches = re.finditer(regex_windows, code, re.MULTILINE)                            \n",
    "                file_names_for_each_code_part = []\n",
    "\n",
    "                for matchNum, match in enumerate(matches, start=1):\n",
    "                    file_names_for_each_code_part.append((match.groups()[3].strip(), match.groups()[6].strip()))\n",
    "#                     file_names_for_each_code_part.append(match.groups()[1].strip())\n",
    "                    # print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "                    # for groupNum in range(0, len(match.groups())):\n",
    "                        # groupNum = groupNum + 1\n",
    "                        # print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n",
    "#                 file_names_for_each_code_part = [s.strip() for s in file_names_for_each_code_part]  # Strip the list\n",
    "#                 file_names_for_each_code_part = list(set(file_names_for_each_code_part))            # create a unique list\n",
    "                if file_names_for_each_code_part:                                                     # Ignore the empty list\n",
    "                    result_post_file_names.append(file_names_for_each_code_part)\n",
    "            \n",
    "    except:\n",
    "        print(\"\\n Error Id:\", _id, \" Error index:\", error_index, \"\\n\")\n",
    "        print(error_code)\n",
    "        return None, None\n",
    "\n",
    "    return OS_flag, result_post_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc583436-6446-47b3-8811-ee3b316c57cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, [])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for Unix path\n",
    "# https://stackoverflow.com/questions/51839415/tensorflow-valueerror-rank-mismatch\n",
    "# df_w_pt_tags.iloc[9][:]\n",
    "extract_pathnames_from_code_column(df_w_pt_tags[\"Code\"][51], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8642e202-ad70-4f13-9440-57eeeb3fda8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example for Windows path\n",
    "# df_w_pt_tags['Code'] = df_w_pt_tags['Body'].apply(lambda row_body: extract_code_blocks(row_body))\n",
    "# print(df_w_pt_tags[\"Code\"][9])\n",
    "# extract_pathnames_from_code_column(df_w_pt_tags[\"Code\"][84])\n",
    "# extract_pathnames_from_code_column(df_w_pt_tags[\"Code\"][606])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c61970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_pt_tags[\"Body\"][606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0dd38400-fb42-4dc7-8f9d-deb13a98c1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_w_pt_tags['Bugy_py_files'] = df_w_pt_tags.apply(lambda row: extract_pathnames_from_code_column(row.Code, row.Id), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7d4de",
   "metadata": {},
   "source": [
    "Save the dataframe as csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e4ea318-37e3-4d03-b3a2-566723d22160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_w_pt_tags.loc[df_w_PT_tags['Id'] == 46509039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4718e5db-2866-4f96-8a3a-2a09e559cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_pt_tags[[\"Title\", \"Code\", \"Bugy_py_files\"]].head(100)\n",
    "# df_w_pt_tags.to_csv('./pt_Code_bug.csv', sep='\\n', encoding='utf-8')\n",
    "# df_w_pt_tags['Bugy_py_files'].to_csv('./pt_bugy_tuples.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7e0c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_has_trace_col(cal_tuple) -> bool:\n",
    "    if cal_tuple[0] == \"windows\" or cal_tuple[0] == \"unix\":\n",
    "        return True\n",
    "    elif cal_tuple[0] is None:\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acd983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Has_trace'] = df_w_pt_tags['Bugy_py_files'].apply(lambda cell_tuple: create_has_trace_col(cell_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60aff5",
   "metadata": {},
   "source": [
    "#### Finding the number and type of LOC in the body of post:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33da7bf-c174-48ba-999c-766d91c33a7a",
   "metadata": {},
   "source": [
    "For example how many pairs did you find in a post and defining the OS of that stack trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c25a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_line_of_code(code_list: List) -> Tuple[int, int, int]:\n",
    "    line_count_trace_win   = 0\n",
    "    line_count_trace_unix  = 0\n",
    "    line_count_simple_code = 0\n",
    "    \n",
    "    for code in code_list:\n",
    "        regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/\\\\]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\s\\W*\\d*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?\\/?([^\\<\\>\\:\\\"\\\\\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        # regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\" version 2\n",
    "        # regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d+)\\W*in\\W*([a-zA-Z_$][a-zA-Z_$0-9]*)\" version 1\n",
    "        # regex_windows = r\"[a-zA-Z]:\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d+)\\W*in\\W*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        pattern_unix  = re.compile(regex_unix)\n",
    "        pattern_windows = re.compile(regex_windows)\n",
    "        if pattern_unix.search(code):\n",
    "            OS_flag = \"unix\"\n",
    "        elif pattern_windows.search(code):\n",
    "            OS_flag = \"windows\"\n",
    "        else:\n",
    "            OS_flag = \"nothing\"\n",
    "            \n",
    "        code_wo_empty_line = os.linesep.join([s for s in code.splitlines() if s])\n",
    "            \n",
    "        if OS_flag == \"unix\":\n",
    "            line_count_trace_unix += len(code_wo_empty_line.splitlines())\n",
    "        elif OS_flag == \"windows\":\n",
    "            line_count_trace_win += len(code_wo_empty_line.splitlines())\n",
    "        elif OS_flag == \"nothing\":\n",
    "            line_count_simple_code += len(code_wo_empty_line.splitlines()) \n",
    "        else:\n",
    "            print(\"Error!\")\n",
    "\n",
    "    return (line_count_trace_unix, line_count_trace_win, line_count_simple_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4054d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finding_line_of_code(df_w_pt_tags.loc[19, 'Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2f3958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Line_code_u_w_s'] = df_w_pt_tags['Code'].apply(lambda code_list: finding_line_of_code(code_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3e57594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Line_code_uix'] = df_w_pt_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a683106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_pt_tags['Line_code_win'] = df_w_pt_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b99bf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has a code (Python code) inside the post\n",
    "df_w_pt_tags['Line_code_simple_code'] = df_w_pt_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3534efd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Source</th>\n",
       "      <th>source</th>\n",
       "      <th>Code</th>\n",
       "      <th>Has_code</th>\n",
       "      <th>Text</th>\n",
       "      <th>Q_text_words_num</th>\n",
       "      <th>Bugy_py_files</th>\n",
       "      <th>Has_trace</th>\n",
       "      <th>Line_code_u_w_s</th>\n",
       "      <th>Line_code_uix</th>\n",
       "      <th>Line_code_win</th>\n",
       "      <th>Line_code_simple_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63831906</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-10 14:30:09</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Reading from cuda array in torch c++ without t...</td>\n",
       "      <td>&lt;p&gt;I am trying to read cuda array located in G...</td>\n",
       "      <td>&lt;c++&gt;&lt;python-3.x&gt;&lt;pytorch&gt;&lt;torch&gt;&lt;libtorch&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[auto options = torch::TensorOptions().dtype(t...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I am trying to read cuda array located in GPU...</td>\n",
       "      <td>163</td>\n",
       "      <td>(None, [])</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0, 2)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52948410</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-23 11:51:54</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Frequently getting CUDA error out of memory?</td>\n",
       "      <td>&lt;p&gt;I have written a code for training a deep l...</td>\n",
       "      <td>&lt;python-3.x&gt;&lt;deep-learning&gt;&lt;pytorch&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[    for epoch in range(1+last_epoch, self.num...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I have written a code for training a deep lea...</td>\n",
       "      <td>57</td>\n",
       "      <td>(None, [])</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0, 59)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  PostTypeId  AcceptedAnswerId         CreationDate  ViewCount  AnswerCount  CommentCount  Score                                              Title                                               Body                                         Tags Source source                                               Code  Has_code                                               Text  Q_text_words_num Bugy_py_files  Has_trace Line_code_u_w_s  Line_code_uix  Line_code_win  Line_code_simple_code\n",
       "0  63831906           1               NaN  2020-09-10 14:30:09         73            0             2      0  Reading from cuda array in torch c++ without t...  <p>I am trying to read cuda array located in G...  <c++><python-3.x><pytorch><torch><libtorch>    old    NaN  [auto options = torch::TensorOptions().dtype(t...      True  [I am trying to read cuda array located in GPU...               163    (None, [])      False       (0, 0, 2)              0              0                      2\n",
       "1  52948410           1               NaN  2018-10-23 11:51:54        226            1             2     -1       Frequently getting CUDA error out of memory?  <p>I have written a code for training a deep l...         <python-3.x><deep-learning><pytorch>    old    NaN  [    for epoch in range(1+last_epoch, self.num...      True  [I have written a code for training a deep lea...                57    (None, [])      False      (0, 0, 59)              0              0                     59"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pt_tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fde1f5",
   "metadata": {},
   "source": [
    "#### Question Post's Length (body of the post): Defining the lists for plotting their comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd5dee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_num_words_w_tra  = []\n",
    "list_num_words_wo_tra = []\n",
    "\n",
    "for index1, row in df_w_pt_tags.iterrows():\n",
    "    if row.Has_trace is True:\n",
    "        list_num_words_w_tra.append(row.Q_text_words_num)\n",
    "    elif row.Has_trace is False:\n",
    "        list_num_words_wo_tra.append(row.Q_text_words_num)\n",
    "    else:\n",
    "        print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae0b5-da13-4ad7-b853-44783e21104b",
   "metadata": {},
   "source": [
    "#### OS Stack Traces: Defining the number of stack straces the belongs to the Unix or Windows OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd3530e5-831c-4db8-b250-089f05938c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found the 471 of stackoverflow's posts that belong to the Windows OS.\n",
      "We found the 1524 of stackoverflow's posts that belong to the Unix OS.\n"
     ]
    }
   ],
   "source": [
    "counter_win  = 0\n",
    "counter_unix = 0\n",
    "# dim_win  = []\n",
    "# dim_unix = []\n",
    "\n",
    "for tp in df_w_pt_tags[\"Bugy_py_files\"]:\n",
    "    if tp[0] == \"windows\":\n",
    "        counter_win += 1\n",
    "#         np_array = np.array(tuple[1], dtype=object)\n",
    "#         dim_win.append(np_array.shape)\n",
    "        \n",
    "    elif tp[0] == \"unix\":\n",
    "        counter_unix += 1\n",
    "#         np_array = np.array(tuple[1], dtype=object)\n",
    "#         dim_unix.append(np_array.shape)\n",
    "\n",
    "print(f\"We found the {counter_win} of stackoverflow's posts that belong to the Windows OS.\")\n",
    "print(f\"We found the {counter_unix} of stackoverflow's posts that belong to the Unix OS.\")\n",
    "# print(\"The dimensions of Windows labels is: \", set(dim_win))\n",
    "# print(\"The dimensions of Unix labels is: \", set(dim_unix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "862bb743-f63d-4f4f-9b62-e38bb4711f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "PostTypeId                 int64\n",
       "AcceptedAnswerId         float64\n",
       "CreationDate              object\n",
       "ViewCount                  int64\n",
       "AnswerCount                int64\n",
       "CommentCount               int64\n",
       "Score                      int64\n",
       "Title                     object\n",
       "Body                      object\n",
       "Tags                      object\n",
       "Source                    object\n",
       "source                    object\n",
       "Code                      object\n",
       "Has_code                    bool\n",
       "Text                      object\n",
       "Q_text_words_num           int64\n",
       "Bugy_py_files             object\n",
       "Has_trace                   bool\n",
       "Line_code_u_w_s           object\n",
       "Line_code_uix              int64\n",
       "Line_code_win              int64\n",
       "Line_code_simple_code      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_pt_tags.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4c57c-d11e-4e1d-ac85-9c155d748630",
   "metadata": {},
   "source": [
    "#### Define two lists for storing the information of the questions w or w/o stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a685f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_w_t  = 0\n",
    "count_wo_t = 0\n",
    "count_win  = 0\n",
    "count_unix = 0\n",
    "\n",
    "Question_with_trace_info = []\n",
    "Question_with_wo_trace_info = []\n",
    "\n",
    "def counting_w_or_wo_trace(row_id: int, \n",
    "                           row_cr: object, \n",
    "                           row_vc: int, \n",
    "                           row_ac: int, \n",
    "                           row_cc: int, \n",
    "                           row_sc: int, \n",
    "                           row_ac_an_id: float, \n",
    "                           row_t: object, \n",
    "                           has_code: bool) -> None:\n",
    "    \n",
    "    global count_w_t, count_wo_t, count_win, count_unix, Question_with_trace_info, Question_with_wo_trace_info\n",
    "\n",
    "    if has_code:\n",
    "        if row_t[0] is not None:\n",
    "            count_w_t = count_w_t + 1\n",
    "            Question_with_trace_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))\n",
    "            \n",
    "            if row_t[0] == 'unix':\n",
    "                count_unix = count_unix + 1\n",
    "            else:\n",
    "                count_win = count_win + 1\n",
    "        else:\n",
    "            count_wo_t = count_wo_t + 1\n",
    "            Question_with_wo_trace_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee29fdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = df_w_pt_tags.apply(lambda row: counting_w_or_wo_trace(row.Id, \n",
    "                                                               row.CreationDate, \n",
    "                                                               row.ViewCount,\n",
    "                                                               row.AnswerCount,\n",
    "                                                               row.CommentCount,\n",
    "                                                               row.Score,\n",
    "                                                               row.AcceptedAnswerId,\n",
    "                                                               row.Bugy_py_files, \n",
    "                                                               row.Has_code), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f73aa-307c-4ca5-ad1f-9c80e0067c0f",
   "metadata": {},
   "source": [
    "#### Creating a string matrix of pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe9422-3706-4fc3-9135-8cbd87353226",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://stackoverflow.com/questions/32037893/numpy-fix-array-with-rows-of-different-lengths-by-filling-the-empty-elements-wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3390d5ca-986e-4ddf-a48f-eb4e45ab46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_fillna(data: List) -> np.ndarray:\n",
    "    # Get lengths of each row of data\n",
    "    lens = np.array([len(i) for i in data])\n",
    "\n",
    "    # Mask of valid places in each row\n",
    "    mask = np.arange(lens.max()) < lens[:, None]\n",
    "\n",
    "    # Setup output array and put elements from data into masked positions\n",
    "    out = np.zeros(mask.shape, dtype='object')\n",
    "    out[mask] = np.concatenate(data)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "043411f3-4d8b-43b5-89e2-7a9b5d9e1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_2D_array_with_str = []\n",
    "\n",
    "# The below list store the post Id for each instances (or row in _2D_array). \n",
    "# We have to mention that the index of _2D_array and _Id_array helps us to find the id pattern quickly.\n",
    "_Id_array = []\n",
    "\n",
    "for index1, row in df_w_pt_tags.iterrows():\n",
    "    row_tuple = row.Bugy_py_files\n",
    "    row_id = row.Id\n",
    "    \n",
    "    # row: (some rows have multiple patterns)\n",
    "    # ('unix', [[('estimator', 'train'), ('estimator', '_train_model'), \n",
    "    #            ('estimator', '_train_model_default'), ('estimator', '_call_model_fn'), ('nn_ops', 'sparse_softmax_cross_entropy_with_logits')]])\n",
    "    \n",
    "    if row_tuple[0] is None: continue\n",
    "    \n",
    "    for element in row_tuple[1]:\n",
    "        _Id_array.append(row_id)\n",
    "        element_tmp = element[:]\n",
    "        _2D_array_with_str.append(element_tmp)\n",
    "\n",
    "# _2D_array_pad = numpy_fillna(_2D_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa51f-6992-42c2-9cf0-fd1888ae4047",
   "metadata": {},
   "source": [
    "#### Creating a numerical matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ab766-8031-4eca-9cef-455c127c6283",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-pandas-factorize/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbea84-d201-4010-9759-c32f05b80aa9",
   "metadata": {},
   "source": [
    "##### Creating a dictionary based on pairs and assigning a unique number to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8257c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict pair : int\n",
    "\n",
    "dic = {} \n",
    "specific_val = 1\n",
    "for row in _2D_array_with_str:\n",
    "    for element in row:\n",
    "        if element not in dic:\n",
    "            dic[element] = specific_val\n",
    "            specific_val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82ffd8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique pairs is:  3846\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique pairs is: \", max(dic.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfa8c9-9b6c-4643-b0b7-6b39e7fe40e4",
   "metadata": {},
   "source": [
    "##### Converting strings on the _2D_array into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2bf0be4-4828-4126-8816-81c1a4a3f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array_with_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a556c82-ad7d-43c9-b7f1-c852da489f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array = list()\n",
    "# _2D_array_str = _2D_array_with_str.copy()\n",
    "# _2D_array = _2D_array_with_str[:]\n",
    "_2D_array = _2D_array_with_str[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ff5062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(_2D_array):\n",
    "    for j in range(len(row)):\n",
    "        _2D_array[i][j] = dic[_2D_array[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3971037-915c-4994-9107-5b36a9d62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array_with_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec5559a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _2D_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f97135b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqe_dic int : pair\n",
    "uniqe_dic = dict([(value, key) for key, value in dic.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a621bac-8178-438b-8464-73225fe218a7",
   "metadata": {},
   "source": [
    "By the below function we deleted duplicated rows in 2d_array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca3c46e1-7f42-4369-8ea3-6a25dbadc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2d_array_dup(_2d_array: list) -> Tuple[int, list]:\n",
    "    \n",
    "    dup_count = 0\n",
    "    _2d_array_tmp = _2d_array.copy()\n",
    "    _2d_array_tmp_next = []\n",
    "    \n",
    "    idx = 0\n",
    "    while idx != len(_2d_array_tmp):\n",
    "        \n",
    "        for indx_previous in range(0, idx+1):\n",
    "            _2d_array_tmp_next.append(_2d_array_tmp[indx_previous])\n",
    "        \n",
    "        for indx_next in range(idx+1, len(_2d_array_tmp)):\n",
    "#             print(idx, indx_next)\n",
    "#             print(_2d_array_tmp)\n",
    "#             print(_2d_array_tmp_next)\n",
    "\n",
    "            if _2d_array_tmp[idx] == _2d_array_tmp[indx_next]:\n",
    "                dup_count += 1\n",
    "            else:\n",
    "                _2d_array_tmp_next.append(_2d_array_tmp[indx_next])\n",
    "#         print(_2d_array_tmp_next)\n",
    "#         print(len(_2d_array_tmp_next))\n",
    "#         break\n",
    "        _2d_array_tmp = _2d_array_tmp_next\n",
    "        _2d_array_tmp_next = []\n",
    "        idx += 1\n",
    "    \n",
    "    return dup_count, _2d_array_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd20b1db-3f52-4f69-ad94-f91eff4c5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplication_row, _2D_array_new = find_2d_array_dup(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "038074a7-a09a-4288-9368-db126c18d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"We decresed the number of patterns from {len(_2D_array)} to {len(_2D_array_new)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa324359",
   "metadata": {},
   "source": [
    "## Answering the second research question (RQ2): Finding Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31312935",
   "metadata": {},
   "source": [
    "## Contiguous Sequential Pattern Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4c26c",
   "metadata": {},
   "source": [
    "https://www.cc.gatech.edu/~hic/CS7616/pdf/lecture13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ff498",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Approach (1):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9bae7",
   "metadata": {},
   "source": [
    "The shortest yet efficient implementation of the famous frequent sequential pattern mining algorithm PrefixSpan, the famous frequent closed sequential pattern mining algorithm BIDE (in closed.py), and the frequent generator sequential pattern mining algorithm FEAT (in generator.py), as a unified and holistic algorithm framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96570036",
   "metadata": {},
   "source": [
    "https://github.com/chuanconggao/PrefixSpan-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5eaa5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35702190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prefixspan import PrefixSpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c509adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PrefixSpan(_2D_array_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df9fc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = ps.frequent(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b69e8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"/home-students/amghad/sample.txt\", \"w\")\n",
    "# str_list = repr(k)\n",
    "# file.write(str_list)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2979a",
   "metadata": {},
   "source": [
    "### Approach (2): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a8e0a",
   "metadata": {},
   "source": [
    "pymining is a small collection of data mining algorithms implemented in Python. I did not design any of the algorithms, but I use them in my own research so I thought other developers might be interested to use them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94392e0f",
   "metadata": {},
   "source": [
    "https://github.com/bartdag/pymining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e8d57",
   "metadata": {},
   "source": [
    "### Approach (3): By this approach we simply check all possible status for each row (or pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec37188-5c46-407b-b193-55c54b2e1841",
   "metadata": {},
   "source": [
    "We want to create a dict based on the vectors on the numerical matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f60f00-0840-41a0-8398-8f863bc2bc68",
   "metadata": {},
   "source": [
    "By the below function, we tried to find and search the patterns for each vector based on the window_size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d8aae18-d1d3-4282-9bf7-f7fe45ca5d6b",
   "metadata": {},
   "source": [
    "Input Vector: [1, 2, 6, 3]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "822ce776-1a3b-476d-92e6-be663d91ff05",
   "metadata": {},
   "source": [
    "{0: [(2, [(1, 2), (2, 6), (6, 3)]),\n",
    "    (3, [(1, 2, 6), (2, 6, 3)]),\n",
    "    (4, [(1, 2, 6, 3)])]\n",
    " ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233612b-f3b4-4328-88ed-7843b13d0957",
   "metadata": {},
   "source": [
    "0: The index of vector <br>\n",
    "list: Contains tuples with different windows_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "03fb9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dicc_new(dicc: dict, vec_id: int, list_: list) -> dict:\n",
    "    if vec_id not in dicc:\n",
    "        # key not exist\n",
    "        dicc[vec_id] = list_\n",
    "    else:\n",
    "        # key exist\n",
    "        for tuple_ in list_:\n",
    "            for item in dicc[vec_id]:\n",
    "                if item[0] == tuple_[0]:\n",
    "                    item[1].append(tuple_[1][0])\n",
    "                    break\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2a340-fad0-4464-a15b-01f01995d3b0",
   "metadata": {},
   "source": [
    "The \"low\" parameter can help us control the lower bound of the window_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1c3380c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0    # <~~~~~~~ define the lower bound threshold\n",
    "up = len(uniqe_dic)\n",
    "dicc = {}     \n",
    "\n",
    "for i_v, vector in enumerate(_2D_array):    \n",
    "    for index, element in enumerate(vector):\n",
    "        list_ = []\n",
    "        for wind_size in range(low, len(vector)+1-index):\n",
    "            list_.append((wind_size, [(*vector[index:index+wind_size], )]))\n",
    "        dicc = append_to_dicc_new(dicc, i_v, list_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "88e6b3a4-6f49-462d-aac4-afa5cb3d4725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2089"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddd8bf1e-a7ad-45d8-99ab-a22e4b3f53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f09aefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplication(dup_list: list) -> list:\n",
    "    final_list = []\n",
    "    for item in dup_list:\n",
    "        if item not in final_list:\n",
    "            final_list.append(item)\n",
    "        else:\n",
    "            indx = final_list.index(item)\n",
    "            counter = final_list[indx][0] + 1\n",
    "            pair = final_list[indx][1]\n",
    "            final_list.remove(item)\n",
    "            final_list.append((counter, pair))\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a41ac-d183-4807-a0d1-fa9328e359cf",
   "metadata": {},
   "source": [
    "dic_count is a dictionary that key is window_size, and value is a list that contains tuples. Each tuple shows a pair and the number of pair's iteration on the matrix."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4befab67-c057-41a7-84c5-aa6b89e363ef",
   "metadata": {},
   "source": [
    "{2: [(1, (5, 1)),\n",
    "  (1, (1, 6)),\n",
    "  (1, (1, 2)),\n",
    "  (1, (2, 6)),\n",
    "  (2, (6, 3)),\n",
    "  (1, (6, 1)),\n",
    "  (2, (1, 3)),\n",
    "  (3, (4, 5)),\n",
    "  (5, (3, 4)),\n",
    "  (2, (4, 3)),\n",
    "  (1, (3, 6)),\n",
    "  (1, (2, 3)),\n",
    "  (1, (3, 1)),\n",
    "  (2, (1, 4)),\n",
    "  (1, (4, 6))],\n",
    "  ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ef3ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_count = {}\n",
    "\n",
    "for vec_i, list_tuples in dicc.items():\n",
    "#     print(vec_i, list_tuples,\"\\n\")\n",
    "    for tuples_ in list_tuples:\n",
    "#         print(tuples_)\n",
    "        \n",
    "        if tuples_[0] not in dic_count:\n",
    "            lst_ = [(1, tuple_) for tuple_ in tuples_[1]] \n",
    "            \n",
    "            if len(lst_) != len(set(lst_)):\n",
    "                lst_ = remove_duplication(lst_)\n",
    "            \n",
    "            dic_count[tuples_[0]] = lst_  \n",
    "        else:\n",
    "            #(2, [(1, 3), (1, 4), (3, 4), (4, 5), (5, 1)]\n",
    "            #break\n",
    "            for tuple_ in tuples_[1]:\n",
    "                flag = 0 \n",
    "                for item in dic_count[tuples_[0]]:\n",
    "                    if item[1] == tuple_:\n",
    "                        counter = item[0] + 1\n",
    "                        dic_count[tuples_[0]].remove(item)\n",
    "                        dic_count[tuples_[0]].append((counter, item[1]))\n",
    "                        flag = 1\n",
    "                        break\n",
    "                # tuple is new\n",
    "                if flag == 0:\n",
    "                    dic_count[tuples_[0]].append((1, tuple_))\n",
    "#                 else: \n",
    "#                     print(\"Error100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85825caa-0ea6-49f4-afb9-467ca6dcd2f8",
   "metadata": {},
   "source": [
    "dic_count is a dictionary that key is window_size, and value is a list that contains tuples. Each tuple shows a pair and the number of pair's iteration on the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f87b4-36e2-4376-8f3f-ba55164a1b72",
   "metadata": {},
   "source": [
    "For each window_size we count the number of patterns that we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "735ff20e-0a61-4acb-b2e4-3c9e4e9886cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5624, ()), (5626, ())]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_count.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2db34be8-e770-4e6f-a243-1f70b1766461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inst_length = dic_count.keys()\n",
    "inst_count = [len(value) for key, value in dic_count.items()]\n",
    "comulative_inst_count = np.cumsum(inst_count)\n",
    "\n",
    "per_comulative_inst_count = []\n",
    "for element in comulative_inst_count:\n",
    "    per_comulative_inst_count.append((element*100)/comulative_inst_count[-1])\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=100)\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(inst_length, per_comulative_inst_count, '--o', color='#4b8262', linewidth=2)\n",
    "plt.xlabel('Instance\\'s length')\n",
    "plt.ylabel('Cumulative % of stack trace instance')\n",
    "ax1.set_title('pt RQ2')\n",
    "\n",
    "# plt.vlines(x=5, ymin=60, ymax=95, color='red')\n",
    "\n",
    "# plt.text(5.5, 65, 'sentence', rotation=0)\n",
    "ax1.axis(ymin=0, ymax=102)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42ac2495-df65-4f9b-a88d-c2fc13e51d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x420 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize =(10, 6), dpi=70)\n",
    "ax.barh(list(inst_length), inst_count, align='center', alpha=0.5, log=True)\n",
    "\n",
    "for i in ax.patches:\n",
    "    plt.text(i.get_width()+0.2, i.get_y()+0.3,\n",
    "             str(round((i.get_width()), 2)),\n",
    "             fontsize = 10, fontweight ='bold',\n",
    "             color ='grey')\n",
    "\n",
    "# Add Plot Title\n",
    "ax.set_title('The frequency of stack trace intances for each instance\\'s length',loc ='center')\n",
    "# ax.set_yticks(y_pos, objects)\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Instance\\'s length')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8dc6b-c1d8-45fc-a851-184118ca1a3a",
   "metadata": {},
   "source": [
    "### Approach (4): CC-Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87d8aea6-501b-4a56-98ea-2cdad58ed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dicc_new(dicc, vec_id, list_):\n",
    "    if vec_id not in dicc:\n",
    "        # key not exist\n",
    "        dicc[vec_id] = list_\n",
    "    else:\n",
    "        # key exist\n",
    "        for tuple_ in list_:\n",
    "            for item in dicc[vec_id]:\n",
    "                if item[0] == tuple_[0]:\n",
    "                    item[1].append(tuple_[1][0])\n",
    "                    break\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8570828-2fb9-4945-b5df-70c17a4ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f9370071-2ec9-4fbb-8b33-8e66e38b8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching Pattern\n",
    "low = 1     # <~~~~~~~ define the lower bound threshold\n",
    "up = len(uniqe_dic)\n",
    "dicc = {}     \n",
    "\n",
    "for i_v, vector in enumerate(_2D_array):    \n",
    "    for index, element in enumerate(vector):\n",
    "        list_ = []\n",
    "        for wind_size in range(low, len(vector)+1-index):\n",
    "            list_.append((wind_size, [(*vector[index:index+wind_size], )]))\n",
    "        dicc = append_to_dicc_new(dicc, i_v, list_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a64a3b0e-ffa9-4999-96cf-5bdc766df1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting\n",
    "def remove_duplication(dup_list):\n",
    "    final_list = []\n",
    "    for item in dup_list:\n",
    "        if item not in final_list:\n",
    "            final_list.append(item)\n",
    "        else:\n",
    "            indx = final_list.index(item)\n",
    "            counter = final_list[indx][0] + 1\n",
    "            pair = final_list[indx][1]\n",
    "            final_list.remove(item)\n",
    "            final_list.append((counter, pair))\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca4b370c-9b01-4e16-a3a6-a7a58bc463e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_count = {}\n",
    "\n",
    "for vec_i, list_tuples in dicc.items():\n",
    "#     print(vec_i, list_tuples,\"\\n\")\n",
    "    for tuples_ in list_tuples:\n",
    "#         print(tuples_)\n",
    "        \n",
    "        if tuples_[0] not in dic_count:\n",
    "            lst_ = [(1, tuple_) for tuple_ in tuples_[1]] \n",
    "            \n",
    "            if len(lst_) != len(set(lst_)):\n",
    "                lst_ = remove_duplication(lst_)\n",
    "            \n",
    "            dic_count[tuples_[0]] = lst_  \n",
    "        else:\n",
    "            #(2, [(1, 3), (1, 4), (3, 4), (4, 5), (5, 1)]\n",
    "            #break\n",
    "            for tuple_ in tuples_[1]:\n",
    "                flag = 0 \n",
    "                for item in dic_count[tuples_[0]]:\n",
    "                    if item[1] == tuple_:\n",
    "                        counter = item[0] + 1\n",
    "                        dic_count[tuples_[0]].remove(item)\n",
    "                        dic_count[tuples_[0]].append((counter, item[1]))\n",
    "                        flag = 1\n",
    "                        break\n",
    "                # tuple is new\n",
    "                if flag == 0:\n",
    "                    dic_count[tuples_[0]].append((1, tuple_))\n",
    "#                 else: \n",
    "#                     print(\"Error100\")\n",
    "#     print(\"salam\", dic_count[2], \"\\n\\n\" )\n",
    "#     if vec_i == 1:\n",
    "#         break\n",
    "\n",
    "# _2d_array = [[1, 3, 4, 3, 4, 5, 1, 4],\n",
    "#              [1, 6, 3, 4, 5],\n",
    "#              [1, 2, 6, 3],\n",
    "#              [6, 1, 3, 4, 5],\n",
    "#              [3, 4, 3, 6],\n",
    "#              [2, 3, 1, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb0c9fd7-b3c5-4e61-84bd-bd84f14b392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subsequence(needle: list, haystack: list) -> bool:\n",
    "    # >>> is_subsequence([2, 3, 4], [1, 2, 3, 4, 5, 6])\n",
    "    return any(\n",
    "        haystack[i:i+len(needle)] == needle\n",
    "        for i in range(len(haystack) - len(needle) + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "777e6228-2296-47e7-bc0a-aa9f658346a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen(dic_count: dict, threshold: int) -> list:\n",
    "    closed_list = []\n",
    "    for key, v_list in dic_count.items():\n",
    "        #print(key, v_list)\n",
    "        for item_tup in v_list:\n",
    "            tmp_flag = False\n",
    "            for key, v_list_search in dic_count.items():\n",
    "                for item_tup_search in v_list_search:\n",
    "                    #print(\"compare with: \", item_tup_search[1])\n",
    "                    if len(item_tup_search[1]) >= len(item_tup[1]) and is_subsequence(item_tup[1], item_tup_search[1]) and item_tup[1] != item_tup_search[1]:\n",
    "                        if item_tup[0] == item_tup_search[0]:\n",
    "                            tmp_flag = True\n",
    "            if not tmp_flag and item_tup[0] > threshold:\n",
    "\n",
    "                closed_list.append(item_tup)\n",
    "    return closed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dfbd276c-0735-4163-910b-27bd57d50fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70d292da-2e31-4ae1-9590-255586e51611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen_v2(dic_count: dict) -> list:\n",
    "    closed_list = []\n",
    "    flag_first_step = True\n",
    "    for win_size in list(reversed(list(dic_count))):\n",
    "        # Just add the last or the biggest window_size to the list \n",
    "        if flag_first_step:\n",
    "            flag_first_step = False\n",
    "            for item in dic_count[win_size]:\n",
    "                closed_list.append(item)\n",
    "            continue\n",
    "        \n",
    "        # For other window sizes\n",
    "        for item_tup_new in dic_count[win_size]:\n",
    "            flag_visit = False\n",
    "            for item_tup_old in closed_list:\n",
    "                if item_tup_new[0] == item_tup_old[0] and is_subsequence(item_tup_new[1], item_tup_old[1]):\n",
    "                    flag_visit = True\n",
    "                    break\n",
    "            if not flag_visit:\n",
    "                closed_list.append(item_tup_new)\n",
    "\n",
    "    return len(closed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cbc205ce-b533-4d9e-81c6-623cc7d67941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen_v3(dic_count: dict, threshold: int) -> list:\n",
    "    closed_list = []\n",
    "    removed_closed_list = []\n",
    "    flag_first_step = True\n",
    "    for win_size in list(reversed(list(dic_count))):\n",
    "        # Just add the last or the biggest window_size to the list \n",
    "        if flag_first_step:\n",
    "            for item in dic_count[win_size]:\n",
    "                if item[0] >= threshold:\n",
    "                    flag_first_step = False\n",
    "                    closed_list.append(item)\n",
    "                else:\n",
    "                    removed_closed_list.append(item)\n",
    "            continue\n",
    "        \n",
    "        # For other window sizes\n",
    "        for item_tup_new in dic_count[win_size]:\n",
    "            flag_visit = False\n",
    "            for item_tup_old in closed_list:\n",
    "                if item_tup_new[0] == item_tup_old[0] and is_subsequence(item_tup_new[1], item_tup_old[1]):\n",
    "                    flag_visit = True\n",
    "                    break  \n",
    "            if (not flag_visit) and (item_tup_new[0] >= threshold):\n",
    "                closed_list.append(item_tup_new)\n",
    "            else:\n",
    "                removed_closed_list.append(item_tup_new)\n",
    "\n",
    "    return closed_list, removed_closed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57c0af36-4426-4796-9124-a3fbffa9354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CloConSeqGen_v2(dic_count))\n",
    "# print(CloConSeqGen_v3(dic_count, 1))\n",
    "# print(CloConSeqGen_v3(dic_count, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "227bf25d-7b45-42cf-818e-d417cf39afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CloConSeqGen_v2(dic_count))\n",
    "# print(CloConSeqGen_v3(dic_count, threshold=1))\n",
    "# print(CloConSeqGen_v3(dic_count, threshold=1))\n",
    "# result, result_remove = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2f937-092d-4841-8a89-4e3a49f2ff2e",
   "metadata": {},
   "source": [
    "### Prepare data for support and pattern length when support is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6c02d3d2-9bfa-4b1e-b6e2-3d6b3dac5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, result_remove = CloConSeqGen_v3(dic_count, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "73955570-58a7-4ec8-af38-e5b1879fb691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3125"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "69eb864c-5179-4c3f-b5bb-142276ed3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the low and high boundries of CloConSeqGen_v3 result\n",
    "for element in result:\n",
    "    if result.index(element) == 0:\n",
    "        low = element[0] \n",
    "        high = element[0]\n",
    "        continue\n",
    "    if low > element[0]:\n",
    "        low = element[0]\n",
    "    elif high < element[0]:\n",
    "        high = element[0]\n",
    "        \n",
    "sorted_result = sorted(result, key=lambda tup: tup[0])\n",
    "\n",
    "sup_x = sorted(set([element[0] for element in result]))\n",
    "len_sup_y = []\n",
    "\n",
    "for sup in sup_x:\n",
    "    len_sup_y.append(len(sorted_result) - [y[0] for y in sorted_result].index(sup))\n",
    "    \n",
    "per_len_sup_y = [(x*100)/len_sup_y[0] for x in len_sup_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "05a0269f-32a3-4658-bf39-0c35a9285720",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tf_sup = {\"x\":sup_x, \"y\":per_len_sup_y}\n",
    "pickle.dump(dic_tf_sup, open(\"./Pickle_data/dic_pt_sup.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "413da7a7-3709-4598-adff-2cb27736f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size_list = []\n",
    "for element in result:\n",
    "    win_size_list.append(len(element[1]))\n",
    "win_size_set = set(win_size_list)\n",
    "counter=collections.Counter(win_size_list)\n",
    "\n",
    "counter = dict(sorted(counter.items()))\n",
    "comulative_y = np.cumsum(list(counter.values()))\n",
    "\n",
    "per_list_patterns = []\n",
    "for element in comulative_y:\n",
    "    per_list_patterns.append((element*100)/comulative_y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fd4b44ab-229d-46f1-b6aa-5ecdc6e5e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tf_win = {\"x\":list(counter.keys()), \"y\":per_list_patterns}\n",
    "pickle.dump(dic_tf_win, open(\"./Pickle_data/dic_pt_win.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7326d16-125c-4a28-bf6c-0655ad8414c3",
   "metadata": {},
   "source": [
    "### Prepare data for support and pattern length when support is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "39a8dd67-f3d0-485c-9c3f-2fc8d7823bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, result_remove = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "827b1c72-a704-40d2-9727-01c506a5fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1787"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1e3d4c0f-ba07-4e4c-9989-dbc7d994c29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_num_string(input_list: list, unique_dic: dict) -> list:\n",
    "    convert_lst = []\n",
    "    for pattern in input_list:\n",
    "        string_pattern_tuple = ()\n",
    "        for item in pattern[1]:\n",
    "            string_pattern_tuple = string_pattern_tuple + (unique_dic[item],)\n",
    "        convert_lst.append((pattern[0], string_pattern_tuple))\n",
    "    return convert_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50098c2c-6d90-4eff-9cb5-1ce50862496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_sublist(lst_big: list, lst_small: list) -> bool:\n",
    "    return lst_small in [lst_big[i:len(lst_small)+i] for i in range(len(lst_big))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "446df13c-ce91-4a69-b600-85669f9141a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str = convert_num_string(result, uniqe_dic)\n",
    "assert len(result) == len(result_str), \"It should be the same.\"\n",
    "pattern_str_w_qid = []\n",
    "\n",
    "for pattern in result_str:\n",
    "    for q_id in _Id_array:\n",
    "        # assert not df_w_sklearn_tags.loc[df_w_sklearn_tags['Id'] == q_id].Bugy_py_files.empty, \"It's not possible!\"\n",
    "        exit_flag_q_id = False\n",
    "        \n",
    "        for item in df_w_pt_tags['Bugy_py_files'].to_numpy()[df_w_pt_tags['Id'].to_numpy() == q_id].item()[1]:\n",
    "           \n",
    "            if order_sublist(item, list(pattern[1])):\n",
    "                # pattern_str_w_qid.append((pattern[0], pattern[1]))\n",
    "                \n",
    "                exist = False\n",
    "                for ele in pattern_str_w_qid:\n",
    "                    if ele[1] == pattern[0] and ele[2] == pattern[1]:\n",
    "                        exist = True\n",
    "                        ele[0].append(q_id)\n",
    "                        \n",
    "                        if len(ele[0]) ==  pattern[0]: exit_flag_q_id = True\n",
    "                if not exist:\n",
    "                    pattern_str_w_qid.append((list([q_id]), pattern[0], pattern[1]))\n",
    "                    if pattern[0] == 1: exit_flag_q_id = True\n",
    "        \n",
    "        if exit_flag_q_id: break\n",
    "            \n",
    "    # print(\"\\n\\n\")\n",
    "pickle.dump(pattern_str_w_qid, open(\"./Pickle_data/pt_ccspan_2_result_pure.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "722f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_patterns(patterns_lst: list, top: int) -> list:\n",
    "    assert top != 0, \"The top value is wrong!\"\n",
    "    top_list = []\n",
    "    support_set = set()\n",
    "    \n",
    "    # Find the support list\n",
    "    for pattern in patterns_lst:\n",
    "        support_set.add(pattern[0])\n",
    "        \n",
    "    top_support_list = sorted(list(support_set))[0:top]\n",
    "    \n",
    "    for pattern in patterns_lst:\n",
    "        if pattern[0] in top_support_list:\n",
    "            top_list.append(pattern)\n",
    "            \n",
    "    return top_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a455b92-37e7-4d77-8ea1-4312b0a48faf",
   "metadata": {},
   "source": [
    "The below function based on the dic_count dictionary trys to find x top patterns for each window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d07908ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pattern_num = get_top_patterns(result, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3fa153b3-af93-4c74-907f-36fefcce2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_pattern_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7279c556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_num_string(input_list: list, unique_dic: dict) -> list:\n",
    "    convert_lst = []\n",
    "    for pattern in input_list:\n",
    "        string_pattern_tuple = ()\n",
    "        for item in pattern[1]:\n",
    "            string_pattern_tuple = string_pattern_tuple + (unique_dic[item],)\n",
    "        convert_lst.append((pattern[0], string_pattern_tuple))\n",
    "    return convert_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82bce5-7af6-4782-b604-28cfe546b864",
   "metadata": {},
   "source": [
    "The below code converts the number pairs to the string pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d86e89e0-774f-4435-99cf-1b1f6cbbb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pattern_str = convert_num_string(top_pattern_num, uniqe_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f4c8d3ff-a0b4-4464-ba4e-80170401506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_pattern_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdac07b-dca6-4c30-9d08-786f01535355",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Find the Id of a post based on its pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "314c9c2e-1104-466f-ae09-ffb379fbc9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(_2D_array_with_str) == len(_2D_array), \"Always should be the same.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f4fff9b0-4939-474b-9db2-03740e518292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2089, 1787)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_Id_array), len(result)\n",
    "# , _Id_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4795d690-d2e1-4f04-b37a-8f0eab767651",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, result_remove = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "760ea42e-7bf6-4a7e-9282-6dd41f52c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_id_based_on_str_pattern(total_IDs: list, pattern_str_lst: list) -> dict:\n",
    "    dict_pattern_and_qid = {}\n",
    "    \n",
    "    for pattern in pattern_str_lst:\n",
    "        for q_id in total_IDs:\n",
    "            # assert not df_w_pt_tags.loc[df_w_pt_tags['Id'] == q_id].Bugy_py_files.empty, \"It's not possible!\"\n",
    "\n",
    "            for item in df_w_pt_tags['Bugy_py_files'].to_numpy()[df_w_pt_tags['Id'].to_numpy() == q_id].item()[1]:\n",
    "\n",
    "                if order_sublist(item, list(pattern[1])):\n",
    "                    pattern_tpl = (*pattern[1], )\n",
    "                    if pattern_tpl not in dict_pattern_and_qid.keys():\n",
    "                        dict_pattern_and_qid[pattern_tpl] = set({q_id})\n",
    "                    else:\n",
    "                        dict_pattern_and_qid[pattern_tpl].add(q_id)\n",
    "    return dict_pattern_and_qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af140a17-af6e-40a5-a774-a111c2db2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_number(dict_pattern_and_qid: dict) -> int:\n",
    "    q_total_set = set({})\n",
    "    \n",
    "    for key, value in dict_pattern_and_qid.items():\n",
    "        # print(value)\n",
    "        q_total_set.update(value)\n",
    "\n",
    "    return len(q_total_set), q_total_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d8345bd6-b985-49e1-a114-0f5b7accbe53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703\n"
     ]
    }
   ],
   "source": [
    "dict_pattern_and_qid = find_q_id_based_on_str_pattern(_Id_array, convert_num_string(result, uniqe_dic))\n",
    "q_total_set_len, q_total_sett  = get_q_number(dict_pattern_and_qid)\n",
    "print(q_total_set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5074b1-ea39-4121-841c-b147b04e6cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst_q_id_has_pattern = []\n",
    "for top_pattern in top_pattern_str:\n",
    "    # print(\"Pattern(small set): \\t\", top_pattern[1])\n",
    "    for q_id in _Id_array:\n",
    "        # print(q_id)\n",
    "        assert not df_w_pt_tags.loc[df_w_pt_tags['Id'] == q_id].Bugy_py_files.empty, \"It's not possible!\"\n",
    "        \n",
    "        for item in df_w_pt_tags['Bugy_py_files'].to_numpy()[df_w_pt_tags['Id'].to_numpy() == q_id].item()[1]:\n",
    "        # for item in df_w_pt_tags.loc[df_w_pt_tags['Id'] == q_id].Bugy_py_files.values[0][1]:\n",
    "            # print(\"Big set: \\t\", item)\n",
    "            if order_sublist(item, list(top_pattern[1])):\n",
    "                # print(\"Big Set: \\t\", item)\n",
    "                # print(\"Small Set: \\t\", list(top_pattern[1]))\n",
    "                # print(\"\\n\\n\")\n",
    "                lst_q_id_has_pattern.append(q_id)\n",
    "    # print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23791a-9002-46e6-aeb8-2d6b65bb6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lst_q_id_has_pattern, \"It not should be empty.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60bb8a-137e-4bc5-89e3-6bc3c180c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern = df_w_pt_tags.loc[df_w_pt_tags['Id'].isin(lst_q_id_has_pattern)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62807f4-5baf-4a4e-9b22-5e5a030e5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern.rename(columns = {'Id':'Q_id', 'CreationDate':'Q_create_time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc07a5-f62c-488d-b873-b22c99368924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"pt_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58c7cb-163b-4c69-a8ef-d51ec98d694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_w = pd.merge(df_pattern, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"ViewCount\", \"CommentCount\", \"Score\", \"AnswerCount\", \"AcceptedAnswerId\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "df_pattern_ans = pd_tmp_new_w[pd_tmp_new_w.AnswerCount != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e8a96-1d56-4914-b24a-77278e0eb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans = df_pattern_ans[df_pattern_ans.AcceptedAnswerId > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1b206-dfda-47ed-9469-06dc34e4d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_patt_ans(lst_ans_id_1, lst_ans_id_2):\n",
    "    assert set(lst_ans_id_1) == set(lst_ans_id_2), \"We couldn't find all answers.\"\n",
    "    assert len(lst_ans_id_1) == len(lst_ans_id_2), \"The length of answer lists are not the same.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6b524-d003-41d2-a51d-7b36e1306f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_patt_ans(df_pattern_ans.AcceptedAnswerId, df_pattern[df_pattern.AcceptedAnswerId > 0].AcceptedAnswerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f97050-f8ad-4ac2-8339-7f1addc3f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans.insert(len(df_pattern_ans.columns), 'First_ans_time', np.nan)\n",
    "df_pattern_ans.insert(len(df_pattern_ans.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb3a82-8e38-4310-a2ed-1c89601e205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_the_answers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for index1, row_status in df.iterrows():   \n",
    "        flag = 0\n",
    "        fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "        acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "\n",
    "        if not row_status[\"Answer_tup\"]:\n",
    "            pd_tmp_new3_w.at[index1,'First_ans_time'] = np.nan\n",
    "            pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = np.nan\n",
    "            continue\n",
    "\n",
    "        for answer in row_status[\"Answer_tup\"]:\n",
    "\n",
    "            anwer_time = pd.to_datetime(answer[1])\n",
    "\n",
    "            if flag == 0:\n",
    "                fr_time = anwer_time\n",
    "                flag = 1\n",
    "\n",
    "            if fr_time > anwer_time:\n",
    "                fr_time = anwer_time\n",
    "\n",
    "            if row_status[\"AcceptedAnswerId\"] == answer[0]:\n",
    "                acc_time = anwer_time\n",
    "\n",
    "        df.at[index1,'First_ans_time'] = fr_time\n",
    "\n",
    "        if pd.isna(row_status[\"AcceptedAnswerId\"]):\n",
    "            acc_time = np.nan\n",
    "\n",
    "        df.at[index1,'First_acc_ans_time'] = acc_time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ceb7d8-c5bc-44eb-815b-b3ebd36a92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans = assign_the_answers(df_pattern_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce318475-189c-4af8-9566-054f69be6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans[\"Q_create_time\"]      = pd.to_datetime(df_pattern_ans[\"Q_create_time\"])\n",
    "df_pattern_ans[\"First_acc_ans_time\"] = pd.to_datetime(df_pattern_ans[\"First_acc_ans_time\"])\n",
    "df_pattern_ans[\"First_ans_time\"]     = pd.to_datetime(df_pattern_ans[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bf41c-e69c-4e36-bbdd-b95db19b00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans[\"Duration_ans\"] = df_pattern_ans.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "df_pattern_ans[\"Duration_acc_ans\"] = df_pattern_ans.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4dc3e2-21f2-421d-8432-9acad1c4fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661abcc-2375-4a2d-ac90-bed22f468e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=['Index', 'Q_id', 'Title', 'OS', '# ST-Post', '# ST', 'Link'])\n",
    "\n",
    "for _indx, row in df_pattern.iterrows():\n",
    "    _c = 0\n",
    "    for item in row.Bugy_py_files[1]:\n",
    "        _c += len(item)\n",
    "    _link = \"https://stackoverflow.com/questions/\" + str(row.Q_id)\n",
    "    tmp_dic = {'Index': _indx+1, 'Q_id': row.Q_id, 'Title': row.Title, 'OS': row.Bugy_py_files[0], '# ST-Post': len(row.Bugy_py_files[1]), '# ST': _c, 'Link': _link}\n",
    "    df2 = pd.DataFrame(tmp_dic, index={len(tmp_dic)+1})\n",
    "    df_result = pd.concat([df_result, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf331b-860e-4f6a-91bc-57c99ab10afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/\\\\]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\s\\W*\\d*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?\\/?([^\\<\\>\\:\\\"\\\\\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "# https://regex101.com/r/5yCAdA/1   Unix\n",
    "# https://regex101.com/r/50Vcmo/1 Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139b576-02c8-4019-9829-c5387d7464aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "df_pattern.loc[df_pattern.Q_id == 54219826].Bugy_py_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b8cd9-ab58-4448-a5f6-15b0fb6cb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern.loc[df_pattern.Q_id == 54219826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766c065-c694-422e-b157-19a55f52f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_id_has_trace_wo_err_mess = []\n",
    "c_has_trace   = 0\n",
    "c_has_err_mes = 0\n",
    "\n",
    "def extract_error_messages(id: int, Has_code: bool, Has_trace: bool, code_sec: List) -> Optional[List]:\n",
    "    try:\n",
    "        global lst_id_has_trace_wo_err_mess, c_has_trace, c_has_err_mes\n",
    "        \n",
    "        if Has_trace: c_has_trace += 1\n",
    "        # if not (Has_trace and Has_code): print(f\"Error (2): It's not possiable. Has_code: {Has_code}, Has_trace: {Has_trace}\")\n",
    "            \n",
    "        result_total = []\n",
    "        \n",
    "        for code in code_sec:\n",
    "            # regex = r\"([A-Z]\\w+(Error|Warning|Exception))([^:]*):\\s(.*)$\"\n",
    "            # V3\n",
    "            regex = r\"^([A-Z]\\w+Error)(\\w|\\s|\\(|\\)|\\d)*:\\s(.*)$\"\n",
    "            # regex = r\"([A-Z]\\w+Error):\\s(.*)$\"\n",
    "            code = code.replace(\"\\\\n\", \"\\n\")\n",
    "            code = code.replace('&lt;', '<')\n",
    "            code = code.replace('&gt;', '>')\n",
    "            code = code.replace('&quot;', '\"')\n",
    "            matches = re.finditer(regex, code, re.MULTILINE)\n",
    "            result_each_code_part = []\n",
    "\n",
    "            for matchNum, match in enumerate(matches, start=1):\n",
    "                result_each_code_part.append((match.groups()[0].strip(), match.groups()[2].strip()))\n",
    "            \n",
    "            if result_each_code_part:   # Ignore the empty list\n",
    "                result_total.append(result_each_code_part)\n",
    "\n",
    "        if (not result_total) and Has_trace: \n",
    "            # print(\"Warning!: We have to check this is ID: \", id)\n",
    "            lst_id_has_trace_wo_err_mess.append(id)\n",
    "        \n",
    "        if result_total:\n",
    "            c_has_err_mes += len(result_total)\n",
    "            \n",
    "        return result_total\n",
    "    \n",
    "    except:\n",
    "        print(\"Error(1): \", id)\n",
    "        print(code_sec)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3133ee-8feb-4741-9663-10ba2d5aae6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pattern[\"Err_msg\"] = df_pattern.apply(lambda row: extract_error_messages(row.Q_id, row.Has_code, row.Has_trace, row.Code), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf43e9-7d3c-485a-9a1f-0a2d5da10956",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We captured {c_has_trace} stack traces, however {c_has_trace-len(lst_id_has_trace_wo_err_mess)} stacktraces have a one type of error messages. I mean, {len(lst_id_has_trace_wo_err_mess)} stack traces didn't have any error message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34043-59ca-49ec-add3-929367024323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_pattern[df_pattern['Err_msg'].map(lambda err_msg_list: len(err_msg_list)) > 0]\n",
    "df_tmp.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609acf2-489e-42c5-bd10-dcebd3796e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg = pd.DataFrame(columns=['Q_id', 'ErrorType', 'ErrorMessage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bcfba-7be1-46f4-95b9-6a44c09d9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_extractor(msg_q_id: str, msg_list: list) -> None:\n",
    "    global df_pattern_err_msg\n",
    "    for msg_t in msg_list:\n",
    "        for message in msg_t:\n",
    "            df_pattern_err_msg = pd.concat([df_pattern_err_msg, pd.DataFrame.from_records([{'Q_id': msg_q_id, 'ErrorType': message[0], 'ErrorMessage': message[1]}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13526342-f7cf-43a0-b013-5acd281f3038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = df_tmp.apply(lambda row: message_extractor(row.Q_id, row.Err_msg), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfe0ce-8a87-473e-bc51-b06e22ca6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d6c77-2c1a-462a-bf95-3e7aec229d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010615a-39a7-4a9b-b211-565e51094f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all the elements are string\n",
    "df_pattern_err_msg = df_pattern_err_msg.applymap(str)\n",
    "\n",
    "# Notice: strip() function will remove leading and trailing whitespaces.\n",
    "df_pattern_err_msg['ErrorType'] = df_pattern_err_msg['ErrorType'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898083b2-8efa-4536-be80-156b6925b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP = 10\n",
    "df_tmp = df_pattern_err_msg.groupby(['ErrorType'])['ErrorType'].count().reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "df2 = df_tmp.iloc[:TOP]\n",
    "df2 = df2.append({'ErrorType': 'Other', 'count': df_tmp['count'].iloc[TOP:].sum()}, ignore_index=True)\n",
    "colors = ['tab:blue', 'tab:cyan', 'tab:gray', 'tab:orange', 'tab:red', 'burlywood', 'y']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "patches, texts, pcts =  ax.pie(df2.set_index('ErrorType')['count'],\n",
    "                               labels=df2['ErrorType'],\n",
    "                                autopct='%1.1f%%', \n",
    "                                pctdistance=0.7, \n",
    "                                labeldistance=1.1, \n",
    "                                # textprops={'fontsize': 12},\n",
    "                                textprops={'size': 'x-large'},\n",
    "                                colors=colors,\n",
    "                                wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'},)\n",
    "\n",
    "s = df2.groupby('ErrorType')['count'].sum().map(lambda x : x).sort_values(ascending = False)\n",
    "labels = [f'{name}, {percentage*100:0.1f}%' for name, percentage in zip(s.index, s / s.sum())]\n",
    "ax.legend(bbox_to_anchor=(1.2, 1), \n",
    "           loc='upper left', \n",
    "           # labels=labels,\n",
    "           title=\"Error Types\",\n",
    "           # labelcolor=colors,\n",
    "           fontsize=14)\n",
    "\n",
    "\n",
    "plt.setp(pcts, color='white', fontweight='bold')\n",
    "ax.set_title(\"pt Error Distribution\", fontsize=18)\n",
    "for i, patch in enumerate(patches):\n",
    "    texts[i].set_color(patch.get_facecolor())\n",
    "    \n",
    "plt.setp(texts, fontweight=600)\n",
    "\n",
    "ax.axis('equal')  \n",
    "# plt.tight_layout()\n",
    "# ax.figure.savefig('piechart.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd039f6a-c399-4022-b617-f3c029525e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frequency of each message type\n",
    "print(df_pattern_err_msg.groupby(['ErrorType'])['ErrorType'].count().reset_index(name='count').sort_values(['count'], ascending=False).nlargest(20, 'count'))\n",
    "df_pattern_err_msg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469d64-2c15-4fa9-81df-790273d8e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score median: \", df_pattern.Score.median())\n",
    "print(\"View median: \", df_pattern.ViewCount.median())\n",
    "print(\"Answer_count median: \", df_pattern.AnswerCount.median())\n",
    "print(\"Comment median: \", df_pattern.CommentCount.median())\n",
    "print(\"# Accepted answer:\", df_pattern.AcceptedAnswerId.count(), \"  Total Accepted answer:\", df_pattern.AcceptedAnswerId.shape[0], \"  Percentage of Accepted answer:\", \"{:.2f}\".format(df_pattern.AcceptedAnswerId.count() *100 / df_pattern.AcceptedAnswerId.shape[0]))\n",
    "print(\"LOC median: \", (df_pattern[df_pattern.Has_trace == True].Line_code_win + df_pattern[df_pattern.Has_trace == True].Line_code_uix).median())\n",
    "print(\"LOP median: \", df_pattern.Q_text_words_num.median())\n",
    "print(\"Answer duration median: \", \"{:.2f}\".format(df_pattern_ans.Duration_ans.median()))\n",
    "print(\"Accepted Answer duration median: \", \"{:.2f}\".format(df_pattern_ans.Duration_acc_ans.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130682a1-c135-4957-aac8-e4f9af3deed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg.Q_id = df_pattern_err_msg.Q_id.astype(int)\n",
    "df_result.Q_id = df_result.Q_id.astype(int)\n",
    "df_result_mrg = pd.merge(df_pattern_err_msg, df_result, on=[\"Q_id\"], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25154-9b96-4755-a17c-b3ad44a30f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# print(tabulate(df_pattern_err_msg, headers='keys', tablefmt='psql', showindex=False))\n",
    "# print(tabulate(df_result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da919845-8275-4d7d-9f18-004ae0b6679e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    @param filename: File path or existing ExcelWriter\n",
    "                     (Example: '/path/to/file.xlsx')\n",
    "    @param df: DataFrame to save to workbook\n",
    "    @param sheet_name: Name of sheet which will contain DataFrame.\n",
    "                       (default: 'Sheet1')\n",
    "    @param startrow: upper left cell row to dump data frame.\n",
    "                     Per default (startrow=None) calculate the last row\n",
    "                     in the existing DF and write to the next row...\n",
    "    @param truncate_sheet: truncate (remove and recreate) [sheet_name]\n",
    "                           before writing DataFrame to Excel file\n",
    "    @param to_excel_kwargs: arguments which will be passed to `DataFrame.to_excel()`\n",
    "                            [can be a dictionary]\n",
    "    @return: None\n",
    "\n",
    "    Usage examples:\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df)\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df, header=None, index=False)\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df, sheet_name='Sheet2',\n",
    "                           index=False)\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df, sheet_name='Sheet2', \n",
    "                           index=False, startrow=25)\n",
    "\n",
    "    (c) [MaxU](https://stackoverflow.com/users/5741205/maxu?tab=profile)\n",
    "    \"\"\"\n",
    "    # Excel file doesn't exist - saving and exiting\n",
    "    if not os.path.isfile(filename):\n",
    "        df.to_excel(\n",
    "            filename,\n",
    "            sheet_name=sheet_name, \n",
    "            startrow=startrow if startrow is not None else 0, \n",
    "            **to_excel_kwargs)\n",
    "        return\n",
    "    \n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace')\n",
    "\n",
    "    # try to open an existing workbook\n",
    "    writer.book = load_workbook(filename)\n",
    "    \n",
    "    # get the last row in the existing Excel sheet\n",
    "    # if it was not specified explicitly\n",
    "    if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "        startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "    # truncate sheet\n",
    "    if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "        # index of [sheet_name] sheet\n",
    "        idx = writer.book.sheetnames.index(sheet_name)\n",
    "        # remove [sheet_name]\n",
    "        writer.book.remove(writer.book.worksheets[idx])\n",
    "        # create an empty sheet [sheet_name] using old index\n",
    "        writer.book.create_sheet(sheet_name, idx)\n",
    "    \n",
    "    # copy existing sheets\n",
    "    writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78596f0f-6163-442d-98ca-a7327e1a0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result_mrg.drop(\"Index\", axis=1, inplace=True)\n",
    "# df_result_mrg.to_excel(\"../Emp_st_p_1.xlsx\", sheet_name='pt') \n",
    "# df_result_mrg.drop(\"Index\", axis=1, inplace=True)\n",
    "append_df_to_excel(\"../Emp_st_p_1.xlsx\", df_result_mrg, sheet_name='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b4d58-307c-46b5-9b7a-51db062db2f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create covered question plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196f392-af34-4ef3-8a52-b3132b5b25b5",
   "metadata": {},
   "source": [
    "Create the x-axist: sorted based on the support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f9cee-8321-490f-91f9-518113466814",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str = convert_num_string(result, uniqe_dic)\n",
    "len(result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f422b6-2eae-4289-87e1-d731349c1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str_rev_sorted = sorted(result_str, key=lambda tup: tup[0], reverse=True)\n",
    "x_number_of_patterns = list(range(1, len(result_str_rev_sorted)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039c428-c9b8-482f-bfce-03723bede3c8",
   "metadata": {},
   "source": [
    "Create the y-axist: % of coverd questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11efd163-6304-4ecf-ad8c-e68732e9a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_unique_questions, set_of_unique_questions = get_q_number(dict_pattern_and_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc17a37-85bd-486c-bd69-5160b8c53372",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_questions = set()\n",
    "y_axis_peresentage_of_coverage = []\n",
    "for support, pattern in result_str_rev_sorted:    \n",
    "    visited_questions.update(dict_pattern_and_qid[pattern])\n",
    "    if len(visited_questions) < len(set_of_unique_questions):\n",
    "        y_axis_peresentage_of_coverage.append(len(visited_questions)*100/len(set_of_unique_questions))\n",
    "    elif len(visited_questions) > len(set_of_unique_questions):\n",
    "        print(\"Error(100)!\")\n",
    "    elif len(visited_questions) == len(set_of_unique_questions):\n",
    "        y_axis_peresentage_of_coverage.append(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6115f3c-d88e-4bd3-8a60-22f6c2cc74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=110)\n",
    "\n",
    "ax.plot(x_number_of_patterns, y_axis_peresentage_of_coverage, '-', color='green', linewidth=2)\n",
    "\n",
    "ax.set_title('PyTorch', fontname=\"Times New Roman\", fontsize=16)\n",
    "\n",
    "ax.set_xlabel('The number of patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(range(1, max(x_number_of_patterns)+1, 50))\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.set_ylabel('The percentage of covered questions', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, 101, 10))\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('sp_le_rq1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ac2d3-d78f-42e8-b309-344791a920ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dic_pt_covered_ques = {\"x\":x_number_of_patterns, \"y\":y_axis_peresentage_of_coverage}\n",
    "pickle.dump(plt_dic_pt_covered_ques, open(\"./Pickle_data/plt_dic_pt_covered_ques.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bc342",
   "metadata": {},
   "source": [
    "## Answer time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448de367",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Answer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b763dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pure_ans_data = working_directory_path + \"ansSample.csv\"\n",
    "# path_ans = Path(pure_ans_data)\n",
    "\n",
    "# if path_ans.suffix == \".csv\":\n",
    "#     df_ans = pd.read_csv(path_ans, encoding=encoding)\n",
    "# else:\n",
    "#     raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf259d-561a-4487-9908-da7e4da40191",
   "metadata": {},
   "source": [
    "## Create DF based on the questions contain stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_info\"] = Question_with_trace_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_with_trace_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_id\"]          = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_status_w_stack[\"Q_create_time\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_status_w_stack[\"View_count\"]    = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_status_w_stack[\"Answer_count\"]  = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_status_w_stack[\"Comment_count\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_status_w_stack[\"Score\"]         = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_status_w_stack[\"Accepted_Answer_id\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28deb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack = df_status_w_stack.drop(['Q_info'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_create_time\"]      = pd.to_datetime(df_status_w_stack[\"Q_create_time\"])\n",
    "df_status_w_stack[\"First_acc_ans_time\"] = pd.to_datetime(df_status_w_stack[\"First_acc_ans_time\"])\n",
    "df_status_w_stack[\"First_ans_time\"]     = pd.to_datetime(df_status_w_stack[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd1bbb",
   "metadata": {},
   "source": [
    "#### Filling the Answers column: A list contains the id and time of answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7d931-c4d3-492a-8276-abc6de000ea3",
   "metadata": {},
   "source": [
    "We have to prepare and find answers that has sp parrentID, so first we catch the questions and store as table in DB. Before this job we have to create a table with all answrs and apply inner join to those tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8093c-3c26-4d31-adab-ad1c4bd66959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_id\"].to_csv('../code_output_csv/df_pt_w_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61f7376f-6f99-46ba-ac0e-296c646279bd",
   "metadata": {},
   "source": [
    "SELECT df_pt_w_stack.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_pt_w_stack\n",
    "INNER JOIN all_results\n",
    "ON df_pt_w_stack.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bf191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"pt_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4de2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_status_w_stack['Answers'] = df_status_w_stack.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9770ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index1, row_status in df_status_w_stack.iterrows():\n",
    "#     for index2, row_night in df_night.iterrows():\n",
    "#             if row_night[\"ParentId\"] == row_status[\"Q_id\"]:\n",
    "#                     row_status['Answers'].append((row_night[\"Id\"], row_night[\"CreationDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e9b00-b12d-498a-a816-9284be6bf1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3732d4c-0d2b-4cfa-9cd3-c1ad1472244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_w = pd.merge(df_status_w_stack, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new2_w = pd_tmp_new_w[pd_tmp_new_w.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack[\"Answers\"] = df_status_w_stack[\"Answers\"].apply(lambda answers_list: list(set(answers_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checker_1(i, answers_list, answers_count):\n",
    "#     global counter\n",
    "#     if len(answers_list) != answers_count:\n",
    "#         print(\"Error \", i, len(answers_list), answers_count)\n",
    "\n",
    "# def checker_ans_and_ans_tup(row_indx: int, ans_count: int, ans_list: list) -> None:\n",
    "#     if len(ans_list) != ans_count:\n",
    "#         print(\"Error!: \", row_indx, ans_count, ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2f339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_status_w_stack.apply(lambda row: checker_1(row.name, row.Answers, row.Answer_count), axis=1)\n",
    "_ = pd_tmp_new2_w.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735f1d5-381b-454f-b369-0968480dfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7019b-2ab6-4088-91ac-ad6ae20eceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w = pd_tmp_new2_w.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a596f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_w.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_w.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_w.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = acc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847107e7",
   "metadata": {},
   "source": [
    "Write df_status_w_stack to the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.to_csv('./status_PT_df_w_stack_with_list_of_answers_col.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4253bbc",
   "metadata": {},
   "source": [
    "Read df_status_w_stack from the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f760c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack = pd.read_csv('./status_df_w_stack_with_list_of_answers_col.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a424d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack[\"Duration_ans\"] = df_status_w_stack.apply(lambda row: (row.First_ans_time-row.Q_create_time).days, axis=1)\n",
    "# df_status_w_stack[\"Duration_acc_ans\"] = df_status_w_stack.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).days, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_acc_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new3_w['Duration_ans'] = pd_tmp_new3_w['Duration_ans'].fillna(0)\n",
    "# pd_tmp_new3_w['Duration_acc_ans'] = pd_tmp_new3_w['Duration_acc_ans'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d09fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19800ec",
   "metadata": {},
   "source": [
    "## Create DF based on the questions do not have stack traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57682814-ce03-41e4-88d5-1ed524f79811",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have to prepare and find answers that has Pytorch parrentID, so first we catch the questions and store as table in DB. Before this job we have to create a table with all answrs and apply inner join to those tables:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ece49f68-9d28-4236-957e-0a98cd01b9f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "SELECT df_pt_wo_stack.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_pt_wo_stack\n",
    "INNER JOIN all_results\n",
    "ON df_pt_wo_stack.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f26363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"pt_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night_wo = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c567d8-93cd-488a-9715-2c3b6a011077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2258f0-f3e4-4a6a-99a1-9413d666c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195bf92-32fc-45a2-8560-d3e654b35132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_night_wo.drop_duplicates([\"Q_id\", \"Id\", \"ParentId\", \"CreationDate\"], ignore_index=False, inplace=True)\n",
    "df_night_wo = df_night_wo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_status_wo_stack[\"Q_info\"] = Question_with_wo_trace_info\n",
    "\n",
    "df_status_wo_stack[\"Q_id\"]          = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_status_wo_stack[\"Q_create_time\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_status_wo_stack[\"View_count\"]    = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_status_wo_stack[\"Answer_count\"]  = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_status_wo_stack[\"Comment_count\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_status_wo_stack[\"Score\"]         = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_status_wo_stack[\"Accepted_Answer_id\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[6])\n",
    "\n",
    "df_status_wo_stack = df_status_wo_stack.drop(['Q_info'], axis='columns')\n",
    "\n",
    "df_status_wo_stack[\"Q_create_time\"] = pd.to_datetime(df_status_wo_stack[\"Q_create_time\"])\n",
    "df_status_wo_stack[\"First_acc_ans_time\"] = pd.to_datetime(df_status_wo_stack[\"First_acc_ans_time\"])\n",
    "df_status_wo_stack[\"First_ans_time\"]     = pd.to_datetime(df_status_wo_stack[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a896da-2513-472b-8562-a80b6b4c9ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_status_wo_stack[\"Q_id\"].to_csv('../code_output_csv/df_pt_wo_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe64a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02caaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack['Answers'] = df_status_wo_stack.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dca9f-f50d-4844-8636-0c9163cb68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006ded-2978-4735-9e8d-1c6f818c5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca48d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # It is super time-consuming and never run!\n",
    "# for index1, row_status in df_status_wo_stack.iterrows():\n",
    "#     for index2, row_night in df_night_wo.iterrows():\n",
    "#         if row_night[\"ParentId\"] == row_status[\"Q_id\"]:\n",
    "#                 row_status['Answers'].append((row_night[\"Id\"], row_night[\"CreationDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd65ef-8327-4d89-b46a-0b6c9e701df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_wo = pd.merge(df_status_wo_stack, df_night_wo, how='left',left_on=['Q_id'],right_on=['ParentId']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4bb1c-c844-4fb1-b291-4a243d589c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_tmp_wo[\"Answer_tup\"] = pd_tmp_wo.apply(lambda x: (x.Id, x.CreationDate), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399421d6-ecc5-41bf-872d-52d39610d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new = pd_tmp.groupby([\"First_ans_time\", \"First_acc_ans_time\", \"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"])[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new_wo = pd_tmp_wo.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf8935-4cfb-4a8f-93ea-8a85965cf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo = pd_tmp_new_wo[pd_tmp_new_wo.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2018458-7fd9-4ca3-9da1-5714b03e3e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We checked all Q_id_x are unique\n",
    "_ = pd_tmp_new2_wo.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abeea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_wo_stack[\"Answers\"] = df_status_wo_stack[\"Answers\"].apply(lambda answers_list: list(set(answers_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdae5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_status_wo_stack.apply(lambda row: checker_1(row.name, row.Answers, row.Answer_count), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c2fbc-1102-4751-bb8f-8d7d484182fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f892ae5-e359-4a30-ae5e-255cc23ae8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb04af7-e1a0-459f-a6a9-220ec4df1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28955ecd-1434-4f76-bac1-6da683f872f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_wo = pd_tmp_new2_wo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_wo.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_wo.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_wo.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = acc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f34b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_wo[\"Duration_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_wo[\"Duration_acc_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1467f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new3_wo['Duration_ans'] = pd_tmp_new3_wo['Duration_ans'].fillna(0)\n",
    "# pd_tmp_new3_wo['Duration_acc_ans'] = pd_tmp_new3_wo['Duration_acc_ans'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac7769",
   "metadata": {},
   "source": [
    "### Find the durarion of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e7aaf-49d8-434f-93c2-1a5874830b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to delete rows or posts that doesn't have answer, because their zero values affect the meadian value (or the box plot values):\n",
    "# df_status_w_stack_filtered = pd_tmp_new3_wo[pd_tmp_new3_wo[\"Answer_count\"] > 0]\n",
    "# pd_tmp_new3_filtered = pd_tmp_new3_w[pd_tmp_new3_w[\"Answer_count\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33ac9d-d93f-423f-bec9-f1c38644a4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd_tmp_new3_w[[\"Q_create_time\", \"First_ans_time\", \"Answer_count\", \"Duration_ans\"]].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355b03d-d61b-4124-9ce2-7dddc08b253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w[[\"Q_create_time\", \"First_ans_time\", \"Answer_count\", \"Duration_ans\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d041705-edf2-43bf-a88e-45f9d3036f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.to_csv('./CSV_data/plt_df_pt_w_ans_stack.csv', encoding='utf-8')\n",
    "pd_tmp_new3_wo.to_csv('./CSV_data/plt_df_pt_wo_ans_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005c133-bf61-4d79-acc3-19f170740a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_w['Duration_ans']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_wo['Duration_ans']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "resultComment = pd.concat([df_1, df_2])\n",
    "resultComment['Type'] = \"First Answer\"\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_w['Duration_acc_ans']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_wo['Duration_acc_ans']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "resultAnswer = pd.concat([df_1, df_2])\n",
    "resultAnswer['Type'] = \"First Accepted Answer\"\n",
    "# ###################################################################################\n",
    "\n",
    "result = pd.concat([resultComment, resultAnswer], ignore_index=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Hours\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               # scale=\"count\",\n",
    "               # inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-5000,10000)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Answers Duration (pt Questions)')\n",
    "# fig.suptitle('TensorFlow Questions', prop={\"size\":10})\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb65388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Questions (with stack traces)', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_w['Duration_ans']\n",
    "df_1['Questions (with stack traces)'] = df_1['Questions (with stack traces)'].apply(lambda x: \"First Answer\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions (with stack traces)', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_w['Duration_acc_ans']\n",
    "df_2['Questions (with stack traces)'] = df_2['Questions (with stack traces)'].apply(lambda x: \"First Accepted Answer\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "\n",
    "# Reset index\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=result[\"Questions (with stack traces)\"], y=result[\"Hours\"])\n",
    "\n",
    "# plt.ylim(-250,500)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "# # min_ = min(min(df_status_w_stack['Duration_ans']), min(df_status_w_stack['Duration_acc_ans']))\n",
    "# # max_ = max(max(df_status_w_stack['Duration_ans']), max(df_status_w_stack['Duration_acc_ans']))\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# sns.violinplot(data=df_status_w_stack['Duration_ans'])\n",
    "# ax1.set_xlabel(\"First Answer\")\n",
    "# ax1.set_ylabel(\"Day\")\n",
    "# # ax1 = plt.ylim(min_,max_)\n",
    "\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# sns.violinplot(data=df_status_w_stack['Duration_acc_ans'])\n",
    "# ax2.set_xlabel(\"First Accepted Answer\")\n",
    "# ax2.set_ylabel(\"Day\")\n",
    "# # ax2 = plt.ylim(min_,max_)\n",
    "\n",
    "fig.suptitle('Answers Duration (with stack traces)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b540d9-50f5-4867-be9a-e13e9bd585ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Questions (W/O stack traces)', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_wo['Duration_ans']\n",
    "df_1['Questions (W/O stack traces)'] = df_1['Questions (W/O stack traces)'].apply(lambda x: \"First Answer\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions (W/O stack traces)', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_wo['Duration_acc_ans']\n",
    "df_2['Questions (W/O stack traces)'] = df_2['Questions (W/O stack traces)'].apply(lambda x: \"First Accepted Answer\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "\n",
    "# Reset index\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=result[\"Questions (W/O stack traces)\"], y=result[\"Hours\"])\n",
    "\n",
    "# plt.ylim(-250,500)\n",
    "\n",
    "fig.suptitle('Answers Duration (W/O stack traces)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd473e",
   "metadata": {},
   "source": [
    "## Statistics Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question Numbers with all ML tags: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac51430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question Numbers (with pt tags): \", df_w_pt_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817104d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question Numbers (without pt tags): \", df.shape[0] - df_w_pt_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pt Question Numbers (with code): \", count__question_w_code)\n",
    "print(\"pt Question Numbers (without code): \", count__question_wo_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356dcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pt Question Numbers (with code) have stack trace: \", count_w_t)  # 40 disappeared ?!\n",
    "print(\"pt Question Numbers (with code) that doesn't have stack trace: \",count_wo_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebaf5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"pt Question Numbers (with stack trace:) on Unix based systems: \", count_unix)\n",
    "print(\"pt Question Numbers (with stack trace:) on Windows based systems: \", count_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777daa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "line_count_unix   = 0\n",
    "line_count_win    = 0\n",
    "line_count_simple = 0\n",
    "\n",
    "for tuple in df_w_pt_tags[\"Line_code_u_w_s\"]:\n",
    "    line_count_unix   += tuple[0]\n",
    "    line_count_win    += tuple[1]\n",
    "    line_count_simple += tuple[2]\n",
    "        \n",
    "print(f\"The total number of line codes in the body part (w/o stack trace) is {line_count_simple}.\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_unix} (Unix-based reports).\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_win} (Windows-based reports).\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_unix+line_count_win}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13260028-8d85-4f82-8d22-ca47a7e5b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We found {max(dic.values())} unique pairs in stack traces posts related to the pt frameworks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d46d5-b096-40ca-83c2-f72897d7114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# print(\"Pst: \", '{:,}'.format(df_w_pt_tags.shape[0]), \"\\nPst_wc: \", math.ceil(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \"\\nPst_woc:\", 100-math.ceil(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \"\\nCB:\", '{:,}'.format(count__num_codes), \"\\nCB_ws:\", math.ceil(count_w_t*100/(count_w_t+count_wo_t)), \"\\nCB_wos:\", 100-(math.ceil(count_w_t*100/(count_w_t+count_wo_t))) , \"\\nST:\", '{:,}'.format(count_w_t), \"\\nU:\", math.ceil(count_unix*100/count_w_t), \"\\nW:\",100-math.ceil(count_unix*100/count_w_t))\n",
    "print(\"Pst: \", '{:,}'.format(df_w_pt_tags.shape[0]), \"\\nPst_wc: \", \n",
    "      '{0:0.2f}'.format(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \n",
    "      \"\\nPst_woc:\", '{0:0.2f}'.format(100-(count__question_w_code*100/(count__question_w_code+count__question_wo_code))), \n",
    "      \"\\nCB:\", '{:,}'.format(count__num_codes), \n",
    "      \"\\nCB_ws:\", '{0:0.2f}'.format(count_w_t*100/(count_w_t+count_wo_t)), \n",
    "      \"\\nCB_wos:\", '{0:0.2f}'.format(100-(count_w_t*100/(count_w_t+count_wo_t))) , \n",
    "      \"\\nST:\", '{:,}'.format(count_w_t), \n",
    "      \"\\nU:\", '{0:0.2f}'.format(count_unix*100/count_w_t), \n",
    "      \"\\nW:\",'{0:0.2f}'.format(100-(count_unix*100/count_w_t)))\n",
    "\n",
    "print( '{:,}'.format(df_w_pt_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \n",
    "      '& {0:0.1f}\\%'.format(100-(count__question_w_code*100/(count__question_w_code+count__question_wo_code))), \n",
    "      '& {:,}'.format(count__num_codes), \n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/(count_w_t+count_wo_t)), \n",
    "      '& {0:0.1f}\\%'.format(100-(count_w_t*100/(count_w_t+count_wo_t))) , \n",
    "      '& \\multicolumn{1}{r:}{\\\\textbf{', count_w_t, '}}',\n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/df_w_pt_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count_unix*100/count_w_t), \n",
    "      '& {0:0.1f}\\%'.format(100-(count_unix*100/count_w_t)))\n",
    "\n",
    "print( '{:,}'.format(df_w_pt_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \n",
    "      '& {:,}'.format(count__num_codes), \n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/(count_w_t+count_wo_t)), \n",
    "      '& \\multicolumn{1}{r:}{\\\\textbf{', count_w_t, '}}',\n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/df_w_pt_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count_unix*100/count_w_t), \n",
    "      '& {0:0.1f}\\%'.format(100-(count_unix*100/count_w_t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808f478-1be0-46aa-b0e3-81e90bbb5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w-ST:\", '{:,}'.format(count_w_t), \"wo-ST:\", '{:,}'.format(count_wo_t))\n",
    "ACC_W, ACC_WO = 87 , 69\n",
    "print('P1: {0:0.4f}'.format(ACC_W/count_w_t))\n",
    "print('N1: {}'.format(count_w_t))\n",
    "print('P2: {0:0.4f}'.format(ACC_WO/count_wo_t))\n",
    "print('N2: {}'.format(count_wo_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01a48e",
   "metadata": {},
   "source": [
    "## Graphical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f3688",
   "metadata": {},
   "source": [
    "### LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_wo_trace  = df_w_pt_tags[(df_w_pt_tags.Has_code == True) & (df_w_pt_tags.Has_trace == False)].Line_code_simple_code\n",
    "code_w_trace   = df_w_pt_tags[df_w_pt_tags.Has_trace == True].Line_code_win + df_w_pt_tags[df_w_pt_tags.Has_trace == True].Line_code_uix\n",
    "\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'LOC (in each question post)'])\n",
    "df_1['LOC (in each question post)'] = code_wo_trace\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"code blocks w/o stack trace\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'LOC (in each question post)'])\n",
    "df_2['LOC (in each question post)'] = code_w_trace\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"code blocks with stack trace\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "result.to_csv('./CSV_data/plt_df_loc_pt.csv', encoding='utf-8', index=False)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"LOC (in each question post)\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               # scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(-15, 100)\n",
    "# plt.xlim(-1, 1)\n",
    "\n",
    "fig.suptitle('Comparing the LOC between regular code and stack trace')\n",
    "\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":8})\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf06607",
   "metadata": {},
   "source": [
    "### Question Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198cd0c-00e6-4673-96e0-300b3dc0492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Words (in each question post)'])\n",
    "df_1['Words (in each question post)'] = list_num_words_wo_tra\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"w/o stack trace\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Words (in each question post)'])\n",
    "df_2['Words (in each question post)'] = list_num_words_w_tra\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"with stack trace\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aebb4b-37f8-4817-a1d3-a0d462cbad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./CSV_data/plt_df_ques_len_pt.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92381996",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Words (in each question post)\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(0, 300)\n",
    "# plt.xlim(-1, 1)\n",
    "\n",
    "fig.suptitle('Comparing the Question Length')\n",
    "\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":8})\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4fb36",
   "metadata": {},
   "source": [
    "### Plotting Score, View, Answer, Comment Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593359f-60ab-48a0-b48c-a93d7f61679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack.to_csv('./CSV_data/plt_df_pt_w_table3_stack.csv', encoding='utf-8')\n",
    "df_status_wo_stack.to_csv('./CSV_data/plt_df_pt_wo_table3_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sturges_rule_number(n_obser: int) -> int:\n",
    "    '''\n",
    "    Sturges Rule is the most common method for determining the optimal number of bins.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    n_obser : int\n",
    "        The total number of observations in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    Use   for returning a value: Symbols that mean ceiling  i.e. round the answer up to\n",
    "    the nearest integer.\n",
    "    '''\n",
    "    # return round(1 + math.log2(n_obser))\n",
    "    return round(np.ceil(1 + (3.322 * np.log10(n_obser))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('View Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nView Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['View_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['View_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='purple', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(False)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('View Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nView Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['View_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['View_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='purple', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=15)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['View_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['View_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(-2500,13000)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('View Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8319c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Answer Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nAnswer Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Answer_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Answer_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='g', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Answer Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nAnswer Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Answer_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Answer_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='g', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Answer_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Answer_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-.5,4.1)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Answer Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Comment Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nComment Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Comment_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Comment_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='b', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Comment Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nComment Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Comment_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Comment_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='b', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a20d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Comment_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Comment_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-1.1,10)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Comment Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d464c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Comment_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Comment_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "resultComment = pd.concat([df_1, df_2])\n",
    "resultComment['Type'] = \"Comment Count\"\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Answer_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Answer_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "resultAnswer = pd.concat([df_1, df_2])\n",
    "resultAnswer['Type'] = \"Answer Count\"\n",
    "# ###################################################################################\n",
    "# df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_1['Frequency'] = df_status_wo_stack['View_count']\n",
    "# df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "# df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_2['Frequency'] = df_status_w_stack['View_count']\n",
    "# df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "# resultView = pd.concat([df_1, df_2])\n",
    "# resultView['Type'] = \"View Count\"\n",
    "# ###################################################################################\n",
    "# df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_1['Frequency'] = df_status_wo_stack['Score']\n",
    "# df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "# df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_2['Frequency'] = df_status_w_stack['Score']\n",
    "# df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "# resultScore = pd.concat([df_1, df_2])\n",
    "# resultScore['Type'] = \"Score Count\"\n",
    "# ###################################################################################\n",
    "result = pd.concat([resultComment, resultAnswer], ignore_index=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-1,6)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('pt Questions')\n",
    "# fig.suptitle('TensorFlow Questions', prop={\"size\":10})\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Score Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nScore Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Score']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Score'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='orange', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Score Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nScore Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Score']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Score'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='orange', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Score']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Score']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-7,15)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Score Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf446f-652d-42ac-8a08-2f21e529a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2, result_remove2 = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9f7a0-c19e-4bcb-99bb-ba7f7b417ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size_list_2 = []\n",
    "for element in result2:\n",
    "    win_size_list_2.append(len(element[1]))\n",
    "win_size_set_2 = set(win_size_list_2)\n",
    "cnt_2=collections.Counter(win_size_list_2)\n",
    "\n",
    "x = np.array(sorted(cnt_2.keys())) # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "patters_num_2 = []\n",
    "for key in sorted(cnt_2.keys()) :\n",
    "    patters_num_2.append(cnt_2[key])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=110)\n",
    "\n",
    "x = [str(item) for item in x] \n",
    "\n",
    "rects2 = ax.bar(x, patters_num_2, width, label='Support Threshold = 2')\n",
    "\n",
    "ax.set_title('PyTorch', fontname=\"Times New Roman\", fontsize=16)\n",
    "ax.legend(prop={'family':'Times New Roman', 'size':10}, facecolor='w', framealpha=1)\n",
    "\n",
    "ax.set_xlabel('Pattern\\'s length', fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_ylabel('The number of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, max(patters_num_2)+1, 50))\n",
    "\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "win_size_list = []\n",
    "for element in result2:\n",
    "    win_size_list.append(len(element[1]))\n",
    "win_size_set = set(win_size_list)\n",
    "counter=collections.Counter(win_size_list)\n",
    "\n",
    "counter = dict(sorted(counter.items()))\n",
    "comulative_y = np.cumsum(list(counter.values()))\n",
    "\n",
    "per_list_patterns = []\n",
    "for element in comulative_y:\n",
    "    per_list_patterns.append((element*100)/comulative_y[-1])\n",
    "\n",
    "x2 = counter.keys() \n",
    "x2 = [str(item) for item in x2] \n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x2, per_list_patterns, '-o', color='green', linewidth=2)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax2.set_ylabel('Cumulative % of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "\n",
    "ax2.grid(axis = 'y', color='green', linestyle='--', linewidth=0.5)\n",
    "# ax2.grid(False)\n",
    "ax.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('pt_le_rq1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ced14e-a059-453b-a8f5-4cac3b360ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dic_pt_plength_rq1 = {\"x\":x, \"y2\":per_list_patterns, \"y1\": patters_num_2}\n",
    "pickle.dump(plt_dic_pt_plength_rq1, open(\"./Pickle_data/plt_dic_pt_plength_rq1.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00877e55-5557-4103-b09f-a89538247ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "result2, result_remove2 = CloConSeqGen_v3(dic_count, threshold=2)\n",
    "      \n",
    "sorted_result2 = sorted(result2, key=lambda tup: tup[0])\n",
    "\n",
    "sup_x = sorted(set([element[0] for element in result2]))\n",
    "\n",
    "len_sup_y = []\n",
    "lst_supp = [y[0] for y in sorted_result2]\n",
    "\n",
    "cnt = collections.Counter(lst_supp)\n",
    "for item in sup_x:\n",
    "    len_sup_y.append(cnt[item])\n",
    "    \n",
    "comulative_y = np.cumsum(list(cnt.values()))\n",
    "\n",
    "per_len_sup_y = []\n",
    "for element in comulative_y:\n",
    "    per_len_sup_y.append((element*100)/comulative_y[-1])\n",
    "per_len_sup_y = [100-x for x in per_len_sup_y]\n",
    "per_len_sup_y.insert(0, 100)\n",
    "per_len_sup_y.pop()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=110)\n",
    "\n",
    "sup_x = [str(item) for item in sup_x] \n",
    "\n",
    "rects = ax.bar(sup_x, len_sup_y, width=0.5, label='Support Threshold = 2')\n",
    "\n",
    "ax.set_title('PyTorch', fontname=\"Times New Roman\", fontsize=16)\n",
    "ax.legend(prop={'family':'Times New Roman', 'size':10}, facecolor='w', framealpha=1)\n",
    "\n",
    "ax.set_xlabel('Support', fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(sup_x)\n",
    "plt.xlim([-1, len(sup_x)])\n",
    "\n",
    "ax.set_ylabel('The number of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, max(len_sup_y)+1, 50))\n",
    "\n",
    "ax.bar_label(rects, padding=3)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "plt.plot(sup_x, per_len_sup_y, '--o', color='orange', linewidth=2)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax2.set_ylabel('Cumulative % of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "\n",
    "ax2.grid(axis = 'y', color='orange', linestyle='--', linewidth=0.5)\n",
    "# ax2.grid(False)\n",
    "ax.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('pt_sup_rq1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c70366-05e3-42b2-86cc-f11621064f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dic_pt_sup_rq1 = {\"x\":sup_x, \"y2\":per_len_sup_y, \"y1\": len_sup_y}\n",
    "pickle.dump(plt_dic_pt_sup_rq1, open(\"./Pickle_data/plt_dic_pt_sup_rq1.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756060e6-a3a2-4d09-8f92-b4fdbb0d518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "result2, result_remove2 = CloConSeqGen_v3(dic_count, threshold=2)\n",
    "      \n",
    "sorted_result2 = sorted(result2, key=lambda tup: tup[0])\n",
    "\n",
    "sup_x = sorted(set([element[0] for element in result2]))\n",
    "\n",
    "len_sup_y = []\n",
    "lst_supp = [y[0] for y in sorted_result2]\n",
    "\n",
    "cnt = collections.Counter(lst_supp)\n",
    "for item in sup_x:\n",
    "    len_sup_y.append(cnt[item])\n",
    "    \n",
    "comulative_y = np.cumsum(list(cnt.values()))\n",
    "\n",
    "per_len_sup_y = []\n",
    "for element in comulative_y:\n",
    "    per_len_sup_y.append((element*100)/comulative_y[-1])\n",
    "per_len_sup_y = [100-x for x in per_len_sup_y]\n",
    "per_len_sup_y.insert(0, 100)\n",
    "per_len_sup_y.pop()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=110)\n",
    "\n",
    "sup_x = [str(item) for item in sup_x] \n",
    "\n",
    "# show just 10 elements on x-axis\n",
    "sup_x = sup_x[:10]\n",
    "len_sup_y = len_sup_y[:10]\n",
    "per_len_sup_y = per_len_sup_y[:10]\n",
    "\n",
    "rects = ax.bar(sup_x, len_sup_y, width=0.5, label='Support Threshold = 2')\n",
    "\n",
    "ax.set_title('PyTorch', fontname=\"Times New Roman\", fontsize=16)\n",
    "ax.legend(prop={'family':'Times New Roman', 'size':10}, facecolor='w', framealpha=1)\n",
    "\n",
    "ax.set_xlabel('Support', fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(sup_x)\n",
    "plt.xlim([-1, len(sup_x)])\n",
    "\n",
    "ax.set_ylabel('The number of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, max(len_sup_y)+1, 50))\n",
    "\n",
    "ax.bar_label(rects, padding=3)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "plt.plot(sup_x, per_len_sup_y, '--o', color='orange', linewidth=2)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax2.set_ylabel('Cumulative % of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "\n",
    "ax2.grid(axis = 'y', color='orange', linestyle='--', linewidth=0.5)\n",
    "# ax2.grid(False)\n",
    "ax.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('pt_sup_rq1.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
