{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782e8f80-78a9-4e0b-9384-896f365185cf",
   "metadata": {},
   "source": [
    "# Stack Traces Project (keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3cb62-d481-464d-bac4-fb42528b9ca4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ce22b98e-8698-4c40-8ca0-245c1f8adf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Union, Tuple\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "import string\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from itertools import permutations\n",
    "import heapq\n",
    "import csv\n",
    "import pickle\n",
    "import matplotlib.ticker as mtick\n",
    "import collections\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# pd.options.display.max_colwidth = 500\n",
    "# pd.options.display.max_columns = None\n",
    "# pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0f3f2-df8e-49fa-b853-7b834194a10b",
   "metadata": {},
   "source": [
    "## Setting up the project environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a33fcc34-2081-48b3-8cb7-817b87d3fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .csv configuration\n",
    "encoding = \"utf-8\"\n",
    "delimiter = None\n",
    "working_directory_path = \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d94d09-86aa-46ee-9a4f-3de1442d24b9",
   "metadata": {},
   "source": [
    "## Loading the question dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a4c9e24a-26aa-454f-a424-5a667d25817f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"question_tag.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_sotorrent = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1401237b-1dd9-49ba-ad91-50929602772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163194, 11)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sotorrent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c616d9ac-5921-465c-aaf3-f2578e4864c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sotorrent['Source'] = 'old'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2314e81-5865-4ebd-8dab-a9e60d110eaf",
   "metadata": {},
   "source": [
    "Update the DB"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6381d8d-24d6-43b4-938e-67c9305b1318",
   "metadata": {},
   "source": [
    "Ref: https://data.stackexchange.com/stackoverflow/query/edit/1769158\n",
    "\n",
    "SELECT \n",
    "      Id, \n",
    "      PostTypeId, \n",
    "      AcceptedAnswerId, \n",
    "      CreationDate, \n",
    "      ViewCount, \n",
    "      AnswerCount, \n",
    "      CommentCount, \n",
    "      Score,\n",
    "      Title,\n",
    "      Body,\n",
    "      Tags\n",
    "FROM Posts \n",
    "WHERE (tags like '%tensorflow%' OR\n",
    "      tags LIKE '%pytorch%' OR\n",
    "      tags LIKE '%scikit-learn%' OR\n",
    "      tags LIKE '%keras%' OR\n",
    "      tags LIKE '%nltk%' OR\n",
    "      tags LIKE '%huggingface%' OR\n",
    "      tags LIKE '%spark-ml%') AND\n",
    "      creationDate > '2021-01-25 00:00:00' AND\n",
    "      PostTypeId=1\n",
    "ORDER BY [creationDate] DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "48e538f7-e9e5-4dab-ac00-7c179f4892ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"proj1_update_qst.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_remained = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "cd5b336b-1fe2-4bc6-a99c-837f3f672283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49918, 11)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "300bd414-ed1e-4bff-80f8-c3f6894c1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remained['source'] = 'new'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed36c3a-6087-495c-822b-9fb83c84ec23",
   "metadata": {},
   "source": [
    "Concat two data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "96f69893-e004-497d-a407-0dc3cc3bb0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213112, 13)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_sotorrent, df_remained])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8311d4f5-9748-465f-b6f4-023dde556a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates([\"Id\", \"PostTypeId\", \"AcceptedAnswerId\", \"ViewCount\", \"AnswerCount\", \"CommentCount\", \"Score\", \"Title\", 'Body', 'Tags'], ignore_index=False, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bc3f69f7-987e-4076-b1e1-0e345ff45fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records (w/o considering specific tag set) : 171114\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of records (w/o considering specific tag set) :\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e408693",
   "metadata": {},
   "source": [
    "## Answering the first research question (RQ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a6e6e-46f4-432b-81c6-a5f646d6dd08",
   "metadata": {},
   "source": [
    "### Filtering the specific tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "eae1d276-5b01-482b-b244-cd89bef86bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_filter(pref_tags: List, tags: str) -> bool:\n",
    "    regex = \"\"\n",
    "    for tag in pref_tags:\n",
    "        regex += '(?=.*\\\\b'+ tag +'([+-]?([0-9]*[.])?[0-9]*)\\\\b)'\n",
    "    regex = r\"^\" + regex + \".*$\"\n",
    "    tags = tags.strip().lower()\n",
    "    match_result = re.match(regex, tags, re.MULTILINE | re.IGNORECASE)\n",
    "    if match_result is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6b05dfaf-8a60-4a86-b341-b78d16a32226",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"keras\", \"python\"]\n",
    "df['HasPreferableTags'] = df['Tags'].apply(lambda row_tags: tag_filter(tags, row_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "40b740ac-83e0-45f1-a2be-e8825609ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags = df[df['HasPreferableTags']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3a2d3ed2-b450-4151-8856-352d7e8a2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags = df_w_keras_tags.drop(['HasPreferableTags'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "32db8e0e-ad52-40ee-aab0-229a72267751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30344, 13)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_keras_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb0623-d6d8-4261-90f3-c3eace22e119",
   "metadata": {},
   "source": [
    "We found there are some duplocated rows in our DB, so we eleminate those based on some columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "eb8b23cc-bffd-4fc3-a8c6-1fae9798336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags.drop_duplicates([\"Id\", \"PostTypeId\", \"AcceptedAnswerId\", \"ViewCount\", \"AnswerCount\", \"CommentCount\", \"Score\", \"Title\"], ignore_index=False, inplace=True)\n",
    "df_w_keras_tags = df_w_keras_tags.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b79a315e-28a4-4ae4-8fb7-dcfb510a291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30344, 13)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_keras_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c96c84-dedb-4f7f-a464-f8c8e8607970",
   "metadata": {
    "tags": []
   },
   "source": [
    "The new dataset that has a specific tag/s is reduced to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "15fdfa92-2d73-4f6c-af4d-4a814b7d11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The orginal DB:  171114\n",
      "The new DB (sp):  30344\n",
      "The difference is:  140770\n"
     ]
    }
   ],
   "source": [
    "print(\"The orginal DB: \", df.shape[0])\n",
    "print(\"The new DB (sp): \", df_w_keras_tags.shape[0])\n",
    "print(\"The difference is: \", df.shape[0] - df_w_keras_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2050397c-ca76-4c95-843d-71fbd9940991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Source</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52019226</td>\n",
       "      <td>1</td>\n",
       "      <td>52019631.0</td>\n",
       "      <td>2018-08-25 16:32:19</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Keras w/ Tensorflow intermediate layer extraction in batches</td>\n",
       "      <td>&lt;p&gt;I am currently trying to leverage an intermediate layer from my already trained DL model as an embedding to a given input. The code below already works at getting the layer I want, however it is extremely slow to do this iteratively for a large number of inputs.&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;model = load_model('model.h5')\\ninp = model.input\\noutputs = [layer.output for layer in model.layers]\\nfunctors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]\\n\\ndef text2tensor(text):\\n   ...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;&lt;deep-learning&gt;&lt;batch-processing&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64070871</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-25 20:19:10</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>How can i reshape TFRecord dataset to train RNN model?</td>\n",
       "      <td>&lt;p&gt;I am trying to feed an RNN model with &lt;code&gt;.tfrecords&lt;/code&gt; datasets (train,test) in order to train it. But i am getting an error about the size of input0. &lt;br&gt;\\nI think &lt;code&gt;train_data&lt;/code&gt; wants to reshape to 4 dims but i am not sure.&lt;/p&gt;\\n&lt;hr /&gt;\\n&lt;p&gt;The bellow function returning the datasets from &lt;code&gt;.tfrecords&lt;/code&gt; with features and one hot encoded label.&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;def get_dataset(directory, num_classes=60, batch_size=32, drop_remainder=False,\\n                shuffle=F...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;machine-learning&gt;&lt;keras&gt;&lt;recurrent-neural-network&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54004682</td>\n",
       "      <td>1</td>\n",
       "      <td>54005594.0</td>\n",
       "      <td>2019-01-02 10:27:49</td>\n",
       "      <td>1510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Loading a video dataset (Keras)</td>\n",
       "      <td>&lt;p&gt;I'm trying to implement an LRCN/C(LSTM)RNN to classify emotions in videos. My dataset structure is split in two folders - \"train_set\" and \"valid_set\". \\nWhen you open, either of them, you can find 3 folders, \"positive\", \"negative\" and \"surprise\". Lastly, each of these 3 folders has video-folders, each of which is a collection of frames of a video in .jpg. Videos have different length, hence a video-folder can have 200 frames, the one next to it 1200, 700...! To load the dataset I am using...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;video&gt;&lt;keras&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59113797</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 06:30:12</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Keras model training hanging on first epoch</td>\n",
       "      <td>&lt;p&gt;I have been trying to train a keras model but it keeps getting stuck at the start of the first epoch. The worst thing is that it is not throwing any errors. I am training on a GTX 1050TI&lt;/p&gt;\\n\\n&lt;p&gt;Below is a sample of my code:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;import tensorflow as tf\\nimport os\\n\\nfrom tensorflow import keras\\nfrom keras_preprocessing.image import ImageDataGenerator\\nfrom keras_applications.xception import Xception\\n\\n\\nimport matplotlib.pyplot as plt\\n\\n\\ntrain_dir='C:\\\\Users\\\\AYERHAN M...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;&lt;neural-network&gt;&lt;deep-learning&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58245855</td>\n",
       "      <td>1</td>\n",
       "      <td>58315643.0</td>\n",
       "      <td>2019-10-05 06:13:39</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Numpy arrays used in training in TF1--Keras have much lower accuracy in TF2</td>\n",
       "      <td>&lt;p&gt;I had a neural net in keras that performed well. Now with the deprecation that came with Tensorflow 2 I had to rewrite the model. Now it is giving me worse accuracy metrics. &lt;/p&gt;\\n\\n&lt;p&gt;My suspicion is that tf2 wants you to use their data structure to train models and they give a example of how to go from Numpy to tf.data.Dataset &lt;a href=\"https://www.tensorflow.org/tutorials/load_data/numpy\" rel=\"nofollow noreferrer\"&gt;here&lt;/a&gt;.&lt;/p&gt;\\n\\n&lt;p&gt;So I did:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;train_dataset = tf.data.D...</td>\n",
       "      <td>&lt;python-3.x&gt;&lt;tensorflow&gt;&lt;tensorflow-datasets&gt;&lt;tensorflow2.0&gt;&lt;tf.keras&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  PostTypeId  AcceptedAnswerId         CreationDate  ViewCount  AnswerCount  CommentCount  Score                                                                        Title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Body                                                                     Tags Source source\n",
       "0  52019226           1        52019631.0  2018-08-25 16:32:19        312            1             2      0                 Keras w/ Tensorflow intermediate layer extraction in batches  <p>I am currently trying to leverage an intermediate layer from my already trained DL model as an embedding to a given input. The code below already works at getting the layer I want, however it is extremely slow to do this iteratively for a large number of inputs.</p>\\n\\n<pre><code>model = load_model('model.h5')\\ninp = model.input\\noutputs = [layer.output for layer in model.layers]\\nfunctors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]\\n\\ndef text2tensor(text):\\n   ...             <python><tensorflow><keras><deep-learning><batch-processing>    old    NaN\n",
       "1  64070871           1               NaN  2020-09-25 20:19:10         45            0             1      1                       How can i reshape TFRecord dataset to train RNN model?  <p>I am trying to feed an RNN model with <code>.tfrecords</code> datasets (train,test) in order to train it. But i am getting an error about the size of input0. <br>\\nI think <code>train_data</code> wants to reshape to 4 dims but i am not sure.</p>\\n<hr />\\n<p>The bellow function returning the datasets from <code>.tfrecords</code> with features and one hot encoded label.</p>\\n<pre><code>def get_dataset(directory, num_classes=60, batch_size=32, drop_remainder=False,\\n                shuffle=F...  <python><tensorflow><machine-learning><keras><recurrent-neural-network>    old    NaN\n",
       "2  54004682           1        54005594.0  2019-01-02 10:27:49       1510            1             0      4                                              Loading a video dataset (Keras)  <p>I'm trying to implement an LRCN/C(LSTM)RNN to classify emotions in videos. My dataset structure is split in two folders - \"train_set\" and \"valid_set\". \\nWhen you open, either of them, you can find 3 folders, \"positive\", \"negative\" and \"surprise\". Lastly, each of these 3 folders has video-folders, each of which is a collection of frames of a video in .jpg. Videos have different length, hence a video-folder can have 200 frames, the one next to it 1200, 700...! To load the dataset I am using...                                       <python><tensorflow><video><keras>    old    NaN\n",
       "3  59113797           1               NaN  2019-11-30 06:30:12        139            1             4      0                                  Keras model training hanging on first epoch  <p>I have been trying to train a keras model but it keeps getting stuck at the start of the first epoch. The worst thing is that it is not throwing any errors. I am training on a GTX 1050TI</p>\\n\\n<p>Below is a sample of my code:</p>\\n\\n<pre><code>import tensorflow as tf\\nimport os\\n\\nfrom tensorflow import keras\\nfrom keras_preprocessing.image import ImageDataGenerator\\nfrom keras_applications.xception import Xception\\n\\n\\nimport matplotlib.pyplot as plt\\n\\n\\ntrain_dir='C:\\\\Users\\\\AYERHAN M...               <python><tensorflow><keras><neural-network><deep-learning>    old    NaN\n",
       "4  58245855           1        58315643.0  2019-10-05 06:13:39        231            1             2      1  Numpy arrays used in training in TF1--Keras have much lower accuracy in TF2  <p>I had a neural net in keras that performed well. Now with the deprecation that came with Tensorflow 2 I had to rewrite the model. Now it is giving me worse accuracy metrics. </p>\\n\\n<p>My suspicion is that tf2 wants you to use their data structure to train models and they give a example of how to go from Numpy to tf.data.Dataset <a href=\"https://www.tensorflow.org/tutorials/load_data/numpy\" rel=\"nofollow noreferrer\">here</a>.</p>\\n\\n<p>So I did:</p>\\n\\n<pre><code>train_dataset = tf.data.D...   <python-3.x><tensorflow><tensorflow-datasets><tensorflow2.0><tf.keras>    old    NaN"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_keras_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28990026-83cc-4af5-94f6-5b2a75eb41f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting the code parts from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "23057f26-0779-428d-885f-7b166ea7ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_blocks(body: str, _id: int) -> List:\n",
    "    global index\n",
    "    # regex = r\"<pre><code>((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>)\"\n",
    "    # regex = r\"(<pre>|(<pre((.*?)|(\\n)*)*><code>))((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>|</pre>)\"\n",
    "    regex = r\"<pre(><code>|>|(((.*?)|(\\n)*)><code>)|((.*?)|(\\n)*)>)((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>|</pre>)\"\n",
    "    matches = re.finditer(regex, body, re.MULTILINE | re.IGNORECASE)\n",
    "    result = []\n",
    "    \n",
    "    try:\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            code = match.group()\n",
    "            code = re.sub('<pre(><code>|>|(((.*?)|(\\n)*)><code>)|((.*?)|(\\n)*)>)', '', code)\n",
    "            code = code.replace(\"<pre><code>\", \"\")\n",
    "            code = code.replace(\"</pre></code>\", \"\")\n",
    "            code = code.replace(\"</code></pre>\", \"\")\n",
    "            result.append(code)\n",
    "    except:\n",
    "        print(\"\\n Error(1): \", _id)\n",
    "        print(body)\n",
    "        return None\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "f87db6b2-b24a-45d5-a7d2-e234bc3f0f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_w_keras_tags['Code'] = df_w_keras_tags.apply(lambda row: extract_code_blocks(row.Body, row.Id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "25534f29-f886-4366-9c74-366cb41becd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_w_tags.iloc[7]['Body'])\n",
    "# print(type(extract_code_blocks(df_w_tags.iloc[7]['Body'])))\n",
    "# print(len(extract_code_blocks(df_w_tags.iloc[7]['Body'])))\n",
    "# print(extract_code_blocks(df_w_tags.iloc[7]['Body'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b1e27-61be-4359-9b1c-c80828413913",
   "metadata": {},
   "source": [
    "Reset the index of dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e700b0aa-2f79-43c5-90e8-f969379e8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags = df_w_keras_tags.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbd611",
   "metadata": {},
   "source": [
    "#### Finding the number of questions that have a code or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "717748e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count__question_w_code  = 0\n",
    "count__question_wo_code = 0\n",
    "count__num_codes = 0\n",
    "\n",
    "def counting_w_or_wo_code(row_code: List) -> bool:\n",
    "    global count__question_w_code, count__question_wo_code, count__num_codes\n",
    "    \n",
    "    if row_code:\n",
    "        count__question_w_code = count__question_w_code + 1\n",
    "        count__num_codes += len(row_code)\n",
    "        return True\n",
    "    else:\n",
    "        count__question_wo_code = count__question_wo_code + 1\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9a723e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Has_code'] = df_w_keras_tags['Code'].apply(lambda row_code: counting_w_or_wo_code(row_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d8547f91-ce63-4b34-a349-f13a0815fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 30344 records in our DB, including 26439 posts that have code block in themselve and 3905 w/o any code block.\n",
      "We have 61179 number of code blocks including stacktrace, snippet code, error message.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {df_w_keras_tags.shape[0]} records in our DB, including {count__question_w_code} posts that have code block in themselve and {count__question_wo_code} w/o any code block.\")\n",
    "print(f\"We have {count__num_codes} number of code blocks including stacktrace, snippet code, error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd63ed7-eb63-42e3-b2a5-bc9641a5de68",
   "metadata": {},
   "source": [
    "### Define two lists for storing the information of the questions w or w/o Code Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b44b9a6a-140f-4f38-b16f-d8e15e839a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_w_code_info = []\n",
    "Question_wo_code_info = []\n",
    "\n",
    "def counting_w_or_wo_code(row_id: int, \n",
    "                           row_cr: object, \n",
    "                           row_vc: int, \n",
    "                           row_ac: int, \n",
    "                           row_cc: int, \n",
    "                           row_sc: int, \n",
    "                           row_ac_an_id: float, \n",
    "                           has_code: bool) -> None:\n",
    "    \n",
    "    global Question_w_code_info, Question_wo_code_info\n",
    "\n",
    "    if has_code:\n",
    "        Question_w_code_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))\n",
    "\n",
    "    else:\n",
    "        Question_wo_code_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7e93c5a0-3392-486c-bbff-bd269b758523",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_w_keras_tags.apply(lambda row: counting_w_or_wo_code(row.Id, \n",
    "                                                           row.CreationDate, \n",
    "                                                           row.ViewCount,\n",
    "                                                           row.AnswerCount,\n",
    "                                                           row.CommentCount,\n",
    "                                                           row.Score,\n",
    "                                                           row.AcceptedAnswerId,\n",
    "                                                           row.Has_code), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23ebc0-7b80-4c39-8df1-8d47da8c5d02",
   "metadata": {},
   "source": [
    "Create dfs based on the two lists, Question_w_code_info and Question_wo_code_info and filled their answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "42393cac-4d55-40c3-91b4-ff5b0c46e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_w_code_v1 = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_q_w_code_v1[\"Q_info\"] = Question_w_code_info\n",
    "\n",
    "df_q_w_code_v1[\"Q_id\"]          = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_q_w_code_v1[\"Q_create_time\"] = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_q_w_code_v1[\"View_count\"]    = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_q_w_code_v1[\"Answer_count\"]  = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_q_w_code_v1[\"Comment_count\"] = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_q_w_code_v1[\"Score\"]         = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_q_w_code_v1[\"Accepted_Answer_id\"] = df_q_w_code_v1['Q_info'].apply(lambda q_info: q_info[6])\n",
    "df_q_w_code_v1 = df_q_w_code_v1.drop(['Q_info'], axis='columns')\n",
    "df_q_w_code_v1[\"Q_create_time\"]      = pd.to_datetime(df_q_w_code_v1[\"Q_create_time\"])\n",
    "df_q_w_code_v1[\"First_acc_ans_time\"] = pd.to_datetime(df_q_w_code_v1[\"First_acc_ans_time\"])\n",
    "df_q_w_code_v1[\"First_ans_time\"]     = pd.to_datetime(df_q_w_code_v1[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "85d12996-1ea2-4467-b684-eef698f5d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "df_q_w_code_v1[\"Q_id\"].to_csv('../code_output_csv/df_keras_q_w_code.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6986107d-0813-4c97-842f-9d39e842b4c7",
   "metadata": {},
   "source": [
    "SELECT df_keras_q_w_code.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_keras_q_w_code\n",
    "INNER JOIN all_results\n",
    "ON df_keras_q_w_code.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfb4c0c1-7650-4b65-94ad-4faa7d1d4c2f",
   "metadata": {},
   "source": [
    "with cte1 as (\n",
    "SELECT\n",
    "        p.Id, \n",
    "        p.PostTypeId, \n",
    "        p.AcceptedAnswerId, \n",
    "        p.CreationDate, \n",
    "        p.ViewCount, \n",
    "        p.AnswerCount, \n",
    "        p.CommentCount, \n",
    "        p.Score,\n",
    "        p.Title,\n",
    "        p.Body,\n",
    "        p.Tags,\n",
    "        p.parentid\n",
    "\n",
    "FROM Posts as p\n",
    "inner join posts q \n",
    "        on q.id = coalesce(p.parentid, p.id) -- only questions have tags\n",
    "\n",
    "WHERE \n",
    "      p.PostTypeId=1 AND                     -- Just answers\n",
    "      --(p.Tags LIKE '%tensorflow%' OR\n",
    "       -- p.Tags LIKE '%pytorch%' AND\n",
    "       -- p.Tags LIKE '%scikit-learn%' AND\n",
    "       p.Tags LIKE '%keras%' AND\n",
    "       -- p.Tags LIKE '%nltk%' OR\n",
    "       -- p.Tags LIKE '%huggingface%' AND\n",
    "       -- p.Tags LIKE '%spark-ml%' AND\n",
    "       p.Tags LIKE '%python%'\n",
    ")\n",
    "select\n",
    "        r.parentid as Q_id,\n",
    "        r.parentid as ParentId,\n",
    "        r.Id, \n",
    "        --r.AcceptedAnswerId, \n",
    "        --r.PostTypeId,\n",
    "        --cte1.Id, \n",
    "        --cte1.PostTypeId,\n",
    "        r.CreationDate\n",
    "        --cte1.CreationDate as Q_CreationDate\n",
    "        --r.Score,\n",
    "        --cte1.AcceptedAnswerId\n",
    "        --cte1.ViewCount, \n",
    "        --cte1.AnswerCount,\n",
    "        --cte1.CommentCount, \n",
    "        --cte1.Score\n",
    "        --cte1.Title,\n",
    "        --cte1.Body,\n",
    "        --cte1.Tags,\n",
    "from posts r \n",
    "inner join cte1\n",
    "       on cte1.id = r.parentid\n",
    "where\n",
    "      r.PostTypeId = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1bda-bfff-411f-86a5-6c0a92992de3",
   "metadata": {},
   "source": [
    "The below csv file is the result of the top query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1e40b3f0-9026-4d3a-a6c4-456d32e061b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"keras_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "f45faa6f-fa05-43e1-bff7-803cddaa6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_w = pd.merge(df_q_w_code_v1, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "\n",
    "pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "\n",
    "pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new2_w = pd_tmp_new_w[pd_tmp_new_w.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0c6701e2-f7fc-49df-8cfa-af8fbaf25c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!:  39280813 4.0 [(39385599.0, '2016-09-08 08:01:19'), (39988934.0, '2016-10-12 00:56:59'), (50921203.0, '2018-06-19 05:32:07')]\n",
      "Warning!:  42556972 2.0 [(46344059.0, '2017-09-21 12:33:30')]\n",
      "Warning!:  42812230 4.0 [(42812559.0, '2017-03-15 14:25:40'), (48106769.0, '2018-01-05 03:18:49'), (53670071.0, '2018-12-07 12:59:04')]\n",
      "Warning!:  43058675 2.0 [(43058711.0, '2017-03-28 00:37:11')]\n",
      "Warning!:  45442843 2.0 [(45531884.0, '2017-08-06 12:06:14')]\n",
      "Warning!:  45537372 2.0 [(45583044.0, '2017-08-09 06:25:00')]\n",
      "Warning!:  45945398 7.0 [(45945785.0, '2017-08-29 18:12:52'), (45948885.0, '2017-08-29 21:55:13'), (48875491.0, '2018-02-19 23:05:34'), (54280782.0, '2019-01-20 20:42:05'), (54423546.0, '2019-01-29 14:44:06'), (59027548.0, '2019-11-25 08:17:12')]\n",
      "Warning!:  48979426 4.0 [(56060197.0, '2019-05-09 13:09:32'), (59776666.0, '2020-01-16 19:38:27'), (62719871.0, '2020-07-03 17:07:31')]\n",
      "Warning!:  49005892 2.0 [(59804457.0, '2020-01-18 20:18:13')]\n",
      "Warning!:  49237117 5.0 [(49238753.0, '2018-03-12 15:21:56'), (49238987.0, '2018-03-12 15:32:39'), (52917974.0, '2018-10-21 17:24:43'), (55747328.0, '2019-04-18 13:41:51')]\n",
      "Warning!:  50010929 4.0 [(50048350.0, '2018-04-26 16:53:14'), (50161767.0, '2018-05-03 18:32:52'), (55664372.0, '2019-04-13 10:16:30')]\n",
      "Warning!:  50571245 2.0 [(50588762.0, '2018-05-29 16:16:23')]\n",
      "Warning!:  50892119 2.0 [(50892355.0, '2018-06-16 22:47:50')]\n",
      "Warning!:  50895110 3.0 [(51896376.0, '2018-08-17 13:22:59'), (54888253.0, '2019-02-26 14:54:55')]\n",
      "Warning!:  53366768 3.0 [(53380590.0, '2018-11-19 18:25:07'), (53405554.0, '2018-11-21 05:04:53')]\n",
      "Warning!:  54025916 2.0 [(54029617.0, '2019-01-03 20:51:21')]\n",
      "Warning!:  54274107 2.0 [(54274774.0, '2019-01-20 08:30:57')]\n",
      "Warning!:  54805568 2.0 [(nan, nan)]\n",
      "Warning!:  55481393 2.0 [(59642171.0, '2020-01-08 08:41:51')]\n",
      "Warning!:  55533413 3.0 [(55543516.0, '2019-04-05 21:20:06'), (55827001.0, '2019-04-24 09:40:38')]\n",
      "Warning!:  55634133 3.0 [(55634686.0, '2019-04-11 14:16:31'), (55634744.0, '2019-04-11 14:19:33')]\n",
      "Warning!:  56460901 2.0 [(62140763.0, '2020-06-01 20:48:20')]\n",
      "Warning!:  56498504 3.0 [(56505215.0, '2019-06-08 09:45:08')]\n",
      "Warning!:  56627371 2.0 [(58065919.0, '2019-09-23 15:43:37')]\n",
      "Warning!:  57062456 7.0 [(58726643.0, '2019-11-06 09:15:11'), (58900033.0, '2019-11-17 11:35:22'), (59639212.0, '2020-01-08 03:57:12'), (61002414.0, '2020-04-02 22:50:27'), (62379815.0, '2020-06-15 00:48:20'), (63280924.0, '2020-08-06 09:45:12')]\n",
      "Warning!:  57190095 3.0 [(57192370.0, '2019-07-24 23:12:19'), (57256143.0, '2019-07-29 14:41:48')]\n",
      "Warning!:  57539273 2.0 [(57546746.0, '2019-08-18 17:14:25')]\n",
      "Warning!:  57542946 2.0 [(57546258.0, '2019-08-18 16:06:13')]\n",
      "Warning!:  58154611 2.0 [(nan, nan)]\n",
      "Warning!:  58728086 3.0 [(59525939.0, '2019-12-30 05:04:12'), (64144594.0, '2020-09-30 19:36:06')]\n",
      "Warning!:  58911856 2.0 [(nan, nan)]\n",
      "Warning!:  59380430 3.0 [(59381897.0, '2019-12-17 20:51:21'), (61188801.0, '2020-04-13 13:20:19')]\n",
      "Warning!:  59392084 3.0 [(63946065.0, '2020-09-17 20:54:18'), (64135699.0, '2020-09-30 10:31:56')]\n",
      "Warning!:  59459468 2.0 [(59464417.0, '2019-12-24 05:55:53')]\n",
      "Warning!:  59522643 2.0 [(59523463.0, '2019-12-29 21:29:23')]\n",
      "Warning!:  59783361 2.0 [(59783618.0, '2020-01-17 08:28:11')]\n",
      "Warning!:  60199316 2.0 [(60199477.0, '2020-02-13 02:06:10')]\n",
      "Warning!:  60398061 2.0 [(60398170.0, '2020-02-25 15:33:55')]\n",
      "Warning!:  60923982 2.0 [(60927524.0, '2020-03-30 09:25:27')]\n",
      "Warning!:  61425296 9.0 [(61529308.0, '2020-04-30 17:27:54'), (61555448.0, '2020-05-02 06:40:07'), (61556348.0, '2020-05-02 08:17:31'), (61565801.0, '2020-05-02 20:22:28'), (61567062.0, '2020-05-02 22:20:37'), (61578364.0, '2020-05-03 16:58:12'), (61580287.0, '2020-05-03 19:16:59'), (61583254.0, '2020-05-04 00:07:44')]\n",
      "Warning!:  61563730 2.0 [(61564142.0, '2020-05-02 18:10:51')]\n",
      "Warning!:  61837014 2.0 [(61837256.0, '2020-05-16 13:07:08')]\n",
      "Warning!:  62092147 3.0 [(62092401.0, '2020-05-29 18:21:36'), (62202181.0, '2020-06-04 18:56:24')]\n",
      "Warning!:  62311222 3.0 [(62311595.0, '2020-06-10 19:26:28'), (62311811.0, '2020-06-10 19:39:12')]\n",
      "Warning!:  62482404 2.0 [(62502083.0, '2020-06-21 17:26:46')]\n",
      "Warning!:  62678401 2.0 [(62678585.0, '2020-07-01 14:00:47')]\n",
      "Warning!:  62808712 2.0 [(62881059.0, '2020-07-13 17:25:00')]\n",
      "Warning!:  62836692 2.0 [(62837403.0, '2020-07-10 15:19:53')]\n",
      "Warning!:  63114255 2.0 [(63114571.0, '2020-07-27 11:41:19')]\n",
      "Warning!:  63313062 2.0 [(nan, nan)]\n",
      "Warning!:  63561570 2.0 [(63561931.0, '2020-08-24 13:22:51')]\n",
      "Warning!:  63655484 3.0 [(63671028.0, '2020-08-31 12:40:48'), (67484158.0, '2021-05-11 09:36:44')]\n",
      "Warning!:  63738681 3.0 [(63738887.0, '2020-09-04 09:56:50'), (63739202.0, '2020-09-04 10:17:29')]\n",
      "Warning!:  64434655 2.0 [(64438413.0, '2020-10-20 04:19:07')]\n",
      "Warning!:  64646247 2.0 [(64646350.0, '2020-11-02 13:18:18')]\n",
      "Warning!:  64993322 2.0 [(64994759.0, '2020-11-24 21:00:34')]\n"
     ]
    }
   ],
   "source": [
    "def checker_ans_and_ans_tup(q_id: int, ans_count: int, ans_list: list) -> None:\n",
    "    if len(ans_list) < ans_count:\n",
    "        print(\"Warning!: \", int(q_id), ans_count, ans_list)\n",
    "        \n",
    "_ = pd_tmp_new2_w.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ede30e36-94e3-46a8-a4bf-93ee8bb0d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_acc_ans_time', np.nan)\n",
    "pd_tmp_new3_w = pd_tmp_new2_w.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c8a77995-f0dc-4c9e-b2ef-34b28ed28de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_w.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_w.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_w.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = acc_time\n",
    "\n",
    "pd_tmp_new3_w[\"Duration_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_acc_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc69830-b63f-4696-8d86-25ec5b49f41e",
   "metadata": {},
   "source": [
    "We did the same behaviour for the Question_wo_code_info list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b6e57dad-db68-4579-bfb2-aaa08da7881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_wo_code_v1 = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_q_wo_code_v1[\"Q_info\"] = Question_wo_code_info\n",
    "\n",
    "df_q_wo_code_v1[\"Q_id\"]          = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_q_wo_code_v1[\"Q_create_time\"] = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_q_wo_code_v1[\"View_count\"]    = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_q_wo_code_v1[\"Answer_count\"]  = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_q_wo_code_v1[\"Comment_count\"] = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_q_wo_code_v1[\"Score\"]         = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_q_wo_code_v1[\"Accepted_Answer_id\"] = df_q_wo_code_v1['Q_info'].apply(lambda q_info: q_info[6])\n",
    "df_q_wo_code_v1 = df_q_wo_code_v1.drop(['Q_info'], axis='columns')\n",
    "df_q_wo_code_v1[\"Q_create_time\"] = pd.to_datetime(df_q_wo_code_v1[\"Q_create_time\"])\n",
    "df_q_wo_code_v1[\"First_acc_ans_time\"] = pd.to_datetime(df_q_wo_code_v1[\"First_acc_ans_time\"])\n",
    "df_q_wo_code_v1[\"First_ans_time\"]     = pd.to_datetime(df_q_wo_code_v1[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2b0a19d6-a919-4acb-9101-9ec0bb3a73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "df_q_wo_code_v1[\"Q_id\"].to_csv('../code_output_csv/df_keras_q_wo_code.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3c41fc5-ade4-4b12-9368-7262b638af3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "SELECT df_keras_q_wo_code.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_keras_q_wo_code\n",
    "INNER JOIN all_results\n",
    "ON df_keras_q_wo_code.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653acab6-162d-4ac3-9291-2c70bc944a6a",
   "metadata": {},
   "source": [
    "We used the all answers csv file again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d6db3fba-6f54-4d5d-b550-3ba7bbef2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"keras_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night_wo = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f78b3fbd-aa46-44ab-9ee5-a63eefe96cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo = df_night_wo.reset_index(drop=True)\n",
    "df_q_wo_code_v1['Answers'] = df_q_wo_code_v1.apply(lambda x: [], axis=1)\n",
    "\n",
    "pd_tmp_wo = pd.merge(df_q_wo_code_v1, df_night_wo, how='left',left_on=['Q_id'],right_on=['ParentId']).reset_index(drop=True)\n",
    "\n",
    "pd_tmp_wo[\"Answer_tup\"] = pd_tmp_wo.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_wo = pd_tmp_wo.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new2_wo = pd_tmp_new_wo[pd_tmp_new_wo.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "14c954c0-cd32-42f2-a086-88bf10041767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!:  35050753 5 [(nan, nan)]\n",
      "Warning!:  47946413 2 [(47996856.0, '2017-12-27 18:18:10')]\n",
      "Warning!:  50474336 2 [(50474657.0, '2018-05-22 18:54:02')]\n",
      "Warning!:  51202181 4 [(51202289.0, '2018-07-06 02:39:50'), (51202401.0, '2018-07-06 02:53:36'), (55680849.0, '2019-04-14 23:11:17')]\n",
      "Warning!:  55514435 2 [(58683231.0, '2019-11-03 18:15:52')]\n",
      "Warning!:  55923311 3 [(55937010.0, '2019-05-01 13:27:15'), (64014670.0, '2020-09-22 17:17:21')]\n",
      "Warning!:  57610804 2 [(57614277.0, '2019-08-22 17:20:30')]\n",
      "Warning!:  60580178 2 [(nan, nan)]\n",
      "Warning!:  62073259 2 [(nan, nan)]\n",
      "Warning!:  64734203 2 [(64734388.0, '2020-11-08 02:53:34')]\n",
      "Warning!:  64738104 2 [(nan, nan)]\n"
     ]
    }
   ],
   "source": [
    "_ = pd_tmp_new2_wo.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5bc16074-1766-4c19-b08c-515a12b11ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_acc_ans_time', np.nan)\n",
    "pd_tmp_new3_wo = pd_tmp_new2_wo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7741c7cc-9ed9-4b7b-8af6-7c3c577d3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_wo.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_wo.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_wo.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = acc_time\n",
    "    \n",
    "pd_tmp_new3_wo[\"Duration_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_wo[\"Duration_acc_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8585686a-1ef1-4413-be43-f396bdaf19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "pd_tmp_new3_w.to_csv('./CSV_data/plt_keras_q_w_code.csv', encoding='utf-8')\n",
    "pd_tmp_new3_wo.to_csv('./CSV_data/plt_keras_q_wo_code.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76009349",
   "metadata": {},
   "source": [
    "### Extracting the text parts from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "426b615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_blocks(id: int, body: str) -> Optional[List]:\n",
    "    # It's bug\n",
    "    if id in [10005, 14212, 21959, 26677, 53279, 22356, 16143]: \n",
    "        body = body + \"</p>\"\n",
    "\n",
    "    regex = r\"(<p>((.*?)|(\\n)*)*<\\/p>)|(<ul>((.*?)|(\\n)*)*<\\/ul>)|(<ol>((.*?)|(\\n)*)*<\\/ol>)\"\n",
    "    matches = re.finditer(regex, body, re.MULTILINE | re.IGNORECASE)\n",
    "    result = []\n",
    "    \n",
    "    # if id in [18397]:\n",
    "    #     return result\n",
    "\n",
    "    try:\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            text = match.group()\n",
    "            text = text.replace(\"<p>\", \"\")\n",
    "            text = text.replace(\"<strong>\", \"\")\n",
    "            text = text.replace(\"<br>\", \"\")\n",
    "            text = text.replace(\"<ol>\", \"\")\n",
    "            text = text.replace(\"<ul>\", \"\")\n",
    "            text = text.replace(\"<li>\", \"\")\n",
    "            text = text.replace(\"</p>\", \"\")\n",
    "            text = text.replace(\"</strong>\", \"\")\n",
    "            text = text.replace(\"</ol>\", \"\")\n",
    "            text = text.replace(\"</ul>\", \"\")\n",
    "            text = text.replace(\"</li>\", \"\")\n",
    "            result.append(text)\n",
    "        return result\n",
    "    except:\n",
    "        print(\"Error(1): \", id)\n",
    "        print(body)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "96ff4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Text'] = df_w_keras_tags.apply(lambda row: extract_text_blocks(row.name, row.Body), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bb294",
   "metadata": {},
   "source": [
    "#### Finding the number of body words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "18933061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_text_words(text_list: List) -> int:\n",
    "    word_count = 0\n",
    "    for text in text_list:\n",
    "        word_count += sum([i.strip(string.punctuation).isalpha() for i in text.split()])\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "15bc8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Q_text_words_num'] = df_w_keras_tags[\"Text\"].apply(lambda text_list: find_q_text_words(text_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d4e61-0992-43cf-bfc4-83cebb7d1bbf",
   "metadata": {},
   "source": [
    "Save the dataframe as csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3d8f131a-19f7-46b8-b8e3-399ba5537607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_w_Tens_tags.to_csv('./amin_result_v1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5ff90-afcd-45a3-9d2d-a2b58de44dd9",
   "metadata": {},
   "source": [
    "### Find the Regular Expressions for Unix and Windows base Pathnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3406a54-9a09-4255-8287-d16fab93833d",
   "metadata": {},
   "source": [
    "#### 1) Absolute and Relative Pathnames in UNIX OS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c90be3-66df-4290-972f-940233a71e7c",
   "metadata": {},
   "source": [
    "Stack/trace example: https://stackoverflow.com/questions/37337728/tensorflow-internalerror-blas-sgemm-launch-failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9d6c0-8adb-4939-9f06-329b036eb875",
   "metadata": {},
   "source": [
    "Find the restrictions and limitations related to the Unix pathnames: https://www.cyberciti.biz/faq/linuxunix-rules-for-naming-file-and-directory-names/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32c563-d1db-4f0a-9820-62fd42a6591e",
   "metadata": {},
   "source": [
    "Online regular expression environment for testing: https://regex101.com/r/ZyEx5u/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9456a-4c9e-4a8f-bee5-86a5be847e82",
   "metadata": {},
   "source": [
    "> Regular Expression: \"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb6875-32a5-4f52-b33a-9cb522a49f72",
   "metadata": {},
   "source": [
    "#### 1) Pathnames in Windows OS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9c86a-e55e-4200-85ff-ed3033b4ee64",
   "metadata": {},
   "source": [
    "Stack/trace example: https://stackoverflow.com/questions/49434031/tensorflow-on-windows-cpu-version-importerror-no-module-named-pywrap-tensorf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd40a8-d970-435c-a06d-6a32130d3055",
   "metadata": {},
   "source": [
    "Find the restrictions and limitations related to the Windows pathnames: <br /> \n",
    "https://docs.microsoft.com/en-us/dotnet/standard/io/file-path-formats <br />\n",
    "https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5ffa1-d9f8-4e8c-b9a8-8f438af95a1a",
   "metadata": {},
   "source": [
    "Online regular expression environment for testing: https://regex101.com/r/L6xmCa/1 , https://regex101.com/r/wz1WqW/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1be13-b32c-4d50-9ea2-490eafe5b139",
   "metadata": {},
   "source": [
    "> Regular Expression: \"[a-zA-Z]:\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "bc401c12-44a2-402c-9e4a-1de67941e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pathnames_from_code_column(code_sec: List, _id: int) -> Tuple[str, List]: \n",
    "    try:\n",
    "        result_post_file_names = []\n",
    "        OS_flag = None\n",
    "        error_index = None\n",
    "        error_code = None\n",
    "        regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/\\\\]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\s\\W*\\d*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?\\/?([^\\<\\>\\:\\\"\\\\\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        \n",
    "        for idx, code in enumerate(code_sec):\n",
    "            pattern_unix  = re.compile(regex_unix)\n",
    "            pattern_windows  = re.compile(regex_windows)\n",
    "            if pattern_unix.search(code):\n",
    "                OS_flag = \"unix\"\n",
    "                break\n",
    "            elif pattern_windows.search(code):\n",
    "                OS_flag = \"windows\"\n",
    "                break\n",
    "                \n",
    "        if OS_flag == \"unix\":\n",
    "            for idx, code in enumerate(code_sec):\n",
    "                error_index = idx\n",
    "                code = code.replace(\"\\\\n\", \"\\n\")\n",
    "                code = code.replace('&lt;', '<')\n",
    "                code = code.replace('&gt;', '>')\n",
    "                code = code.replace('&quot;', '\"')\n",
    "                error_code = code\n",
    "                matches = re.finditer(regex_unix, code, re.MULTILINE)\n",
    "                file_names_for_each_code_part = []\n",
    "                \n",
    "                for matchNum, match in enumerate(matches, start=1):\n",
    "                    file_names_for_each_code_part.append((match.groups()[1].strip(), match.groups()[4].strip()))\n",
    "#                     file_names_for_each_code_part.append(match.groups()[1].strip())\n",
    "                    # print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "                    # for groupNum in range(0, len(match.groups())):\n",
    "                        # groupNum = groupNum + 1\n",
    "                        # print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n",
    "#                 print(file_names_for_each_code_part)\n",
    "#                 file_names_for_each_code_part = list(set(file_names_for_each_code_part))            # Create a unique list\n",
    "#                 print(file_names_for_each_code_part)\n",
    "                \n",
    "                if file_names_for_each_code_part:                                                   # Ignore the empty list\n",
    "                    result_post_file_names.append(file_names_for_each_code_part)\n",
    "                    \n",
    "        elif OS_flag == \"windows\":\n",
    "            for idx, code in enumerate(code_sec):\n",
    "                code = code.replace('&lt;', '<')\n",
    "                code = code.replace('&gt;', '>')\n",
    "                code = code.replace('&quot;', '\"')\n",
    "                error_code = code\n",
    "                matches = re.finditer(regex_windows, code, re.MULTILINE)                            \n",
    "                file_names_for_each_code_part = []\n",
    "\n",
    "                for matchNum, match in enumerate(matches, start=1):\n",
    "                    file_names_for_each_code_part.append((match.groups()[3].strip(), match.groups()[6].strip()))\n",
    "#                     file_names_for_each_code_part.append(match.groups()[1].strip())\n",
    "                    # print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "                    # for groupNum in range(0, len(match.groups())):\n",
    "                        # groupNum = groupNum + 1\n",
    "                        # print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n",
    "#                 file_names_for_each_code_part = [s.strip() for s in file_names_for_each_code_part]  # Strip the list\n",
    "#                 file_names_for_each_code_part = list(set(file_names_for_each_code_part))            # create a unique list\n",
    "                if file_names_for_each_code_part:                                                     # Ignore the empty list\n",
    "                    result_post_file_names.append(file_names_for_each_code_part)\n",
    "            \n",
    "    except:\n",
    "        print(\"\\n Error Id:\", _id, \" Error index:\", error_index, \"\\n\")\n",
    "        print(error_code)\n",
    "        return None, None\n",
    "\n",
    "    return OS_flag, result_post_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fc583436-6446-47b3-8811-ee3b316c57cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('windows',\n",
       " [[('sequential', 'predict_classes'),\n",
       "   ('training', 'predict'),\n",
       "   ('training_arrays', 'model_iteration'),\n",
       "   ('backend', '__call__'),\n",
       "   ('session', '__call__')]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for Unix path\n",
    "# https://stackoverflow.com/questions/51839415/tensorflow-valueerror-rank-mismatch\n",
    "# df_w_keras_tags.iloc[9][:]\n",
    "extract_pathnames_from_code_column(df_w_keras_tags[\"Code\"][51], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "8642e202-ad70-4f13-9440-57eeeb3fda8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example for Windows path\n",
    "# df_w_keras_tags['Code'] = df_w_keras_tags['Body'].apply(lambda row_body: extract_code_blocks(row_body))\n",
    "# print(df_w_keras_tags[\"Code\"][9])\n",
    "# extract_pathnames_from_code_column(df_w_keras_tags[\"Code\"][84])\n",
    "# extract_pathnames_from_code_column(df_w_keras_tags[\"Code\"][606])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0c61970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_keras_tags[\"Body\"][606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0dd38400-fb42-4dc7-8f9d-deb13a98c1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_w_keras_tags['Bugy_py_files'] = df_w_keras_tags.apply(lambda row: extract_pathnames_from_code_column(row.Code, row.Id), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7d4de",
   "metadata": {},
   "source": [
    "Save the dataframe as csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "4e4ea318-37e3-4d03-b3a2-566723d22160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_w_keras_tags.loc[df_w_PT_tags['Id'] == 46509039]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "4718e5db-2866-4f96-8a3a-2a09e559cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_keras_tags[[\"Title\", \"Code\", \"Bugy_py_files\"]].head(100)\n",
    "# df_w_keras_tags.to_csv('./keras_Code_bug.csv', sep='\\n', encoding='utf-8')\n",
    "# df_w_keras_tags['Bugy_py_files'].to_csv('./keras_bugy_tuples.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a7e0c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_has_trace_col(cal_tuple) -> bool:\n",
    "    if cal_tuple[0] == \"windows\" or cal_tuple[0] == \"unix\":\n",
    "        return True\n",
    "    elif cal_tuple[0] is None:\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "acd983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Has_trace'] = df_w_keras_tags['Bugy_py_files'].apply(lambda cell_tuple: create_has_trace_col(cell_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60aff5",
   "metadata": {},
   "source": [
    "#### Finding the number and type of LOC in the body of post:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33da7bf-c174-48ba-999c-766d91c33a7a",
   "metadata": {},
   "source": [
    "For example how many pairs did you find in a post and defining the OS of that stack trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9c25a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_line_of_code(code_list: List) -> Tuple[int, int, int]:\n",
    "    line_count_trace_win   = 0\n",
    "    line_count_trace_unix  = 0\n",
    "    line_count_simple_code = 0\n",
    "    \n",
    "    for code in code_list:\n",
    "        regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/\\\\]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\s\\W*\\d*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?\\/?([^\\<\\>\\:\\\"\\\\\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        # regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\" version 2\n",
    "        # regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d+)\\W*in\\W*([a-zA-Z_$][a-zA-Z_$0-9]*)\" version 1\n",
    "        # regex_windows = r\"[a-zA-Z]:\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d+)\\W*in\\W*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        pattern_unix  = re.compile(regex_unix)\n",
    "        pattern_windows = re.compile(regex_windows)\n",
    "        if pattern_unix.search(code):\n",
    "            OS_flag = \"unix\"\n",
    "        elif pattern_windows.search(code):\n",
    "            OS_flag = \"windows\"\n",
    "        else:\n",
    "            OS_flag = \"nothing\"\n",
    "            \n",
    "        code_wo_empty_line = os.linesep.join([s for s in code.splitlines() if s])\n",
    "            \n",
    "        if OS_flag == \"unix\":\n",
    "            line_count_trace_unix += len(code_wo_empty_line.splitlines())\n",
    "        elif OS_flag == \"windows\":\n",
    "            line_count_trace_win += len(code_wo_empty_line.splitlines())\n",
    "        elif OS_flag == \"nothing\":\n",
    "            line_count_simple_code += len(code_wo_empty_line.splitlines()) \n",
    "        else:\n",
    "            print(\"Error!\")\n",
    "\n",
    "    return (line_count_trace_unix, line_count_trace_win, line_count_simple_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4054d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 17)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finding_line_of_code(df_w_keras_tags.loc[19, 'Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c2f3958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Line_code_u_w_s'] = df_w_keras_tags['Code'].apply(lambda code_list: finding_line_of_code(code_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b3e57594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Line_code_uix'] = df_w_keras_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4a683106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_keras_tags['Line_code_win'] = df_w_keras_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b99bf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has a code (Python code) inside the post\n",
    "df_w_keras_tags['Line_code_simple_code'] = df_w_keras_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3534efd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Source</th>\n",
       "      <th>source</th>\n",
       "      <th>Code</th>\n",
       "      <th>Has_code</th>\n",
       "      <th>Text</th>\n",
       "      <th>Q_text_words_num</th>\n",
       "      <th>Bugy_py_files</th>\n",
       "      <th>Has_trace</th>\n",
       "      <th>Line_code_u_w_s</th>\n",
       "      <th>Line_code_uix</th>\n",
       "      <th>Line_code_win</th>\n",
       "      <th>Line_code_simple_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52019226</td>\n",
       "      <td>1</td>\n",
       "      <td>52019631.0</td>\n",
       "      <td>2018-08-25 16:32:19</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Keras w/ Tensorflow intermediate layer extraction in batches</td>\n",
       "      <td>&lt;p&gt;I am currently trying to leverage an intermediate layer from my already trained DL model as an embedding to a given input. The code below already works at getting the layer I want, however it is extremely slow to do this iteratively for a large number of inputs.&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;model = load_model('model.h5')\\ninp = model.input\\noutputs = [layer.output for layer in model.layers]\\nfunctors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]\\n\\ndef text2tensor(text):\\n   ...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;&lt;deep-learning&gt;&lt;batch-processing&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[model = load_model('model.h5')\\ninp = model.input\\noutputs = [layer.output for layer in model.layers]\\nfunctors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]\\n\\ndef text2tensor(text):\\n    \"\"\"Convert string to tensor\"\"\"\\n    tensor = tokenizer.texts_to_sequences([text])\\n    tensor = pad_sequences(tensor, maxlen=10, padding='pre')\\n    return tensor\\n\\ndef get_embedding(tensor, at_layer):\\n    \"\"\"Get output at particular layer in network \"\"\"\\n    functors = [K.functi...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I am currently trying to leverage an intermediate layer from my already trained DL model as an embedding to a given input. The code below already works at getting the layer I want, however it is extremely slow to do this iteratively for a large number of inputs., How do I make use of batch processing so that I don't have to do this one by one? It is extremely slow with the above implementation, but it works.]</td>\n",
       "      <td>77</td>\n",
       "      <td>(None, [])</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0, 23)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64070871</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-25 20:19:10</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>How can i reshape TFRecord dataset to train RNN model?</td>\n",
       "      <td>&lt;p&gt;I am trying to feed an RNN model with &lt;code&gt;.tfrecords&lt;/code&gt; datasets (train,test) in order to train it. But i am getting an error about the size of input0. &lt;br&gt;\\nI think &lt;code&gt;train_data&lt;/code&gt; wants to reshape to 4 dims but i am not sure.&lt;/p&gt;\\n&lt;hr /&gt;\\n&lt;p&gt;The bellow function returning the datasets from &lt;code&gt;.tfrecords&lt;/code&gt; with features and one hot encoded label.&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;def get_dataset(directory, num_classes=60, batch_size=32, drop_remainder=False,\\n                shuffle=F...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;machine-learning&gt;&lt;keras&gt;&lt;recurrent-neural-network&gt;</td>\n",
       "      <td>old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[def get_dataset(directory, num_classes=60, batch_size=32, drop_remainder=False,\\n                shuffle=False, shuffle_size=1000):\\n    # dictionary describing the features.\\n    feature_description = {\\n        'features': tf.io.FixedLenFeature([], tf.string),\\n        'label': tf.io.FixedLenFeature([], tf.int64)\\n    }\\n\\n    # parse each proto and, the features within\\n    def _parse_feature_function(example_proto):\\n        features = tf.io.parse_single_example(example_proto, feature_d...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I am trying to feed an RNN model with &lt;code&gt;.tfrecords&lt;/code&gt; datasets (train,test) in order to train it. But i am getting an error about the size of input0. \\nI think &lt;code&gt;train_data&lt;/code&gt; wants to reshape to 4 dims but i am not sure., The bellow function returning the datasets from &lt;code&gt;.tfrecords&lt;/code&gt; with features and one hot encoded label., The displayed error:, ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=4, found ndim=5. Full shape receiv...</td>\n",
       "      <td>70</td>\n",
       "      <td>(None, [])</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0, 44)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  PostTypeId  AcceptedAnswerId         CreationDate  ViewCount  AnswerCount  CommentCount  Score                                                         Title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Body                                                                     Tags Source source  \\\n",
       "0  52019226           1        52019631.0  2018-08-25 16:32:19        312            1             2      0  Keras w/ Tensorflow intermediate layer extraction in batches  <p>I am currently trying to leverage an intermediate layer from my already trained DL model as an embedding to a given input. The code below already works at getting the layer I want, however it is extremely slow to do this iteratively for a large number of inputs.</p>\\n\\n<pre><code>model = load_model('model.h5')\\ninp = model.input\\noutputs = [layer.output for layer in model.layers]\\nfunctors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]\\n\\ndef text2tensor(text):\\n   ...             <python><tensorflow><keras><deep-learning><batch-processing>    old    NaN   \n",
       "1  64070871           1               NaN  2020-09-25 20:19:10         45            0             1      1        How can i reshape TFRecord dataset to train RNN model?  <p>I am trying to feed an RNN model with <code>.tfrecords</code> datasets (train,test) in order to train it. But i am getting an error about the size of input0. <br>\\nI think <code>train_data</code> wants to reshape to 4 dims but i am not sure.</p>\\n<hr />\\n<p>The bellow function returning the datasets from <code>.tfrecords</code> with features and one hot encoded label.</p>\\n<pre><code>def get_dataset(directory, num_classes=60, batch_size=32, drop_remainder=False,\\n                shuffle=F...  <python><tensorflow><machine-learning><keras><recurrent-neural-network>    old    NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Code  Has_code  \\\n",
       "0  [model = load_model('model.h5')\\ninp = model.input\\noutputs = [layer.output for layer in model.layers]\\nfunctors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]\\n\\ndef text2tensor(text):\\n    \"\"\"Convert string to tensor\"\"\"\\n    tensor = tokenizer.texts_to_sequences([text])\\n    tensor = pad_sequences(tensor, maxlen=10, padding='pre')\\n    return tensor\\n\\ndef get_embedding(tensor, at_layer):\\n    \"\"\"Get output at particular layer in network \"\"\"\\n    functors = [K.functi...      True   \n",
       "1  [def get_dataset(directory, num_classes=60, batch_size=32, drop_remainder=False,\\n                shuffle=False, shuffle_size=1000):\\n    # dictionary describing the features.\\n    feature_description = {\\n        'features': tf.io.FixedLenFeature([], tf.string),\\n        'label': tf.io.FixedLenFeature([], tf.int64)\\n    }\\n\\n    # parse each proto and, the features within\\n    def _parse_feature_function(example_proto):\\n        features = tf.io.parse_single_example(example_proto, feature_d...      True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Text  Q_text_words_num Bugy_py_files  Has_trace Line_code_u_w_s  Line_code_uix  Line_code_win  Line_code_simple_code  \n",
       "0                                                                                        [I am currently trying to leverage an intermediate layer from my already trained DL model as an embedding to a given input. The code below already works at getting the layer I want, however it is extremely slow to do this iteratively for a large number of inputs., How do I make use of batch processing so that I don't have to do this one by one? It is extremely slow with the above implementation, but it works.]                77    (None, [])      False      (0, 0, 23)              0              0                     23  \n",
       "1  [I am trying to feed an RNN model with <code>.tfrecords</code> datasets (train,test) in order to train it. But i am getting an error about the size of input0. \\nI think <code>train_data</code> wants to reshape to 4 dims but i am not sure., The bellow function returning the datasets from <code>.tfrecords</code> with features and one hot encoded label., The displayed error:, ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=4, found ndim=5. Full shape receiv...                70    (None, [])      False      (0, 0, 44)              0              0                     44  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_keras_tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fde1f5",
   "metadata": {},
   "source": [
    "#### Question Post's Length (body of the post): Defining the lists for plotting their comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "bd5dee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_num_words_w_tra  = []\n",
    "list_num_words_wo_tra = []\n",
    "\n",
    "for index1, row in df_w_keras_tags.iterrows():\n",
    "    if row.Has_trace is True:\n",
    "        list_num_words_w_tra.append(row.Q_text_words_num)\n",
    "    elif row.Has_trace is False:\n",
    "        list_num_words_wo_tra.append(row.Q_text_words_num)\n",
    "    else:\n",
    "        print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae0b5-da13-4ad7-b853-44783e21104b",
   "metadata": {},
   "source": [
    "#### OS Stack Traces: Defining the number of stack straces the belongs to the Unix or Windows OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bd3530e5-831c-4db8-b250-089f05938c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found the 1254 of stackoverflow's posts that belong to the Windows OS.\n",
      "We found the 2865 of stackoverflow's posts that belong to the Unix OS.\n"
     ]
    }
   ],
   "source": [
    "counter_win  = 0\n",
    "counter_unix = 0\n",
    "# dim_win  = []\n",
    "# dim_unix = []\n",
    "\n",
    "for tp in df_w_keras_tags[\"Bugy_py_files\"]:\n",
    "    if tp[0] == \"windows\":\n",
    "        counter_win += 1\n",
    "#         np_array = np.array(tuple[1], dtype=object)\n",
    "#         dim_win.append(np_array.shape)\n",
    "        \n",
    "    elif tp[0] == \"unix\":\n",
    "        counter_unix += 1\n",
    "#         np_array = np.array(tuple[1], dtype=object)\n",
    "#         dim_unix.append(np_array.shape)\n",
    "\n",
    "print(f\"We found the {counter_win} of stackoverflow's posts that belong to the Windows OS.\")\n",
    "print(f\"We found the {counter_unix} of stackoverflow's posts that belong to the Unix OS.\")\n",
    "# print(\"The dimensions of Windows labels is: \", set(dim_win))\n",
    "# print(\"The dimensions of Unix labels is: \", set(dim_unix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "862bb743-f63d-4f4f-9b62-e38bb4711f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "PostTypeId                 int64\n",
       "AcceptedAnswerId         float64\n",
       "CreationDate              object\n",
       "ViewCount                  int64\n",
       "AnswerCount                int64\n",
       "CommentCount               int64\n",
       "Score                      int64\n",
       "Title                     object\n",
       "Body                      object\n",
       "Tags                      object\n",
       "Source                    object\n",
       "source                    object\n",
       "Code                      object\n",
       "Has_code                    bool\n",
       "Text                      object\n",
       "Q_text_words_num           int64\n",
       "Bugy_py_files             object\n",
       "Has_trace                   bool\n",
       "Line_code_u_w_s           object\n",
       "Line_code_uix              int64\n",
       "Line_code_win              int64\n",
       "Line_code_simple_code      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_keras_tags.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4c57c-d11e-4e1d-ac85-9c155d748630",
   "metadata": {},
   "source": [
    "#### Define two lists for storing the information of the questions w or w/o stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "7a685f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_w_t  = 0\n",
    "count_wo_t = 0\n",
    "count_win  = 0\n",
    "count_unix = 0\n",
    "\n",
    "Question_with_trace_info = []\n",
    "Question_with_wo_trace_info = []\n",
    "\n",
    "def counting_w_or_wo_trace(row_id: int, \n",
    "                           row_cr: object, \n",
    "                           row_vc: int, \n",
    "                           row_ac: int, \n",
    "                           row_cc: int, \n",
    "                           row_sc: int, \n",
    "                           row_ac_an_id: float, \n",
    "                           row_t: object, \n",
    "                           has_code: bool) -> None:\n",
    "    \n",
    "    global count_w_t, count_wo_t, count_win, count_unix, Question_with_trace_info, Question_with_wo_trace_info\n",
    "\n",
    "    if has_code:\n",
    "        if row_t[0] is not None:\n",
    "            count_w_t = count_w_t + 1\n",
    "            Question_with_trace_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))\n",
    "            \n",
    "            if row_t[0] == 'unix':\n",
    "                count_unix = count_unix + 1\n",
    "            else:\n",
    "                count_win = count_win + 1\n",
    "        else:\n",
    "            count_wo_t = count_wo_t + 1\n",
    "            Question_with_wo_trace_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ee29fdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = df_w_keras_tags.apply(lambda row: counting_w_or_wo_trace(row.Id, \n",
    "                                                               row.CreationDate, \n",
    "                                                               row.ViewCount,\n",
    "                                                               row.AnswerCount,\n",
    "                                                               row.CommentCount,\n",
    "                                                               row.Score,\n",
    "                                                               row.AcceptedAnswerId,\n",
    "                                                               row.Bugy_py_files, \n",
    "                                                               row.Has_code), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f73aa-307c-4ca5-ad1f-9c80e0067c0f",
   "metadata": {},
   "source": [
    "#### Creating a string matrix of pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe9422-3706-4fc3-9135-8cbd87353226",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://stackoverflow.com/questions/32037893/numpy-fix-array-with-rows-of-different-lengths-by-filling-the-empty-elements-wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3390d5ca-986e-4ddf-a48f-eb4e45ab46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_fillna(data: List) -> np.ndarray:\n",
    "    # Get lengths of each row of data\n",
    "    lens = np.array([len(i) for i in data])\n",
    "\n",
    "    # Mask of valid places in each row\n",
    "    mask = np.arange(lens.max()) < lens[:, None]\n",
    "\n",
    "    # Setup output array and put elements from data into masked positions\n",
    "    out = np.zeros(mask.shape, dtype='object')\n",
    "    out[mask] = np.concatenate(data)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "043411f3-4d8b-43b5-89e2-7a9b5d9e1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_2D_array_with_str = []\n",
    "\n",
    "# The below list store the post Id for each instances (or row in _2D_array). \n",
    "# We have to mention that the index of _2D_array and _Id_array helps us to find the id pattern quickly.\n",
    "_Id_array = []\n",
    "\n",
    "for index1, row in df_w_keras_tags.iterrows():\n",
    "    row_tuple = row.Bugy_py_files\n",
    "    row_id = row.Id\n",
    "    \n",
    "    # row: (some rows have multiple patterns)\n",
    "    # ('unix', [[('estimator', 'train'), ('estimator', '_train_model'), \n",
    "    #            ('estimator', '_train_model_default'), ('estimator', '_call_model_fn'), ('nn_ops', 'sparse_softmax_cross_entropy_with_logits')]])\n",
    "    \n",
    "    if row_tuple[0] is None: continue\n",
    "    \n",
    "    for element in row_tuple[1]:\n",
    "        _Id_array.append(row_id)\n",
    "        element_tmp = element[:]\n",
    "        _2D_array_with_str.append(element_tmp)\n",
    "\n",
    "# _2D_array_pad = numpy_fillna(_2D_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa51f-6992-42c2-9cf0-fd1888ae4047",
   "metadata": {},
   "source": [
    "#### Creating a numerical matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ab766-8031-4eca-9cef-455c127c6283",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-pandas-factorize/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbea84-d201-4010-9759-c32f05b80aa9",
   "metadata": {},
   "source": [
    "##### Creating a dictionary based on pairs and assigning a unique number to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "8257c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict pair : int\n",
    "\n",
    "dic = {} \n",
    "specific_val = 1\n",
    "for row in _2D_array_with_str:\n",
    "    for element in row:\n",
    "        if element not in dic:\n",
    "            dic[element] = specific_val\n",
    "            specific_val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "82ffd8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique pairs is:  5003\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique pairs is: \", max(dic.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfa8c9-9b6c-4643-b0b7-6b39e7fe40e4",
   "metadata": {},
   "source": [
    "##### Converting strings on the _2D_array into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "a2bf0be4-4828-4126-8816-81c1a4a3f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array_with_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7a556c82-ad7d-43c9-b7f1-c852da489f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array = list()\n",
    "# _2D_array_str = _2D_array_with_str.copy()\n",
    "# _2D_array = _2D_array_with_str[:]\n",
    "_2D_array = _2D_array_with_str[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0ff5062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(_2D_array):\n",
    "    for j in range(len(row)):\n",
    "        _2D_array[i][j] = dic[_2D_array[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b3971037-915c-4994-9107-5b36a9d62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array_with_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ec5559a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# _2D_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "f97135b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqe_dic int : pair\n",
    "uniqe_dic = dict([(value, key) for key, value in dic.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a621bac-8178-438b-8464-73225fe218a7",
   "metadata": {},
   "source": [
    "By the below function we deleted duplicated rows in 2d_array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ca3c46e1-7f42-4369-8ea3-6a25dbadc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2d_array_dup(_2d_array: list) -> Tuple[int, list]:\n",
    "    \n",
    "    dup_count = 0\n",
    "    _2d_array_tmp = _2d_array.copy()\n",
    "    _2d_array_tmp_next = []\n",
    "    \n",
    "    idx = 0\n",
    "    while idx != len(_2d_array_tmp):\n",
    "        \n",
    "        for indx_previous in range(0, idx+1):\n",
    "            _2d_array_tmp_next.append(_2d_array_tmp[indx_previous])\n",
    "        \n",
    "        for indx_next in range(idx+1, len(_2d_array_tmp)):\n",
    "#             print(idx, indx_next)\n",
    "#             print(_2d_array_tmp)\n",
    "#             print(_2d_array_tmp_next)\n",
    "\n",
    "            if _2d_array_tmp[idx] == _2d_array_tmp[indx_next]:\n",
    "                dup_count += 1\n",
    "            else:\n",
    "                _2d_array_tmp_next.append(_2d_array_tmp[indx_next])\n",
    "#         print(_2d_array_tmp_next)\n",
    "#         print(len(_2d_array_tmp_next))\n",
    "#         break\n",
    "        _2d_array_tmp = _2d_array_tmp_next\n",
    "        _2d_array_tmp_next = []\n",
    "        idx += 1\n",
    "    \n",
    "    return dup_count, _2d_array_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "cd20b1db-3f52-4f69-ad94-f91eff4c5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplication_row, _2D_array_new = find_2d_array_dup(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "038074a7-a09a-4288-9368-db126c18d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"We decresed the number of patterns from {len(_2D_array)} to {len(_2D_array_new)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa324359",
   "metadata": {},
   "source": [
    "## Answering the second research question (RQ2): Finding Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31312935",
   "metadata": {},
   "source": [
    "## Contiguous Sequential Pattern Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4c26c",
   "metadata": {},
   "source": [
    "https://www.cc.gatech.edu/~hic/CS7616/pdf/lecture13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ff498",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Approach (1):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9bae7",
   "metadata": {},
   "source": [
    "The shortest yet efficient implementation of the famous frequent sequential pattern mining algorithm PrefixSpan, the famous frequent closed sequential pattern mining algorithm BIDE (in closed.py), and the frequent generator sequential pattern mining algorithm FEAT (in generator.py), as a unified and holistic algorithm framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96570036",
   "metadata": {},
   "source": [
    "https://github.com/chuanconggao/PrefixSpan-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "5eaa5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "35702190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prefixspan import PrefixSpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c509adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PrefixSpan(_2D_array_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "df9fc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = ps.frequent(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b69e8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"/home-students/amghad/sample.txt\", \"w\")\n",
    "# str_list = repr(k)\n",
    "# file.write(str_list)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2979a",
   "metadata": {},
   "source": [
    "### Approach (2): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a8e0a",
   "metadata": {},
   "source": [
    "pymining is a small collection of data mining algorithms implemented in Python. I did not design any of the algorithms, but I use them in my own research so I thought other developers might be interested to use them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94392e0f",
   "metadata": {},
   "source": [
    "https://github.com/bartdag/pymining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e8d57",
   "metadata": {},
   "source": [
    "### Approach (3): By this approach we simply check all possible status for each row (or pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec37188-5c46-407b-b193-55c54b2e1841",
   "metadata": {},
   "source": [
    "We want to create a dict based on the vectors on the numerical matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f60f00-0840-41a0-8398-8f863bc2bc68",
   "metadata": {},
   "source": [
    "By the below function, we tried to find and search the patterns for each vector based on the window_size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d8aae18-d1d3-4282-9bf7-f7fe45ca5d6b",
   "metadata": {},
   "source": [
    "Input Vector: [1, 2, 6, 3]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "822ce776-1a3b-476d-92e6-be663d91ff05",
   "metadata": {},
   "source": [
    "{0: [(2, [(1, 2), (2, 6), (6, 3)]),\n",
    "    (3, [(1, 2, 6), (2, 6, 3)]),\n",
    "    (4, [(1, 2, 6, 3)])]\n",
    " ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233612b-f3b4-4328-88ed-7843b13d0957",
   "metadata": {},
   "source": [
    "0: The index of vector <br>\n",
    "list: Contains tuples with different windows_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "03fb9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dicc_new(dicc: dict, vec_id: int, list_: list) -> dict:\n",
    "    if vec_id not in dicc:\n",
    "        # key not exist\n",
    "        dicc[vec_id] = list_\n",
    "    else:\n",
    "        # key exist\n",
    "        for tuple_ in list_:\n",
    "            for item in dicc[vec_id]:\n",
    "                if item[0] == tuple_[0]:\n",
    "                    item[1].append(tuple_[1][0])\n",
    "                    break\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2a340-fad0-4464-a15b-01f01995d3b0",
   "metadata": {},
   "source": [
    "The \"low\" parameter can help us control the lower bound of the window_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1c3380c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0    # <~~~~~~~ define the lower bound threshold\n",
    "up = len(uniqe_dic)\n",
    "dicc = {}     \n",
    "\n",
    "for i_v, vector in enumerate(_2D_array):    \n",
    "    for index, element in enumerate(vector):\n",
    "        list_ = []\n",
    "        for wind_size in range(low, len(vector)+1-index):\n",
    "            list_.append((wind_size, [(*vector[index:index+wind_size], )]))\n",
    "        dicc = append_to_dicc_new(dicc, i_v, list_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "88e6b3a4-6f49-462d-aac4-afa5cb3d4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2D_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ddd8bf1e-a7ad-45d8-99ab-a22e4b3f53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f09aefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplication(dup_list: list) -> list:\n",
    "    final_list = []\n",
    "    for item in dup_list:\n",
    "        if item not in final_list:\n",
    "            final_list.append(item)\n",
    "        else:\n",
    "            indx = final_list.index(item)\n",
    "            counter = final_list[indx][0] + 1\n",
    "            pair = final_list[indx][1]\n",
    "            final_list.remove(item)\n",
    "            final_list.append((counter, pair))\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a41ac-d183-4807-a0d1-fa9328e359cf",
   "metadata": {},
   "source": [
    "dic_count is a dictionary that key is window_size, and value is a list that contains tuples. Each tuple shows a pair and the number of pair's iteration on the matrix."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4befab67-c057-41a7-84c5-aa6b89e363ef",
   "metadata": {},
   "source": [
    "{2: [(1, (5, 1)),\n",
    "  (1, (1, 6)),\n",
    "  (1, (1, 2)),\n",
    "  (1, (2, 6)),\n",
    "  (2, (6, 3)),\n",
    "  (1, (6, 1)),\n",
    "  (2, (1, 3)),\n",
    "  (3, (4, 5)),\n",
    "  (5, (3, 4)),\n",
    "  (2, (4, 3)),\n",
    "  (1, (3, 6)),\n",
    "  (1, (2, 3)),\n",
    "  (1, (3, 1)),\n",
    "  (2, (1, 4)),\n",
    "  (1, (4, 6))],\n",
    "  ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "9ef3ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_count = {}\n",
    "\n",
    "for vec_i, list_tuples in dicc.items():\n",
    "#     print(vec_i, list_tuples,\"\\n\")\n",
    "    for tuples_ in list_tuples:\n",
    "#         print(tuples_)\n",
    "        \n",
    "        if tuples_[0] not in dic_count:\n",
    "            lst_ = [(1, tuple_) for tuple_ in tuples_[1]] \n",
    "            \n",
    "            if len(lst_) != len(set(lst_)):\n",
    "                lst_ = remove_duplication(lst_)\n",
    "            \n",
    "            dic_count[tuples_[0]] = lst_  \n",
    "        else:\n",
    "            #(2, [(1, 3), (1, 4), (3, 4), (4, 5), (5, 1)]\n",
    "            #break\n",
    "            for tuple_ in tuples_[1]:\n",
    "                flag = 0 \n",
    "                for item in dic_count[tuples_[0]]:\n",
    "                    if item[1] == tuple_:\n",
    "                        counter = item[0] + 1\n",
    "                        dic_count[tuples_[0]].remove(item)\n",
    "                        dic_count[tuples_[0]].append((counter, item[1]))\n",
    "                        flag = 1\n",
    "                        break\n",
    "                # tuple is new\n",
    "                if flag == 0:\n",
    "                    dic_count[tuples_[0]].append((1, tuple_))\n",
    "#                 else: \n",
    "#                     print(\"Error100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85825caa-0ea6-49f4-afb9-467ca6dcd2f8",
   "metadata": {},
   "source": [
    "dic_count is a dictionary that key is window_size, and value is a list that contains tuples. Each tuple shows a pair and the number of pair's iteration on the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f87b4-36e2-4376-8f3f-ba55164a1b72",
   "metadata": {},
   "source": [
    "For each window_size we count the number of patterns that we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "735ff20e-0a61-4acb-b2e4-3c9e4e9886cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9492, ()), (9491, ()), (9493, ())]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_count.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2db34be8-e770-4e6f-a243-1f70b1766461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inst_length = dic_count.keys()\n",
    "inst_count = [len(value) for key, value in dic_count.items()]\n",
    "comulative_inst_count = np.cumsum(inst_count)\n",
    "\n",
    "per_comulative_inst_count = []\n",
    "for element in comulative_inst_count:\n",
    "    per_comulative_inst_count.append((element*100)/comulative_inst_count[-1])\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4), dpi=100)\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(inst_length, per_comulative_inst_count, '--o', color='#4b8262', linewidth=2)\n",
    "plt.xlabel('Instance\\'s length')\n",
    "plt.ylabel('Cumulative % of stack trace instances')\n",
    "ax1.set_title('keras RQ2')\n",
    "\n",
    "# plt.vlines(x=5, ymin=60, ymax=95, color='red')\n",
    "\n",
    "# plt.text(5.5, 65, 'sentence', rotation=0)\n",
    "ax1.axis(ymin=0, ymax=102)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "42ac2495-df65-4f9b-a88d-c2fc13e51d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x420 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize =(10, 6), dpi=70)\n",
    "ax.barh(list(inst_length), inst_count, align='center', alpha=0.5, log=True)\n",
    "\n",
    "for i in ax.patches:\n",
    "    plt.text(i.get_width()+0.2, i.get_y()+0.3,\n",
    "             str(round((i.get_width()), 2)),\n",
    "             fontsize = 10, fontweight ='bold',\n",
    "             color ='grey')\n",
    "\n",
    "# Add Plot Title\n",
    "ax.set_title('The frequency of stack trace intances for each instance\\'s length',loc ='center')\n",
    "# ax.set_yticks(y_pos, objects)\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Instance\\'s length')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8dc6b-c1d8-45fc-a851-184118ca1a3a",
   "metadata": {},
   "source": [
    "### Approach (4): CC-Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "87d8aea6-501b-4a56-98ea-2cdad58ed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dicc_new(dicc, vec_id, list_):\n",
    "    if vec_id not in dicc:\n",
    "        # key not exist\n",
    "        dicc[vec_id] = list_\n",
    "    else:\n",
    "        # key exist\n",
    "        for tuple_ in list_:\n",
    "            for item in dicc[vec_id]:\n",
    "                if item[0] == tuple_[0]:\n",
    "                    item[1].append(tuple_[1][0])\n",
    "                    break\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b8570828-2fb9-4945-b5df-70c17a4ebf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4319"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f9370071-2ec9-4fbb-8b33-8e66e38b8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching Pattern\n",
    "low = 1     # <~~~~~~~ define the lower bound threshold\n",
    "up = len(uniqe_dic)\n",
    "dicc = {}     \n",
    "\n",
    "for i_v, vector in enumerate(_2D_array):    \n",
    "    for index, element in enumerate(vector):\n",
    "        list_ = []\n",
    "        for wind_size in range(low, len(vector)+1-index):\n",
    "            list_.append((wind_size, [(*vector[index:index+wind_size], )]))\n",
    "        dicc = append_to_dicc_new(dicc, i_v, list_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a64a3b0e-ffa9-4999-96cf-5bdc766df1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting\n",
    "def remove_duplication(dup_list):\n",
    "    final_list = []\n",
    "    for item in dup_list:\n",
    "        if item not in final_list:\n",
    "            final_list.append(item)\n",
    "        else:\n",
    "            indx = final_list.index(item)\n",
    "            counter = final_list[indx][0] + 1\n",
    "            pair = final_list[indx][1]\n",
    "            final_list.remove(item)\n",
    "            final_list.append((counter, pair))\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ca4b370c-9b01-4e16-a3a6-a7a58bc463e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_count = {}\n",
    "\n",
    "for vec_i, list_tuples in dicc.items():\n",
    "#     print(vec_i, list_tuples,\"\\n\")\n",
    "    for tuples_ in list_tuples:\n",
    "#         print(tuples_)\n",
    "        \n",
    "        if tuples_[0] not in dic_count:\n",
    "            lst_ = [(1, tuple_) for tuple_ in tuples_[1]] \n",
    "            \n",
    "            if len(lst_) != len(set(lst_)):\n",
    "                lst_ = remove_duplication(lst_)\n",
    "            \n",
    "            dic_count[tuples_[0]] = lst_  \n",
    "        else:\n",
    "            #(2, [(1, 3), (1, 4), (3, 4), (4, 5), (5, 1)]\n",
    "            #break\n",
    "            for tuple_ in tuples_[1]:\n",
    "                flag = 0 \n",
    "                for item in dic_count[tuples_[0]]:\n",
    "                    if item[1] == tuple_:\n",
    "                        counter = item[0] + 1\n",
    "                        dic_count[tuples_[0]].remove(item)\n",
    "                        dic_count[tuples_[0]].append((counter, item[1]))\n",
    "                        flag = 1\n",
    "                        break\n",
    "                # tuple is new\n",
    "                if flag == 0:\n",
    "                    dic_count[tuples_[0]].append((1, tuple_))\n",
    "#                 else: \n",
    "#                     print(\"Error100\")\n",
    "#     print(\"salam\", dic_count[2], \"\\n\\n\" )\n",
    "#     if vec_i == 1:\n",
    "#         break\n",
    "\n",
    "# _2d_array = [[1, 3, 4, 3, 4, 5, 1, 4],\n",
    "#              [1, 6, 3, 4, 5],\n",
    "#              [1, 2, 6, 3],\n",
    "#              [6, 1, 3, 4, 5],\n",
    "#              [3, 4, 3, 6],\n",
    "#              [2, 3, 1, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "cb0c9fd7-b3c5-4e61-84bd-bd84f14b392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subsequence(needle: list, haystack: list) -> bool:\n",
    "    # >>> is_subsequence([2, 3, 4], [1, 2, 3, 4, 5, 6])\n",
    "    return any(\n",
    "        haystack[i:i+len(needle)] == needle\n",
    "        for i in range(len(haystack) - len(needle) + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "777e6228-2296-47e7-bc0a-aa9f658346a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen(dic_count: dict, threshold: int) -> list:\n",
    "    closed_list = []\n",
    "    for key, v_list in dic_count.items():\n",
    "        #print(key, v_list)\n",
    "        for item_tup in v_list:\n",
    "            tmp_flag = False\n",
    "            for key, v_list_search in dic_count.items():\n",
    "                for item_tup_search in v_list_search:\n",
    "                    #print(\"compare with: \", item_tup_search[1])\n",
    "                    if len(item_tup_search[1]) >= len(item_tup[1]) and is_subsequence(item_tup[1], item_tup_search[1]) and item_tup[1] != item_tup_search[1]:\n",
    "                        if item_tup[0] == item_tup_search[0]:\n",
    "                            tmp_flag = True\n",
    "            if not tmp_flag and item_tup[0] > threshold:\n",
    "\n",
    "                closed_list.append(item_tup)\n",
    "    return closed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "dfbd276c-0735-4163-910b-27bd57d50fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "70d292da-2e31-4ae1-9590-255586e51611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen_v2(dic_count: dict) -> list:\n",
    "    closed_list = []\n",
    "    flag_first_step = True\n",
    "    for win_size in list(reversed(list(dic_count))):\n",
    "        # Just add the last or the biggest window_size to the list \n",
    "        if flag_first_step:\n",
    "            flag_first_step = False\n",
    "            for item in dic_count[win_size]:\n",
    "                closed_list.append(item)\n",
    "            continue\n",
    "        \n",
    "        # For other window sizes\n",
    "        for item_tup_new in dic_count[win_size]:\n",
    "            flag_visit = False\n",
    "            for item_tup_old in closed_list:\n",
    "                if item_tup_new[0] == item_tup_old[0] and is_subsequence(item_tup_new[1], item_tup_old[1]):\n",
    "                    flag_visit = True\n",
    "                    break\n",
    "            if not flag_visit:\n",
    "                closed_list.append(item_tup_new)\n",
    "\n",
    "    return len(closed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "cbc205ce-b533-4d9e-81c6-623cc7d67941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen_v3(dic_count: dict, threshold: int) -> list:\n",
    "    closed_list = []\n",
    "    removed_closed_list = []\n",
    "    flag_first_step = True\n",
    "    for win_size in list(reversed(list(dic_count))):\n",
    "        # Just add the last or the biggest window_size to the list \n",
    "        if flag_first_step:\n",
    "            for item in dic_count[win_size]:\n",
    "                if item[0] >= threshold:\n",
    "                    flag_first_step = False\n",
    "                    closed_list.append(item)\n",
    "                else:\n",
    "                    removed_closed_list.append(item)\n",
    "            continue\n",
    "        \n",
    "        # For other window sizes\n",
    "        for item_tup_new in dic_count[win_size]:\n",
    "            flag_visit = False\n",
    "            for item_tup_old in closed_list:\n",
    "                if item_tup_new[0] == item_tup_old[0] and is_subsequence(item_tup_new[1], item_tup_old[1]):\n",
    "                    flag_visit = True\n",
    "                    break  \n",
    "            if (not flag_visit) and (item_tup_new[0] >= threshold):\n",
    "                closed_list.append(item_tup_new)\n",
    "            else:\n",
    "                removed_closed_list.append(item_tup_new)\n",
    "\n",
    "    return closed_list, removed_closed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "57c0af36-4426-4796-9124-a3fbffa9354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CloConSeqGen_v2(dic_count))\n",
    "# print(CloConSeqGen_v3(dic_count, 1))\n",
    "# print(CloConSeqGen_v3(dic_count, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "227bf25d-7b45-42cf-818e-d417cf39afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CloConSeqGen_v2(dic_count))\n",
    "# print(CloConSeqGen_v3(dic_count, threshold=1))\n",
    "# print(CloConSeqGen_v3(dic_count, threshold=1))\n",
    "# result, result_remove = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f6c79-191c-4ee2-a7c9-e9401b7566c9",
   "metadata": {},
   "source": [
    "### Prepare data for support and pattern length when support is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "fdc068df-aa93-43a5-9a4c-d794dca1ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, result_remove = CloConSeqGen_v3(dic_count, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4337b03f-e920-42e6-b5d6-a0936dc350ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6406"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f9b00c8a-2f0e-40a7-92ff-962cad9bf658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the low and high boundries of CloConSeqGen_v3 result\n",
    "for element in result:\n",
    "    if result.index(element) == 0:\n",
    "        low = element[0] \n",
    "        high = element[0]\n",
    "        continue\n",
    "    if low > element[0]:\n",
    "        low = element[0]\n",
    "    elif high < element[0]:\n",
    "        high = element[0]\n",
    "        \n",
    "sorted_result = sorted(result, key=lambda tup: tup[0])\n",
    "\n",
    "sup_x = sorted(set([element[0] for element in result]))\n",
    "len_sup_y = []\n",
    "\n",
    "for sup in sup_x:\n",
    "    len_sup_y.append(len(sorted_result) - [y[0] for y in sorted_result].index(sup))\n",
    "    \n",
    "per_len_sup_y = [(x*100)/len_sup_y[0] for x in len_sup_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7289acc1-43ea-46d3-b80d-24c1e4261251",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tf_sup = {\"x\":sup_x, \"y\":per_len_sup_y}\n",
    "pickle.dump(dic_tf_sup, open(\"./Pickle_data/dic_keras_sup.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d9f5e832-7572-4a1d-91a0-a807f2b298af",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size_list = []\n",
    "for element in result:\n",
    "    win_size_list.append(len(element[1]))\n",
    "win_size_set = set(win_size_list)\n",
    "counter=collections.Counter(win_size_list)\n",
    "\n",
    "counter = dict(sorted(counter.items()))\n",
    "comulative_y = np.cumsum(list(counter.values()))\n",
    "\n",
    "per_list_patterns = []\n",
    "for element in comulative_y:\n",
    "    per_list_patterns.append((element*100)/comulative_y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b88744e3-113a-4f5f-9e19-c3b202d0d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_tf_win = {\"x\":list(counter.keys()), \"y\":per_list_patterns}\n",
    "pickle.dump(dic_tf_win, open( \"./Pickle_data/dic_keras_win.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa07e1-d0d9-42f8-b9e7-0a463f24dff7",
   "metadata": {},
   "source": [
    "### Prepare data for support and pattern length when support is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "73ce1054-8b7f-4e5e-bea3-f8909d5cc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, result_remove = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "827b1c72-a704-40d2-9727-01c506a5fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4043"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "67ac384f-2bb3-4436-bdde-1baa66580850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_num_string(input_list: list, unique_dic: dict) -> list:\n",
    "    convert_lst = []\n",
    "    for pattern in input_list:\n",
    "        string_pattern_tuple = ()\n",
    "        for item in pattern[1]:\n",
    "            string_pattern_tuple = string_pattern_tuple + (unique_dic[item],)\n",
    "        convert_lst.append((pattern[0], string_pattern_tuple))\n",
    "    return convert_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5a50964f-25a7-420a-93c9-3063977a8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_sublist(lst_big: list, lst_small: list) -> bool:\n",
    "    return lst_small in [lst_big[i:len(lst_small)+i] for i in range(len(lst_big))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "addeb75a-073e-4883-a9fd-b4f68911705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str = convert_num_string(result, uniqe_dic)\n",
    "assert len(result) == len(result_str), \"It should be the same.\"\n",
    "pattern_str_w_qid = []\n",
    "\n",
    "for pattern in result_str:\n",
    "    for q_id in _Id_array:\n",
    "        # assert not df_w_sklearn_tags.loc[df_w_sklearn_tags['Id'] == q_id].Bugy_py_files.empty, \"It's not possible!\"\n",
    "        exit_flag_q_id = False\n",
    "        \n",
    "        for item in df_w_keras_tags['Bugy_py_files'].to_numpy()[df_w_keras_tags['Id'].to_numpy() == q_id].item()[1]:\n",
    "           \n",
    "            if order_sublist(item, list(pattern[1])):\n",
    "                # pattern_str_w_qid.append((pattern[0], pattern[1]))\n",
    "                \n",
    "                exist = False\n",
    "                for ele in pattern_str_w_qid:\n",
    "                    if ele[1] == pattern[0] and ele[2] == pattern[1]:\n",
    "                        exist = True\n",
    "                        ele[0].append(q_id)\n",
    "                        \n",
    "                        if len(ele[0]) ==  pattern[0]: exit_flag_q_id = True\n",
    "                if not exist:\n",
    "                    pattern_str_w_qid.append((list([q_id]), pattern[0], pattern[1]))\n",
    "                    if pattern[0] == 1: exit_flag_q_id = True\n",
    "        \n",
    "        if exit_flag_q_id: break\n",
    "            \n",
    "    # print(\"\\n\\n\")\n",
    "pickle.dump(pattern_str_w_qid, open(\"./Pickle_data/keras_ccspan_2_result_pure.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "722f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_patterns(patterns_lst: list, top: int) -> list:\n",
    "    assert top != 0, \"The top value is wrong!\"\n",
    "    top_list = []\n",
    "    support_set = set()\n",
    "    \n",
    "    # Find the support list\n",
    "    for pattern in patterns_lst:\n",
    "        support_set.add(pattern[0])\n",
    "        \n",
    "    top_support_list = sorted(list(support_set))[0:top]\n",
    "    \n",
    "    for pattern in patterns_lst:\n",
    "        if pattern[0] in top_support_list:\n",
    "            top_list.append(pattern)\n",
    "            \n",
    "    return top_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a455b92-37e7-4d77-8ea1-4312b0a48faf",
   "metadata": {},
   "source": [
    "The below function based on the dic_count dictionary trys to find x top patterns for each window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d07908ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pattern_num = get_top_patterns(result, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3fa153b3-af93-4c74-907f-36fefcce2096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4043"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "7279c556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_num_string(input_list: list, unique_dic: dict) -> list:\n",
    "    convert_lst = []\n",
    "    for pattern in input_list:\n",
    "        string_pattern_tuple = ()\n",
    "        for item in pattern[1]:\n",
    "            string_pattern_tuple = string_pattern_tuple + (unique_dic[item],)\n",
    "        convert_lst.append((pattern[0], string_pattern_tuple))\n",
    "    return convert_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82bce5-7af6-4782-b604-28cfe546b864",
   "metadata": {},
   "source": [
    "The below code converts the number pairs to the string pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d86e89e0-774f-4435-99cf-1b1f6cbbb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pattern_str = convert_num_string(top_pattern_num, uniqe_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f4c8d3ff-a0b4-4464-ba4e-80170401506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_pattern_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdac07b-dca6-4c30-9d08-786f01535355",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Find the Id of a post based on its pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "314c9c2e-1104-466f-ae09-ffb379fbc9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(_2D_array_with_str) == len(_2D_array), \"Always should be the same.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f4fff9b0-4939-474b-9db2-03740e518292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4319"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_Id_array)\n",
    "# , _Id_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4795d690-d2e1-4f04-b37a-8f0eab767651",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, result_remove = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "618652dd-8e19-44fd-bb01-91f6810eeafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_id_based_on_str_pattern(total_IDs: list, pattern_str_lst: list) -> dict:\n",
    "    dict_pattern_and_qid = {}\n",
    "    \n",
    "    for pattern in pattern_str_lst:\n",
    "        for q_id in total_IDs:\n",
    "            # assert not df_w_keras_tags.loc[df_w_keras_tags['Id'] == q_id].Bugy_py_files.empty, \"It's not possible!\"\n",
    "\n",
    "            for item in df_w_keras_tags['Bugy_py_files'].to_numpy()[df_w_keras_tags['Id'].to_numpy() == q_id].item()[1]:\n",
    "            # for item in df_w_keras_tags.loc[df_w_keras_tags['Id'] == q_id].Bugy_py_files.values[0][1]:\n",
    "                if order_sublist(item, list(pattern[1])):\n",
    "                    pattern_tpl = (*pattern[1], )\n",
    "                    if pattern_tpl not in dict_pattern_and_qid.keys():\n",
    "                        dict_pattern_and_qid[pattern_tpl] = set({q_id})\n",
    "                    else:\n",
    "                        dict_pattern_and_qid[pattern_tpl].add(q_id)\n",
    "    return dict_pattern_and_qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "af140a17-af6e-40a5-a774-a111c2db2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q_number(dict_pattern_and_qid: dict) -> int:\n",
    "    q_total_set = set({})\n",
    "    \n",
    "    for key, value in dict_pattern_and_qid.items():\n",
    "        # print(value)\n",
    "        q_total_set.update(value)\n",
    "\n",
    "    return len(q_total_set), q_total_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d8345bd6-b985-49e1-a114-0f5b7accbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3659\n"
     ]
    }
   ],
   "source": [
    "dict_pattern_and_qid = find_q_id_based_on_str_pattern(_Id_array, convert_num_string(result, uniqe_dic))\n",
    "len_q_total_set, q_total_set =  get_q_number(dict_pattern_and_qid)\n",
    "print(len_q_total_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5074b1-ea39-4121-841c-b147b04e6cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lst_q_id_has_pattern = []\n",
    "for top_pattern in top_pattern_str:\n",
    "    # print(\"Pattern(small set): \\t\", top_pattern[1])\n",
    "    for q_id in _Id_array:\n",
    "        # print(q_id)\n",
    "        # assert not df_w_keras_tags.loc[df_w_keras_tags['Id'] == q_id].Bugy_py_files.empty, \"It's pot possible!\"\n",
    "        \n",
    "        for item in df_w_keras_tags['Bugy_py_files'].to_numpy()[df_w_keras_tags['Id'].to_numpy() == q_id].item()[1]:\n",
    "            # print(\"Big set: \\t\", item)\n",
    "            if order_sublist(item, list(top_pattern[1])):\n",
    "                # print(\"Big Set: \\t\", item)\n",
    "                # print(\"Small Set: \\t\", list(top_pattern[1]))\n",
    "                # print(\"\\n\\n\")\n",
    "                lst_q_id_has_pattern.append(q_id)\n",
    "    # print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23791a-9002-46e6-aeb8-2d6b65bb6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lst_q_id_has_pattern, \"It not should be empty.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60bb8a-137e-4bc5-89e3-6bc3c180c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern = df_w_keras_tags.loc[df_w_keras_tags['Id'].isin(lst_q_id_has_pattern)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62807f4-5baf-4a4e-9b22-5e5a030e5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern.rename(columns = {'Id':'Q_id', 'CreationDate':'Q_create_time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc07a5-f62c-488d-b873-b22c99368924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"keras_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58c7cb-163b-4c69-a8ef-d51ec98d694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_w = pd.merge(df_pattern, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"ViewCount\", \"CommentCount\", \"Score\", \"AnswerCount\", \"AcceptedAnswerId\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "df_pattern_ans = pd_tmp_new_w[pd_tmp_new_w.AnswerCount != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e8a96-1d56-4914-b24a-77278e0eb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans = df_pattern_ans[df_pattern_ans.AcceptedAnswerId > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1b206-dfda-47ed-9469-06dc34e4d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_patt_ans(lst_ans_id_1, lst_ans_id_2):\n",
    "    assert set(lst_ans_id_1) == set(lst_ans_id_2), \"We couldn't find all answers.\"\n",
    "    assert len(lst_ans_id_1) == len(lst_ans_id_2), \"The length of answer lists are not the same.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6b524-d003-41d2-a51d-7b36e1306f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_patt_ans(df_pattern_ans.AcceptedAnswerId, df_pattern[df_pattern.AcceptedAnswerId > 0].AcceptedAnswerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f97050-f8ad-4ac2-8339-7f1addc3f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans.insert(len(df_pattern_ans.columns), 'First_ans_time', np.nan)\n",
    "df_pattern_ans.insert(len(df_pattern_ans.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb3a82-8e38-4310-a2ed-1c89601e205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_the_answers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for index1, row_status in df.iterrows():   \n",
    "        flag = 0\n",
    "        fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "        acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "\n",
    "        if not row_status[\"Answer_tup\"]:\n",
    "            pd_tmp_new3_w.at[index1,'First_ans_time'] = np.nan\n",
    "            pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = np.nan\n",
    "            continue\n",
    "\n",
    "        for answer in row_status[\"Answer_tup\"]:\n",
    "\n",
    "            anwer_time = pd.to_datetime(answer[1])\n",
    "\n",
    "            if flag == 0:\n",
    "                fr_time = anwer_time\n",
    "                flag = 1\n",
    "\n",
    "            if fr_time > anwer_time:\n",
    "                fr_time = anwer_time\n",
    "\n",
    "            if row_status[\"AcceptedAnswerId\"] == answer[0]:\n",
    "                acc_time = anwer_time\n",
    "\n",
    "        df.at[index1,'First_ans_time'] = fr_time\n",
    "\n",
    "        if pd.isna(row_status[\"AcceptedAnswerId\"]):\n",
    "            acc_time = np.nan\n",
    "\n",
    "        df.at[index1,'First_acc_ans_time'] = acc_time\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ceb7d8-c5bc-44eb-815b-b3ebd36a92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans = assign_the_answers(df_pattern_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce318475-189c-4af8-9566-054f69be6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans[\"Q_create_time\"]      = pd.to_datetime(df_pattern_ans[\"Q_create_time\"])\n",
    "df_pattern_ans[\"First_acc_ans_time\"] = pd.to_datetime(df_pattern_ans[\"First_acc_ans_time\"])\n",
    "df_pattern_ans[\"First_ans_time\"]     = pd.to_datetime(df_pattern_ans[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bf41c-e69c-4e36-bbdd-b95db19b00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans[\"Duration_ans\"] = df_pattern_ans.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "df_pattern_ans[\"Duration_acc_ans\"] = df_pattern_ans.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4dc3e2-21f2-421d-8432-9acad1c4fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661abcc-2375-4a2d-ac90-bed22f468e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=['Index', 'Q_id', 'Title', 'OS', '# ST-Post', '# ST', 'Link'])\n",
    "\n",
    "for _indx, row in df_pattern.iterrows():\n",
    "    _c = 0\n",
    "    for item in row.Bugy_py_files[1]:\n",
    "        _c += len(item)\n",
    "    _link = \"https://stackoverflow.com/questions/\" + str(row.Q_id)\n",
    "    tmp_dic = {'Index': _indx+1, 'Q_id': row.Q_id, 'Title': row.Title, 'OS': row.Bugy_py_files[0], '# ST-Post': len(row.Bugy_py_files[1]), '# ST': _c, 'Link': _link}\n",
    "    df2 = pd.DataFrame(tmp_dic, index={len(tmp_dic)+1})\n",
    "    df_result = pd.concat([df_result, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf331b-860e-4f6a-91bc-57c99ab10afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/\\\\]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\s\\W*\\d*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?\\/?([^\\<\\>\\:\\\"\\\\\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "# https://regex101.com/r/5yCAdA/1   Unix\n",
    "# https://regex101.com/r/50Vcmo/1 Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139b576-02c8-4019-9829-c5387d7464aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "df_pattern.loc[df_pattern.Q_id == 54219826].Bugy_py_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b8cd9-ab58-4448-a5f6-15b0fb6cb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern.loc[df_pattern.Q_id == 54219826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766c065-c694-422e-b157-19a55f52f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_id_has_trace_wo_err_mess = []\n",
    "c_has_trace   = 0\n",
    "c_has_err_mes = 0\n",
    "\n",
    "def extract_error_messages(id: int, Has_code: bool, Has_trace: bool, code_sec: List) -> Optional[List]:\n",
    "    try:\n",
    "        global lst_id_has_trace_wo_err_mess, c_has_trace, c_has_err_mes\n",
    "        \n",
    "        if Has_trace: c_has_trace += 1\n",
    "        # if not (Has_trace and Has_code): print(f\"Error (2): It's not possiable. Has_code: {Has_code}, Has_trace: {Has_trace}\")\n",
    "            \n",
    "        result_total = []\n",
    "        \n",
    "        for code in code_sec:\n",
    "            # regex = r\"([A-Z]\\w+(Error|Warning|Exception))([^:]*):\\s(.*)$\"\n",
    "            # V3\n",
    "            regex = r\"^([A-Z]\\w+Error)(\\w|\\s|\\(|\\)|\\d)*:\\s(.*)$\"\n",
    "            # regex = r\"([A-Z]\\w+Error):\\s(.*)$\"\n",
    "            code = code.replace(\"\\\\n\", \"\\n\")\n",
    "            code = code.replace('&lt;', '<')\n",
    "            code = code.replace('&gt;', '>')\n",
    "            code = code.replace('&quot;', '\"')\n",
    "            matches = re.finditer(regex, code, re.MULTILINE)\n",
    "            result_each_code_part = []\n",
    "\n",
    "            for matchNum, match in enumerate(matches, start=1):\n",
    "                result_each_code_part.append((match.groups()[0].strip(), match.groups()[2].strip()))\n",
    "            \n",
    "            if result_each_code_part:   # Ignore the empty list\n",
    "                result_total.append(result_each_code_part)\n",
    "\n",
    "        if (not result_total) and Has_trace: \n",
    "            # print(\"Warning!: We have to check this is ID: \", id)\n",
    "            lst_id_has_trace_wo_err_mess.append(id)\n",
    "        \n",
    "        if result_total:\n",
    "            c_has_err_mes += len(result_total)\n",
    "            \n",
    "        return result_total\n",
    "    \n",
    "    except:\n",
    "        print(\"Error(1): \", id)\n",
    "        print(code_sec)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3133ee-8feb-4741-9663-10ba2d5aae6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pattern[\"Err_msg\"] = df_pattern.apply(lambda row: extract_error_messages(row.Q_id, row.Has_code, row.Has_trace, row.Code), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf43e9-7d3c-485a-9a1f-0a2d5da10956",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We captured {c_has_trace} stack traces, however {c_has_trace-len(lst_id_has_trace_wo_err_mess)} stacktraces have a one type of error messages. I mean, {len(lst_id_has_trace_wo_err_mess)} stack traces didn't have any error message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c34043-59ca-49ec-add3-929367024323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_pattern[df_pattern['Err_msg'].map(lambda err_msg_list: len(err_msg_list)) > 0]\n",
    "df_tmp.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609acf2-489e-42c5-bd10-dcebd3796e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg = pd.DataFrame(columns=['Q_id', 'ErrorType', 'ErrorMessage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bcfba-7be1-46f4-95b9-6a44c09d9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_extractor(msg_q_id: str, msg_list: list) -> None:\n",
    "    global df_pattern_err_msg\n",
    "    for msg_t in msg_list:\n",
    "        for message in msg_t:\n",
    "            df_pattern_err_msg = pd.concat([df_pattern_err_msg, pd.DataFrame.from_records([{'Q_id': msg_q_id, 'ErrorType': message[0], 'ErrorMessage': message[1]}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13526342-f7cf-43a0-b013-5acd281f3038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = df_tmp.apply(lambda row: message_extractor(row.Q_id, row.Err_msg), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfe0ce-8a87-473e-bc51-b06e22ca6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d6c77-2c1a-462a-bf95-3e7aec229d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010615a-39a7-4a9b-b211-565e51094f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all the elements are string\n",
    "df_pattern_err_msg = df_pattern_err_msg.applymap(str)\n",
    "\n",
    "# Notice: strip() function will remove leading and trailing whitespaces.\n",
    "df_pattern_err_msg['ErrorType'] = df_pattern_err_msg['ErrorType'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898083b2-8efa-4536-be80-156b6925b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP = 10\n",
    "df_tmp = df_pattern_err_msg.groupby(['ErrorType'])['ErrorType'].count().reset_index(name='count').sort_values(['count'], ascending=False)\n",
    "df2 = df_tmp.iloc[:TOP]\n",
    "df2 = df2.append({'ErrorType': 'Other', 'count': df_tmp['count'].iloc[TOP:].sum()}, ignore_index=True)\n",
    "colors = ['tab:blue', 'tab:cyan', 'tab:gray', 'tab:orange', 'tab:red', 'burlywood', 'y']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "patches, texts, pcts =  ax.pie(df2.set_index('ErrorType')['count'],\n",
    "                               labels=df2['ErrorType'],\n",
    "                                autopct='%1.1f%%', \n",
    "                                pctdistance=0.7, \n",
    "                                labeldistance=1.1, \n",
    "                                # textprops={'fontsize': 12},\n",
    "                                textprops={'size': 'x-large'},\n",
    "                                colors=colors,\n",
    "                                wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'},)\n",
    "\n",
    "s = df2.groupby('ErrorType')['count'].sum().map(lambda x : x).sort_values(ascending = False)\n",
    "labels = [f'{name}, {percentage*100:0.1f}%' for name, percentage in zip(s.index, s / s.sum())]\n",
    "ax.legend(bbox_to_anchor=(1.2, 1), \n",
    "           loc='upper left', \n",
    "           # labels=labels,\n",
    "           title=\"Error Types\",\n",
    "           # labelcolor=colors,\n",
    "           fontsize=14)\n",
    "\n",
    "\n",
    "plt.setp(pcts, color='white', fontweight='bold')\n",
    "ax.set_title(\"keras Error Distribution\", fontsize=18)\n",
    "for i, patch in enumerate(patches):\n",
    "    texts[i].set_color(patch.get_facecolor())\n",
    "    \n",
    "plt.setp(texts, fontweight=600)\n",
    "\n",
    "ax.axis('equal')  \n",
    "# plt.tight_layout()\n",
    "# ax.figure.savefig('piechart.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd039f6a-c399-4022-b617-f3c029525e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frequency of each message type\n",
    "print(df_pattern_err_msg.groupby(['ErrorType'])['ErrorType'].count().reset_index(name='count').sort_values(['count'], ascending=False).nlargest(20, 'count'))\n",
    "df_pattern_err_msg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469d64-2c15-4fa9-81df-790273d8e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score median: \", df_pattern.Score.median())\n",
    "print(\"View median: \", df_pattern.ViewCount.median())\n",
    "print(\"Answer_count median: \", df_pattern.AnswerCount.median())\n",
    "print(\"Comment median: \", df_pattern.CommentCount.median())\n",
    "print(\"# Accepted answer:\", df_pattern.AcceptedAnswerId.count(), \"  Total Accepted answer:\", df_pattern.AcceptedAnswerId.shape[0], \"  Percentage of Accepted answer:\", \"{:.2f}\".format(df_pattern.AcceptedAnswerId.count() *100 / df_pattern.AcceptedAnswerId.shape[0]))\n",
    "print(\"LOC median: \", (df_pattern[df_pattern.Has_trace == True].Line_code_win + df_pattern[df_pattern.Has_trace == True].Line_code_uix).median())\n",
    "print(\"LOP median: \", df_pattern.Q_text_words_num.median())\n",
    "print(\"Answer duration median: \", \"{:.2f}\".format(df_pattern_ans.Duration_ans.median()))\n",
    "print(\"Accepted Answer duration median: \", \"{:.2f}\".format(df_pattern_ans.Duration_acc_ans.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130682a1-c135-4957-aac8-e4f9af3deed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pattern_err_msg.Q_id = df_pattern_err_msg.Q_id.astype(int)\n",
    "df_result.Q_id = df_result.Q_id.astype(int)\n",
    "df_result_mrg = pd.merge(df_pattern_err_msg, df_result, on=[\"Q_id\"], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25154-9b96-4755-a17c-b3ad44a30f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "# print(tabulate(df_pattern_err_msg, headers='keys', tablefmt='psql', showindex=False))\n",
    "# print(tabulate(df_result, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d75c9-e960-47a1-8a40-2324edfec61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    @param filename: File path or existing ExcelWriter\n",
    "                     (Example: '/path/to/file.xlsx')\n",
    "    @param df: DataFrame to save to workbook\n",
    "    @param sheet_name: Name of sheet which will contain DataFrame.\n",
    "                       (default: 'Sheet1')\n",
    "    @param startrow: upper left cell row to dump data frame.\n",
    "                     Per default (startrow=None) calculate the last row\n",
    "                     in the existing DF and write to the next row...\n",
    "    @param truncate_sheet: truncate (remove and recreate) [sheet_name]\n",
    "                           before writing DataFrame to Excel file\n",
    "    @param to_excel_kwargs: arguments which will be passed to `DataFrame.to_excel()`\n",
    "                            [can be a dictionary]\n",
    "    @return: None\n",
    "\n",
    "    Usage examples:\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df)\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df, header=None, index=False)\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df, sheet_name='Sheet2',\n",
    "                           index=False)\n",
    "\n",
    "    >>> append_df_to_excel('d:/temp/test.xlsx', df, sheet_name='Sheet2', \n",
    "                           index=False, startrow=25)\n",
    "\n",
    "    (c) [MaxU](https://stackoverflow.com/users/5741205/maxu?tab=profile)\n",
    "    \"\"\"\n",
    "    # Excel file doesn't exist - saving and exiting\n",
    "    if not os.path.isfile(filename):\n",
    "        df.to_excel(\n",
    "            filename,\n",
    "            sheet_name=sheet_name, \n",
    "            startrow=startrow if startrow is not None else 0, \n",
    "            **to_excel_kwargs)\n",
    "        return\n",
    "    \n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace')\n",
    "\n",
    "    # try to open an existing workbook\n",
    "    writer.book = load_workbook(filename)\n",
    "    \n",
    "    # get the last row in the existing Excel sheet\n",
    "    # if it was not specified explicitly\n",
    "    if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "        startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "    # truncate sheet\n",
    "    if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "        # index of [sheet_name] sheet\n",
    "        idx = writer.book.sheetnames.index(sheet_name)\n",
    "        # remove [sheet_name]\n",
    "        writer.book.remove(writer.book.worksheets[idx])\n",
    "        # create an empty sheet [sheet_name] using old index\n",
    "        writer.book.create_sheet(sheet_name, idx)\n",
    "    \n",
    "    # copy existing sheets\n",
    "    writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d3414-2cb0-4e58-9e91-7cb0349c6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result_mrg.drop(\"Index\", axis=1, inplace=True)\n",
    "# df_result_mrg.to_excel(\"../Emp_st_p_1.xlsx\", sheet_name='keras') \n",
    "# df_result_mrg.drop(\"Index\", axis=1, inplace=True)\n",
    "append_df_to_excel(\"../Emp_st_p_1.xlsx\", df_result_mrg, sheet_name='keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cced58-9ff8-4848-9327-7adc8c285af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create covered question plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a700189b-9906-404b-8085-9c957ca04684",
   "metadata": {},
   "source": [
    "Create the x-axist: sorted based on the support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d38b9-6de8-4149-b666-7401ba1c8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str = convert_num_string(result, uniqe_dic)\n",
    "len(result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a31c7f-753a-447e-87b2-58ac5a0f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str_rev_sorted = sorted(result_str, key=lambda tup: tup[0], reverse=True)\n",
    "x_number_of_patterns = list(range(1, len(result_str_rev_sorted)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81c2f7-d4ff-4a20-a51d-9d8fd747172b",
   "metadata": {},
   "source": [
    "Create the y-axist: % of coverd questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f55323-d4b7-4219-b371-eff271162abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_unique_questions, set_of_unique_questions = get_q_number(dict_pattern_and_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0aa1b-a93b-4125-9de9-b9d86d5f4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_questions = set()\n",
    "y_axis_peresentage_of_coverage = []\n",
    "for support, pattern in result_str_rev_sorted:    \n",
    "    visited_questions.update(dict_pattern_and_qid[pattern])\n",
    "    if len(visited_questions) < len(set_of_unique_questions):\n",
    "        y_axis_peresentage_of_coverage.append(len(visited_questions)*100/len(set_of_unique_questions))\n",
    "    elif len(visited_questions) > len(set_of_unique_questions):\n",
    "        print(\"Error(100)!\")\n",
    "    elif len(visited_questions) == len(set_of_unique_questions):\n",
    "        y_axis_peresentage_of_coverage.append(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518f55d-5d49-4f26-a0d0-fa4339316d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=110)\n",
    "\n",
    "ax.plot(x_number_of_patterns, y_axis_peresentage_of_coverage, '-', color='green', linewidth=2)\n",
    "\n",
    "ax.set_title('Keras', fontname=\"Times New Roman\", fontsize=16)\n",
    "\n",
    "ax.set_xlabel('The number of patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(range(1, max(x_number_of_patterns)+1, 200))\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.set_ylabel('The percentage of covered questions', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, 101, 10))\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('sp_le_rq1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba5753-81d9-4698-926c-8442cbf11982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dic_keras_covered_ques = {\"x\":x_number_of_patterns, \"y\":y_axis_peresentage_of_coverage}\n",
    "pickle.dump(plt_dic_keras_covered_ques, open(\"./Pickle_data/plt_dic_keras_covered_ques.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d5666-371d-436f-a415-e6be8de02df3",
   "metadata": {},
   "source": [
    "## Answer time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448de367",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Answer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b763dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pure_ans_data = working_directory_path + \"ansSample.csv\"\n",
    "# path_ans = Path(pure_ans_data)\n",
    "\n",
    "# if path_ans.suffix == \".csv\":\n",
    "#     df_ans = pd.read_csv(path_ans, encoding=encoding)\n",
    "# else:\n",
    "#     raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf259d-561a-4487-9908-da7e4da40191",
   "metadata": {},
   "source": [
    "## Create DF based on the questions contain stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_info\"] = Question_with_trace_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_with_trace_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_id\"]          = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_status_w_stack[\"Q_create_time\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_status_w_stack[\"View_count\"]    = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_status_w_stack[\"Answer_count\"]  = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_status_w_stack[\"Comment_count\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_status_w_stack[\"Score\"]         = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_status_w_stack[\"Accepted_Answer_id\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28deb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack = df_status_w_stack.drop(['Q_info'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_create_time\"]      = pd.to_datetime(df_status_w_stack[\"Q_create_time\"])\n",
    "df_status_w_stack[\"First_acc_ans_time\"] = pd.to_datetime(df_status_w_stack[\"First_acc_ans_time\"])\n",
    "df_status_w_stack[\"First_ans_time\"]     = pd.to_datetime(df_status_w_stack[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd1bbb",
   "metadata": {},
   "source": [
    "#### Filling the Answers column: A list contains the id and time of answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7d931-c4d3-492a-8276-abc6de000ea3",
   "metadata": {},
   "source": [
    "We have to prepare and find answers that has sp parrentID, so first we catch the questions and store as table in DB. Before this job we have to create a table with all answrs and apply inner join to those tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8093c-3c26-4d31-adab-ad1c4bd66959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_id\"].to_csv('../code_output_csv/df_keras_w_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61f7376f-6f99-46ba-ac0e-296c646279bd",
   "metadata": {},
   "source": [
    "SELECT df_keras_w_stack.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_keras_w_stack\n",
    "INNER JOIN all_results\n",
    "ON df_keras_w_stack.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bf191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"keras_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4de2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_status_w_stack['Answers'] = df_status_w_stack.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9770ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index1, row_status in df_status_w_stack.iterrows():\n",
    "#     for index2, row_night in df_night.iterrows():\n",
    "#             if row_night[\"ParentId\"] == row_status[\"Q_id\"]:\n",
    "#                     row_status['Answers'].append((row_night[\"Id\"], row_night[\"CreationDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e9b00-b12d-498a-a816-9284be6bf1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3732d4c-0d2b-4cfa-9cd3-c1ad1472244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_w = pd.merge(df_status_w_stack, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new2_w = pd_tmp_new_w[pd_tmp_new_w.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack[\"Answers\"] = df_status_w_stack[\"Answers\"].apply(lambda answers_list: list(set(answers_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2f339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_status_w_stack.apply(lambda row: checker_1(row.name, row.Answers, row.Answer_count), axis=1)\n",
    "_ = pd_tmp_new2_w.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735f1d5-381b-454f-b369-0968480dfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7019b-2ab6-4088-91ac-ad6ae20eceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w = pd_tmp_new2_w.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a596f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_w.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_w.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_w.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = acc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847107e7",
   "metadata": {},
   "source": [
    "Write df_status_w_stack to the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.to_csv('./status_PT_df_w_stack_with_list_of_answers_col.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4253bbc",
   "metadata": {},
   "source": [
    "Read df_status_w_stack from the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f760c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack = pd.read_csv('./status_df_w_stack_with_list_of_answers_col.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a424d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack[\"Duration_ans\"] = df_status_w_stack.apply(lambda row: (row.First_ans_time-row.Q_create_time).days, axis=1)\n",
    "# df_status_w_stack[\"Duration_acc_ans\"] = df_status_w_stack.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).days, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_acc_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new3_w['Duration_ans'] = pd_tmp_new3_w['Duration_ans'].fillna(0)\n",
    "# pd_tmp_new3_w['Duration_acc_ans'] = pd_tmp_new3_w['Duration_acc_ans'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d09fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19800ec",
   "metadata": {},
   "source": [
    "## Create DF based on the questions do not have stack traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57682814-ce03-41e4-88d5-1ed524f79811",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have to prepare and find answers that has Pytorch parrentID, so first we catch the questions and store as table in DB. Before this job we have to create a table with all answrs and apply inner join to those tables:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ece49f68-9d28-4236-957e-0a98cd01b9f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "SELECT df_keras_wo_stack.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_keras_wo_stack\n",
    "INNER JOIN all_results\n",
    "ON df_keras_wo_stack.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f26363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"db_results/\" + \"keras_ans_all.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night_wo = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c567d8-93cd-488a-9715-2c3b6a011077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2258f0-f3e4-4a6a-99a1-9413d666c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195bf92-32fc-45a2-8560-d3e654b35132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_night_wo.drop_duplicates([\"Q_id\", \"Id\", \"ParentId\", \"CreationDate\"], ignore_index=False, inplace=True)\n",
    "df_night_wo = df_night_wo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_status_wo_stack[\"Q_info\"] = Question_with_wo_trace_info\n",
    "\n",
    "df_status_wo_stack[\"Q_id\"]          = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_status_wo_stack[\"Q_create_time\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_status_wo_stack[\"View_count\"]    = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_status_wo_stack[\"Answer_count\"]  = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_status_wo_stack[\"Comment_count\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_status_wo_stack[\"Score\"]         = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_status_wo_stack[\"Accepted_Answer_id\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[6])\n",
    "\n",
    "df_status_wo_stack = df_status_wo_stack.drop(['Q_info'], axis='columns')\n",
    "\n",
    "df_status_wo_stack[\"Q_create_time\"] = pd.to_datetime(df_status_wo_stack[\"Q_create_time\"])\n",
    "df_status_wo_stack[\"First_acc_ans_time\"] = pd.to_datetime(df_status_wo_stack[\"First_acc_ans_time\"])\n",
    "df_status_wo_stack[\"First_ans_time\"]     = pd.to_datetime(df_status_wo_stack[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a896da-2513-472b-8562-a80b6b4c9ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_status_wo_stack[\"Q_id\"].to_csv('../code_output_csv/df_keras_wo_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe64a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02caaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack['Answers'] = df_status_wo_stack.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dca9f-f50d-4844-8636-0c9163cb68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006ded-2978-4735-9e8d-1c6f818c5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca48d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # It is super time-consuming and never run!\n",
    "# for index1, row_status in df_status_wo_stack.iterrows():\n",
    "#     for index2, row_night in df_night_wo.iterrows():\n",
    "#         if row_night[\"ParentId\"] == row_status[\"Q_id\"]:\n",
    "#                 row_status['Answers'].append((row_night[\"Id\"], row_night[\"CreationDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd65ef-8327-4d89-b46a-0b6c9e701df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_wo = pd.merge(df_status_wo_stack, df_night_wo, how='left',left_on=['Q_id'],right_on=['ParentId']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4bb1c-c844-4fb1-b291-4a243d589c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_tmp_wo[\"Answer_tup\"] = pd_tmp_wo.apply(lambda x: (x.Id, x.CreationDate), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399421d6-ecc5-41bf-872d-52d39610d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new = pd_tmp.groupby([\"First_ans_time\", \"First_acc_ans_time\", \"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"])[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new_wo = pd_tmp_wo.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf8935-4cfb-4a8f-93ea-8a85965cf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo = pd_tmp_new_wo[pd_tmp_new_wo.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2daa7-d193-4d18-b974-b71b7d697cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checker_ans_and_ans_tup(row_indx: int, ans_count: int, ans_list: list) -> None:\n",
    "#     if len(ans_list) != ans_count:\n",
    "#         print(\"Error!: \", row_indx, ans_count, ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2018458-7fd9-4ca3-9da1-5714b03e3e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We checked all Q_id_x are unique\n",
    "_ = pd_tmp_new2_wo.apply(lambda row: checker_ans_and_ans_tup(row.Q_id_x, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abeea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_wo_stack[\"Answers\"] = df_status_wo_stack[\"Answers\"].apply(lambda answers_list: list(set(answers_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdae5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_status_wo_stack.apply(lambda row: checker_1(row.name, row.Answers, row.Answer_count), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c2fbc-1102-4751-bb8f-8d7d484182fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f892ae5-e359-4a30-ae5e-255cc23ae8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb04af7-e1a0-459f-a6a9-220ec4df1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_wo.insert(len(pd_tmp_new2_wo.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28955ecd-1434-4f76-bac1-6da683f872f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_wo = pd_tmp_new2_wo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_wo.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        pd_tmp_new3_wo.at[index1,'First_ans_time'] = np.nan\n",
    "        pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = np.nan\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_wo.at[index1,'First_ans_time'] = fr_time\n",
    "        \n",
    "    if pd.isna(row_status[\"Accepted_Answer_id\"]):\n",
    "        acc_time = np.nan\n",
    "    \n",
    "    pd_tmp_new3_wo.at[index1,'First_acc_ans_time'] = acc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f34b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_wo[\"Duration_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_ans_time) else np.nan, axis=1)\n",
    "pd_tmp_new3_wo[\"Duration_acc_ans\"] = pd_tmp_new3_wo.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600 if not pd.isna(row.First_acc_ans_time) else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1467f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new3_wo['Duration_ans'] = pd_tmp_new3_wo['Duration_ans'].fillna(0)\n",
    "# pd_tmp_new3_wo['Duration_acc_ans'] = pd_tmp_new3_wo['Duration_acc_ans'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac7769",
   "metadata": {},
   "source": [
    "### Find the durarion of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e7aaf-49d8-434f-93c2-1a5874830b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to delete rows or posts that doesn't have answer, because their zero values affect the meadian value (or the box plot values):\n",
    "# df_status_w_stack_filtered = pd_tmp_new3_wo[pd_tmp_new3_wo[\"Answer_count\"] > 0]\n",
    "# pd_tmp_new3_filtered = pd_tmp_new3_w[pd_tmp_new3_w[\"Answer_count\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33ac9d-d93f-423f-bec9-f1c38644a4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd_tmp_new3_w[[\"Q_create_time\", \"First_ans_time\", \"Answer_count\", \"Duration_ans\"]].head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355b03d-d61b-4124-9ce2-7dddc08b253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w[[\"Q_create_time\", \"First_ans_time\", \"Answer_count\", \"Duration_ans\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d041705-edf2-43bf-a88e-45f9d3036f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.to_csv('./CSV_data/plt_df_keras_w_ans_stack.csv', encoding='utf-8')\n",
    "pd_tmp_new3_wo.to_csv('./CSV_data/plt_df_keras_wo_ans_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005c133-bf61-4d79-acc3-19f170740a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_w['Duration_ans']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_wo['Duration_ans']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "resultComment = pd.concat([df_1, df_2])\n",
    "resultComment['Type'] = \"First Answer\"\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_w['Duration_acc_ans']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_wo['Duration_acc_ans']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "resultAnswer = pd.concat([df_1, df_2])\n",
    "resultAnswer['Type'] = \"First Accepted Answer\"\n",
    "# ###################################################################################\n",
    "\n",
    "result = pd.concat([resultComment, resultAnswer], ignore_index=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Hours\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               # scale=\"count\",\n",
    "               # inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-5000,10000)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Answers Duration (keras Questions)')\n",
    "# fig.suptitle('TensorFlow Questions', prop={\"size\":10})\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb65388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Questions (with stack traces)', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_w['Duration_ans']\n",
    "df_1['Questions (with stack traces)'] = df_1['Questions (with stack traces)'].apply(lambda x: \"First Answer\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions (with stack traces)', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_w['Duration_acc_ans']\n",
    "df_2['Questions (with stack traces)'] = df_2['Questions (with stack traces)'].apply(lambda x: \"First Accepted Answer\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "\n",
    "# Reset index\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=result[\"Questions (with stack traces)\"], y=result[\"Hours\"])\n",
    "\n",
    "# plt.ylim(-250,500)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "# # min_ = min(min(df_status_w_stack['Duration_ans']), min(df_status_w_stack['Duration_acc_ans']))\n",
    "# # max_ = max(max(df_status_w_stack['Duration_ans']), max(df_status_w_stack['Duration_acc_ans']))\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# sns.violinplot(data=df_status_w_stack['Duration_ans'])\n",
    "# ax1.set_xlabel(\"First Answer\")\n",
    "# ax1.set_ylabel(\"Day\")\n",
    "# # ax1 = plt.ylim(min_,max_)\n",
    "\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# sns.violinplot(data=df_status_w_stack['Duration_acc_ans'])\n",
    "# ax2.set_xlabel(\"First Accepted Answer\")\n",
    "# ax2.set_ylabel(\"Day\")\n",
    "# # ax2 = plt.ylim(min_,max_)\n",
    "\n",
    "fig.suptitle('Answers Duration (with stack traces)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b540d9-50f5-4867-be9a-e13e9bd585ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Questions (W/O stack traces)', 'Hours'])\n",
    "df_1['Hours'] = pd_tmp_new3_wo['Duration_ans']\n",
    "df_1['Questions (W/O stack traces)'] = df_1['Questions (W/O stack traces)'].apply(lambda x: \"First Answer\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions (W/O stack traces)', 'Hours'])\n",
    "df_2['Hours'] = pd_tmp_new3_wo['Duration_acc_ans']\n",
    "df_2['Questions (W/O stack traces)'] = df_2['Questions (W/O stack traces)'].apply(lambda x: \"First Accepted Answer\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "\n",
    "# Reset index\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=result[\"Questions (W/O stack traces)\"], y=result[\"Hours\"])\n",
    "\n",
    "# plt.ylim(-250,500)\n",
    "\n",
    "fig.suptitle('Answers Duration (W/O stack traces)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd473e",
   "metadata": {},
   "source": [
    "## Statistics Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question Numbers with all ML tags: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac51430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question Numbers (with keras tags): \", df_w_keras_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817104d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question Numbers (without keras tags): \", df.shape[0] - df_w_keras_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"keras Question Numbers (with code): \", count__question_w_code)\n",
    "print(\"keras Question Numbers (without code): \", count__question_wo_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356dcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"keras Question Numbers (with code) have stack trace: \", count_w_t)  # 40 disappeared ?!\n",
    "print(\"keras Question Numbers (with code) that doesn't have stack trace: \",count_wo_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebaf5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"keras Question Numbers (with stack trace:) on Unix based systems: \", count_unix)\n",
    "print(\"keras Question Numbers (with stack trace:) on Windows based systems: \", count_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777daa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "line_count_unix   = 0\n",
    "line_count_win    = 0\n",
    "line_count_simple = 0\n",
    "\n",
    "for tuple in df_w_keras_tags[\"Line_code_u_w_s\"]:\n",
    "    line_count_unix   += tuple[0]\n",
    "    line_count_win    += tuple[1]\n",
    "    line_count_simple += tuple[2]\n",
    "        \n",
    "print(f\"The total number of line codes in the body part (w/o stack trace) is {line_count_simple}.\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_unix} (Unix-based reports).\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_win} (Windows-based reports).\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_unix+line_count_win}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13260028-8d85-4f82-8d22-ca47a7e5b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We found {max(dic.values())} unique pairs in stack traces posts related to the keras frameworks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d46d5-b096-40ca-83c2-f72897d7114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# print(\"Pst: \", '{:,}'.format(df_w_keras_tags.shape[0]), \"\\nPst_wc: \", math.ceil(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \"\\nPst_woc:\", 100-math.ceil(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \"\\nCB:\", '{:,}'.format(count__num_codes), \"\\nCB_ws:\", math.ceil(count_w_t*100/(count_w_t+count_wo_t)), \"\\nCB_wos:\", 100-(math.ceil(count_w_t*100/(count_w_t+count_wo_t))) , \"\\nST:\", '{:,}'.format(count_w_t), \"\\nU:\", math.ceil(count_unix*100/count_w_t), \"\\nW:\",100-math.ceil(count_unix*100/count_w_t))\n",
    "print(\"Pst: \", '{:,}'.format(df_w_keras_tags.shape[0]), \"\\nPst_wc: \", \n",
    "      '{0:0.2f}'.format(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \n",
    "      \"\\nPst_woc:\", '{0:0.2f}'.format(100-(count__question_w_code*100/(count__question_w_code+count__question_wo_code))), \n",
    "      \"\\nCB:\", '{:,}'.format(count__num_codes), \n",
    "      \"\\nCB_ws:\", '{0:0.2f}'.format(count_w_t*100/(count_w_t+count_wo_t)), \n",
    "      \"\\nCB_wos:\", '{0:0.2f}'.format(100-(count_w_t*100/(count_w_t+count_wo_t))) , \n",
    "      \"\\nST:\", '{:,}'.format(count_w_t), \n",
    "      \"\\nU:\", '{0:0.2f}'.format(count_unix*100/count_w_t), \n",
    "      \"\\nW:\",'{0:0.2f}'.format(100-(count_unix*100/count_w_t)))\n",
    "\n",
    "print( '{:,}'.format(df_w_keras_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \n",
    "      '& {0:0.1f}\\%'.format(100-(count__question_w_code*100/(count__question_w_code+count__question_wo_code))), \n",
    "      '& {:,}'.format(count__num_codes), \n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/(count_w_t+count_wo_t)), \n",
    "      '& {0:0.1f}\\%'.format(100-(count_w_t*100/(count_w_t+count_wo_t))) , \n",
    "      '& \\multicolumn{1}{r:}{\\\\textbf{', count_w_t, '}}',\n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/df_w_keras_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count_unix*100/count_w_t), \n",
    "      '& {0:0.1f}\\%'.format(100-(count_unix*100/count_w_t)))\n",
    "\n",
    "print( '{:,}'.format(df_w_keras_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \n",
    "      '& {:,}'.format(count__num_codes), \n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/(count_w_t+count_wo_t)), \n",
    "      '& \\multicolumn{1}{r:}{\\\\textbf{', count_w_t, '}}',\n",
    "      '& {0:0.1f}\\%'.format(count_w_t*100/df_w_keras_tags.shape[0]), \n",
    "      '& {0:0.1f}\\%'.format(count_unix*100/count_w_t), \n",
    "      '& {0:0.1f}\\%'.format(100-(count_unix*100/count_w_t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808f478-1be0-46aa-b0e3-81e90bbb5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"w-ST:\", '{:,}'.format(count_w_t), \"wo-ST:\", '{:,}'.format(count_wo_t))\n",
    "ACC_W, ACC_WO = 87 , 69\n",
    "print('P1: {0:0.4f}'.format(ACC_W/count_w_t))\n",
    "print('N1: {}'.format(count_w_t))\n",
    "print('P2: {0:0.4f}'.format(ACC_WO/count_wo_t))\n",
    "print('N2: {}'.format(count_wo_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01a48e",
   "metadata": {},
   "source": [
    "## Graphical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f3688",
   "metadata": {},
   "source": [
    "### LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_wo_trace  = df_w_keras_tags[(df_w_keras_tags.Has_code == True) & (df_w_keras_tags.Has_trace == False)].Line_code_simple_code\n",
    "code_w_trace   = df_w_keras_tags[df_w_keras_tags.Has_trace == True].Line_code_win + df_w_keras_tags[df_w_keras_tags.Has_trace == True].Line_code_uix\n",
    "\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'LOC (in each question post)'])\n",
    "df_1['LOC (in each question post)'] = code_wo_trace\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"code blocks w/o stack trace\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'LOC (in each question post)'])\n",
    "df_2['LOC (in each question post)'] = code_w_trace\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"code blocks with stack trace\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "result.to_csv('./CSV_data/plt_df_loc_keras.csv', encoding='utf-8', index=False)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"LOC (in each question post)\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               # scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(-15, 100)\n",
    "# plt.xlim(-1, 1)\n",
    "\n",
    "fig.suptitle('Comparing the LOC between regular code and stack trace')\n",
    "\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":8})\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf06607",
   "metadata": {},
   "source": [
    "### Question Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198cd0c-00e6-4673-96e0-300b3dc0492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Words (in each question post)'])\n",
    "df_1['Words (in each question post)'] = list_num_words_wo_tra\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"w/o stack trace\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Words (in each question post)'])\n",
    "df_2['Words (in each question post)'] = list_num_words_w_tra\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"with stack trace\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aebb4b-37f8-4817-a1d3-a0d462cbad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./CSV_data/plt_df_ques_len_keras.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92381996",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Words (in each question post)\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(0, 300)\n",
    "# plt.xlim(-1, 1)\n",
    "\n",
    "fig.suptitle('Comparing the Question Length')\n",
    "\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":8})\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4fb36",
   "metadata": {},
   "source": [
    "### Plotting Score, View, Answer, Comment Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593359f-60ab-48a0-b48c-a93d7f61679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack.to_csv('./CSV_data/plt_df_keras_w_table3_stack.csv', encoding='utf-8')\n",
    "df_status_wo_stack.to_csv('./CSV_data/plt_df_keras_wo_table3_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sturges_rule_number(n_obser: int) -> int:\n",
    "    '''\n",
    "    Sturges Rule is the most common method for determining the optimal number of bins.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    n_obser : int\n",
    "        The total number of observations in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    Use   for returning a value: Symbols that mean ceiling  i.e. round the answer up to\n",
    "    the nearest integer.\n",
    "    '''\n",
    "    # return round(1 + math.log2(n_obser))\n",
    "    return round(np.ceil(1 + (3.322 * np.log10(n_obser))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('View Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nView Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['View_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['View_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='purple', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(False)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('View Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nView Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['View_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['View_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='purple', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=15)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['View_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['View_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(-2500,13000)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('View Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8319c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Answer Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nAnswer Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Answer_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Answer_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='g', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Answer Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nAnswer Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Answer_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Answer_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='g', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Answer_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Answer_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-.5,4.1)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Answer Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Comment Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nComment Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Comment_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Comment_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='b', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Comment Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nComment Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Comment_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Comment_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='b', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a20d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Comment_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Comment_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-1.1,10)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Comment Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d464c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Comment_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Comment_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "resultComment = pd.concat([df_1, df_2])\n",
    "resultComment['Type'] = \"Comment Count\"\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Answer_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Answer_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "resultAnswer = pd.concat([df_1, df_2])\n",
    "resultAnswer['Type'] = \"Answer Count\"\n",
    "# ###################################################################################\n",
    "# df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_1['Frequency'] = df_status_wo_stack['View_count']\n",
    "# df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "# df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_2['Frequency'] = df_status_w_stack['View_count']\n",
    "# df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "# resultView = pd.concat([df_1, df_2])\n",
    "# resultView['Type'] = \"View Count\"\n",
    "# ###################################################################################\n",
    "# df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_1['Frequency'] = df_status_wo_stack['Score']\n",
    "# df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "# df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_2['Frequency'] = df_status_w_stack['Score']\n",
    "# df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "# resultScore = pd.concat([df_1, df_2])\n",
    "# resultScore['Type'] = \"Score Count\"\n",
    "# ###################################################################################\n",
    "result = pd.concat([resultComment, resultAnswer], ignore_index=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-1,6)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('keras Questions')\n",
    "# fig.suptitle('TensorFlow Questions', prop={\"size\":10})\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Score Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nScore Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Score']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Score'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='orange', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Score Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nScore Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Score']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Score'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='orange', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Score']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Score']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-7,15)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Score Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c70366-05e3-42b2-86cc-f11621064f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2, result_remove2 = CloConSeqGen_v3(dic_count, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756060e6-a3a2-4d09-8f92-b4fdbb0d518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size_list_2 = []\n",
    "for element in result2:\n",
    "    win_size_list_2.append(len(element[1]))\n",
    "win_size_set_2 = set(win_size_list_2)\n",
    "cnt_2=collections.Counter(win_size_list_2)\n",
    "\n",
    "x = np.array(sorted(cnt_2.keys())) # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "patters_num_2 = []\n",
    "for key in sorted(cnt_2.keys()) :\n",
    "    patters_num_2.append(cnt_2[key])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=110)\n",
    "\n",
    "x = [str(item) for item in x] \n",
    "\n",
    "rects2 = ax.bar(x, patters_num_2, width, label='Support Threshold = 2')\n",
    "\n",
    "ax.set_title('Keras', fontname=\"Times New Roman\", fontsize=16)\n",
    "ax.legend(prop={'family':'Times New Roman', 'size':10}, facecolor='w', framealpha=1)\n",
    "\n",
    "ax.set_xlabel('Pattern\\'s length', fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "\n",
    "ax.set_ylabel('The number of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, max(patters_num_2)+1, 100))\n",
    "\n",
    "ax.bar_label(rects2, padding=3)\n",
    "\n",
    "win_size_list = []\n",
    "for element in result2:\n",
    "    win_size_list.append(len(element[1]))\n",
    "win_size_set = set(win_size_list)\n",
    "counter=collections.Counter(win_size_list)\n",
    "\n",
    "counter = dict(sorted(counter.items()))\n",
    "comulative_y = np.cumsum(list(counter.values()))\n",
    "\n",
    "per_list_patterns = []\n",
    "for element in comulative_y:\n",
    "    per_list_patterns.append((element*100)/comulative_y[-1])\n",
    "\n",
    "x2 = counter.keys() \n",
    "x2 = [str(item) for item in x2] \n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(x2, per_list_patterns, '-o', color='green', linewidth=2)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax2.set_ylabel('Cumulative % of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "\n",
    "ax2.grid(axis = 'y', color='green', linestyle='--', linewidth=0.5)\n",
    "# ax2.grid(False)\n",
    "ax.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('keras_le_rq1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb2ba5-102f-47ba-9912-fdafc7edbaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dic_keras_plength_rq1 = {\"x\":x, \"y2\":per_list_patterns, \"y1\": patters_num_2}\n",
    "pickle.dump(plt_dic_keras_plength_rq1, open(\"./Pickle_data/plt_dic_keras_plength_rq1.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49fefc-c53a-4b58-9bfa-30ee2dd2207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "result2, result_remove2 = CloConSeqGen_v3(dic_count, threshold=2)\n",
    "      \n",
    "sorted_result2 = sorted(result2, key=lambda tup: tup[0])\n",
    "\n",
    "sup_x = sorted(set([element[0] for element in result2]))\n",
    "\n",
    "len_sup_y = []\n",
    "lst_supp = [y[0] for y in sorted_result2]\n",
    "\n",
    "cnt = collections.Counter(lst_supp)\n",
    "for item in sup_x:\n",
    "    len_sup_y.append(cnt[item])\n",
    "    \n",
    "comulative_y = np.cumsum(list(cnt.values()))\n",
    "\n",
    "per_len_sup_y = []\n",
    "for element in comulative_y:\n",
    "    per_len_sup_y.append((element*100)/comulative_y[-1])\n",
    "per_len_sup_y = [100-x for x in per_len_sup_y]\n",
    "per_len_sup_y.insert(0, 100)\n",
    "per_len_sup_y.pop()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(35, 6), dpi=110)\n",
    "sup_x = [str(item) for item in sup_x] \n",
    "\n",
    "rects = ax.bar(sup_x, len_sup_y, width=0.5, label='Support Threshold = 2')\n",
    "\n",
    "ax.set_title('Keras', fontname=\"Times New Roman\", fontsize=16)\n",
    "ax.legend(prop={'family':'Times New Roman', 'size':10}, facecolor='w', framealpha=1)\n",
    "\n",
    "ax.set_xlabel('Support', fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_xticks(sup_x)\n",
    "plt.xlim([-1, len(sup_x)])\n",
    "\n",
    "ax.set_ylabel('The number of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "ax.set_yticks(range(0, max(len_sup_y)+1, 100))\n",
    "\n",
    "ax.bar_label(rects, padding=3)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "plt.plot(sup_x, per_len_sup_y, '--o', color='orange', linewidth=2)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax2.set_ylabel('Cumulative % of stack trace patterns', labelpad=10, fontname=\"Times New Roman\", fontsize=14)\n",
    "\n",
    "ax2.grid(axis = 'y', color='orange', linestyle='--', linewidth=0.5)\n",
    "# ax2.grid(False)\n",
    "ax.grid(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('keras_sup_rq1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e624e0-5237-45af-aa0f-2e71e7b7c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dic_keras_sup_rq1 = {\"x\":sup_x, \"y2\":per_len_sup_y, \"y1\": len_sup_y}\n",
    "pickle.dump(plt_dic_keras_sup_rq1, open(\"./Pickle_data/plt_dic_keras_sup_rq1.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
