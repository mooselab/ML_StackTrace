{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782e8f80-78a9-4e0b-9384-896f365185cf",
   "metadata": {},
   "source": [
    "# Stack Traces Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515ef5d",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea3aa8e-15cb-4ec1-b427-1144fcc9f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Union, Tuple\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "import string\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from itertools import permutations\n",
    "import heapq\n",
    "import csv\n",
    "\n",
    "# pd.options.display.max_colwidth = 500\n",
    "# pd.options.display.max_columns = None\n",
    "# pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925ffd5",
   "metadata": {},
   "source": [
    "## Setting up the project environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725feedf-a5c7-4192-aa8f-3ca77a152adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .csv configuration\n",
    "encoding = \"utf-8\"\n",
    "delimiter = None\n",
    "working_directory_path = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c38ac-0fcf-425c-91bb-813366418dbf",
   "metadata": {},
   "source": [
    "## Loading the question dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03769f4-5831-40d4-84ea-4262e234886b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"question_tag.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6396565-7035-4813-8fd1-5572a916c8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163194, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e408693",
   "metadata": {},
   "source": [
    "## Answering the first research question (RQ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a6e6e-46f4-432b-81c6-a5f646d6dd08",
   "metadata": {},
   "source": [
    "### Filtering the specific tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae1d276-5b01-482b-b244-cd89bef86bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_filter(pref_tags: List, tags: str) -> bool:\n",
    "    regex = \"\"\n",
    "    for tag in pref_tags:\n",
    "        regex += '(?=.*\\\\b'+ tag +'([+-]?([0-9]*[.])?[0-9]*)\\\\b)'\n",
    "    regex = r\"^\" + regex + \".*$\"\n",
    "    tags = tags.strip().lower()\n",
    "    match_result = re.match(regex, tags, re.MULTILINE | re.IGNORECASE)\n",
    "    if match_result is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b05dfaf-8a60-4a86-b341-b78d16a32226",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"tensorflow\", \"python\"]\n",
    "df['HasPreferableTags'] = df['Tags'].apply(lambda row_tags: tag_filter(tags, row_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b740ac-83e0-45f1-a2be-e8825609ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags = df[df['HasPreferableTags']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2d3ed2-b450-4151-8856-352d7e8a2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags = df_w_Tens_tags.drop(['HasPreferableTags'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb5366-8428-4aaa-b345-18e04a3f5f4b",
   "metadata": {},
   "source": [
    "We found there are some duplocated rows in our DB, so we eleminate those based on some columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8b23cc-bffd-4fc3-a8c6-1fae9798336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags.drop_duplicates([\"Id\", \"PostTypeId\", \"AcceptedAnswerId\", \"ViewCount\", \"AnswerCount\", \"CommentCount\", \"Score\", \"Title\"], ignore_index=False, inplace=True)\n",
    "df_w_Tens_tags = df_w_Tens_tags.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4ce84-4d78-4782-ac06-b717021702e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "The new dataset that has a specific tag/s is reduced to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15fdfa92-2d73-4f6c-af4d-4a814b7d11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The orginal DB:  163194\n",
      "The new DB (Tensorflow):  39690\n",
      "The difference is:  123504\n"
     ]
    }
   ],
   "source": [
    "print(\"The orginal DB: \", df.shape[0])\n",
    "print(\"The new DB (Tensorflow): \", df_w_Tens_tags.shape[0])\n",
    "print(\"The difference is: \", df.shape[0] - df_w_Tens_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77bd29b-e1ab-4a3e-9456-6530a4d91197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39690, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_Tens_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2050397c-ca76-4c95-843d-71fbd9940991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43574928</td>\n",
       "      <td>1</td>\n",
       "      <td>43575038.0</td>\n",
       "      <td>2017-04-23 18:30:08</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>How to use custom/non-default tf.Graph in Tens...</td>\n",
       "      <td>&lt;p&gt;I'm very new to &lt;code&gt;Tensorflow&lt;/code&gt; and...</td>\n",
       "      <td>&lt;python&gt;&lt;session&gt;&lt;graph&gt;&lt;parallel-processing&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52019226</td>\n",
       "      <td>1</td>\n",
       "      <td>52019631.0</td>\n",
       "      <td>2018-08-25 16:32:19</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Keras w/ Tensorflow intermediate layer extract...</td>\n",
       "      <td>&lt;p&gt;I am currently trying to leverage an interm...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;&lt;deep-learning&gt;&lt;bat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  PostTypeId  AcceptedAnswerId         CreationDate  ViewCount  AnswerCount  CommentCount  Score                                              Title                                               Body                                               Tags\n",
       "0  43574928           1        43575038.0  2017-04-23 18:30:08       1118            1             0      3  How to use custom/non-default tf.Graph in Tens...  <p>I'm very new to <code>Tensorflow</code> and...  <python><session><graph><parallel-processing><...\n",
       "1  52019226           1        52019631.0  2018-08-25 16:32:19        312            1             2      0  Keras w/ Tensorflow intermediate layer extract...  <p>I am currently trying to leverage an interm...  <python><tensorflow><keras><deep-learning><bat..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_Tens_tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28990026-83cc-4af5-94f6-5b2a75eb41f7",
   "metadata": {},
   "source": [
    "### Extracting the code parts from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e727e6b5-0cb7-49e0-971e-dfb1b2f32f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_code_blocks(body: str, _id: int) -> List:\n",
    "    # regex = r\"<pre><code>((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>)\"\n",
    "    # regex = r\"(<pre>|(<pre((.*?)|(\\n)*)*><code>))((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>|</pre>)\"\n",
    "    regex = r\"<pre(><code>|>|(((.*?)|(\\n)*)><code>)|((.*?)|(\\n)*)>)((.*?)|(\\n)*)*(<\\/code><\\/pre>|</pre></code>|</pre>)\"\n",
    "    matches = re.finditer(regex, body, re.MULTILINE | re.IGNORECASE)\n",
    "    result = []\n",
    "    \n",
    "    try:\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            code = match.group()\n",
    "            code = re.sub('<pre(><code>|>|(((.*?)|(\\n)*)><code>)|((.*?)|(\\n)*)>)', '', code)\n",
    "            code = code.replace(\"<pre><code>\", \"\")\n",
    "            code = code.replace(\"</pre></code>\", \"\")\n",
    "            code = code.replace(\"</code></pre>\", \"\")\n",
    "            result.append(code)\n",
    "    except:\n",
    "        print(\"\\n Error(1): \", _id)\n",
    "        print(body)\n",
    "        return None\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f87db6b2-b24a-45d5-a7d2-e234bc3f0f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Code'] = df_w_Tens_tags.apply(lambda row: extract_code_blocks(row.Body, row.Id), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27718c-2a1e-4523-b04e-15f6fe13f297",
   "metadata": {},
   "source": [
    "For testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25534f29-f886-4366-9c74-366cb41becd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_w_tags.iloc[7]['Body'])\n",
    "# print(type(extract_code_blocks(df_w_tags.iloc[7]['Body'])))\n",
    "# print(len(extract_code_blocks(df_w_tags.iloc[7]['Body'])))\n",
    "# print(extract_code_blocks(df_w_tags.iloc[7]['Body'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b1e27-61be-4359-9b1c-c80828413913",
   "metadata": {},
   "source": [
    "Reset the index of dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e700b0aa-2f79-43c5-90e8-f969379e8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags = df_w_Tens_tags.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbd611",
   "metadata": {},
   "source": [
    "#### Finding the number of questions that have a code or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "717748e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count__question_w_code  = 0\n",
    "count__question_wo_code = 0\n",
    "count__num_codes = 0\n",
    "\n",
    "def counting_w_or_wo_code(row_code: List) -> bool:\n",
    "    global count__question_w_code, count__question_wo_code, count__num_codes\n",
    "    \n",
    "    if row_code:\n",
    "        count__question_w_code = count__question_w_code + 1\n",
    "        count__num_codes += len(row_code)\n",
    "        return True\n",
    "    else:\n",
    "        count__question_wo_code = count__question_wo_code + 1\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a723e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Has_code'] = df_w_Tens_tags['Code'].apply(lambda row_code: counting_w_or_wo_code(row_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "469ae92a-5c3b-40c7-ae08-5d75a254f2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 39690 records in our DB, including 32368 posts that have code block in themselve and 7322 w/o any code block.\n",
      "We have 70621 number of code blocks including stacktrace, snippet code, error message.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {df_w_Tens_tags.shape[0]} records in our DB, including {count__question_w_code} posts that have code block in themselve and {count__question_wo_code} w/o any code block.\")\n",
    "print(f\"We have {count__num_codes} number of code blocks including stacktrace, snippet code, error message.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76009349",
   "metadata": {},
   "source": [
    "### Extracting the text parts from body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "426b615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_blocks(id: int, body: str) -> Optional[List]:\n",
    "    # It's bug\n",
    "    if id in [57269598, 61003684]: \n",
    "        body = body + \"</p>\"\n",
    "\n",
    "    regex = r\"(<p>((.*?)|(\\n)*)*<\\/p>)|(<ul>((.*?)|(\\n)*)*<\\/ul>)|(<ol>((.*?)|(\\n)*)*<\\/ol>)\"\n",
    "    matches = re.finditer(regex, body, re.MULTILINE | re.IGNORECASE)\n",
    "    result = []\n",
    "    \n",
    "    # if id in [18397]:\n",
    "    #     return result\n",
    "\n",
    "    try:\n",
    "        for matchNum, match in enumerate(matches, start=1):\n",
    "            text = match.group()\n",
    "            text = text.replace(\"<p>\", \"\")\n",
    "            text = text.replace(\"<strong>\", \"\")\n",
    "            text = text.replace(\"<br>\", \"\")\n",
    "            text = text.replace(\"<ol>\", \"\")\n",
    "            text = text.replace(\"<ul>\", \"\")\n",
    "            text = text.replace(\"<li>\", \"\")\n",
    "            text = text.replace(\"</p>\", \"\")\n",
    "            text = text.replace(\"</strong>\", \"\")\n",
    "            text = text.replace(\"</ol>\", \"\")\n",
    "            text = text.replace(\"</ul>\", \"\")\n",
    "            text = text.replace(\"</li>\", \"\")\n",
    "            result.append(text)\n",
    "        return result\n",
    "    except:\n",
    "        print(\"Error(1): \", id)\n",
    "        print(body)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96ff4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Text'] = df_w_Tens_tags.apply(lambda row: extract_text_blocks(row.Id, row.Body), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bb294",
   "metadata": {},
   "source": [
    "#### Finding the number of body words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18933061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_text_words(text_list: List) -> int:\n",
    "    word_count = 0\n",
    "    for text in text_list:\n",
    "        word_count += sum([i.strip(string.punctuation).isalpha() for i in text.split()])\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15bc8431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Q_text_words_num'] = df_w_Tens_tags[\"Text\"].apply(lambda text_list: find_q_text_words(text_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d4e61-0992-43cf-bfc4-83cebb7d1bbf",
   "metadata": {},
   "source": [
    "Save the dataframe as csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d8f131a-19f7-46b8-b8e3-399ba5537607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_w_Tens_tags.to_csv('./amin_result_v1.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5ff90-afcd-45a3-9d2d-a2b58de44dd9",
   "metadata": {},
   "source": [
    "### Find the Regular Expressions for Unix and Windows base Pathnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3406a54-9a09-4255-8287-d16fab93833d",
   "metadata": {},
   "source": [
    "#### 1) Absolute and Relative Pathnames in UNIX OS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c90be3-66df-4290-972f-940233a71e7c",
   "metadata": {},
   "source": [
    "Stack/trace example: https://stackoverflow.com/questions/37337728/tensorflow-internalerror-blas-sgemm-launch-failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9d6c0-8adb-4939-9f06-329b036eb875",
   "metadata": {},
   "source": [
    "Find the restrictions and limitations related to the Unix pathnames: https://www.cyberciti.biz/faq/linuxunix-rules-for-naming-file-and-directory-names/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32c563-d1db-4f0a-9820-62fd42a6591e",
   "metadata": {},
   "source": [
    "Online regular expression environment for testing: https://regex101.com/r/ZyEx5u/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9456a-4c9e-4a8f-bee5-86a5be847e82",
   "metadata": {},
   "source": [
    "> Regular Expression: \"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb6875-32a5-4f52-b33a-9cb522a49f72",
   "metadata": {},
   "source": [
    "#### 1) Pathnames in Windows OS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9c86a-e55e-4200-85ff-ed3033b4ee64",
   "metadata": {},
   "source": [
    "Stack/trace example: https://stackoverflow.com/questions/49434031/tensorflow-on-windows-cpu-version-importerror-no-module-named-pywrap-tensorf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd40a8-d970-435c-a06d-6a32130d3055",
   "metadata": {},
   "source": [
    "Find the restrictions and limitations related to the Windows pathnames: <br /> \n",
    "https://docs.microsoft.com/en-us/dotnet/standard/io/file-path-formats <br />\n",
    "https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5ffa1-d9f8-4e8c-b9a8-8f438af95a1a",
   "metadata": {},
   "source": [
    "Online regular expression environment for testing: https://regex101.com/r/L6xmCa/1 , https://regex101.com/r/wz1WqW/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1be13-b32c-4d50-9ea2-490eafe5b139",
   "metadata": {},
   "source": [
    "> Regular Expression: \"[a-zA-Z]:\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc401c12-44a2-402c-9e4a-1de67941e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pathnames_from_code_column(code_sec: List) -> Tuple[str, List]: \n",
    "    try:\n",
    "        result_post_file_names = []\n",
    "        OS_flag = None\n",
    "        \n",
    "        for code in code_sec:\n",
    "            regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "            regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "            pattern_unix  = re.compile(regex_unix)\n",
    "            pattern_windows  = re.compile(regex_windows)\n",
    "            if pattern_unix.search(code):\n",
    "                OS_flag = \"unix\"\n",
    "                break\n",
    "            elif pattern_windows.search(code):\n",
    "                OS_flag = \"windows\"\n",
    "                break\n",
    "        \n",
    "        if OS_flag == \"unix\":\n",
    "            for code in code_sec:\n",
    "                regex = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "                code = code.replace(\"\\\\n\", \"\\n\")\n",
    "                code = code.replace('&lt;', '<')\n",
    "                code = code.replace('&gt;', '>')\n",
    "                code = code.replace('&quot;', '\"')\n",
    "                matches = re.finditer(regex, code, re.MULTILINE)\n",
    "                file_names_for_each_code_part = []\n",
    "\n",
    "                for matchNum, match in enumerate(matches, start=1):\n",
    "                    file_names_for_each_code_part.append((match.groups()[1].strip(), match.groups()[4].strip()))\n",
    "#                     file_names_for_each_code_part.append(match.groups()[1].strip())\n",
    "                    # print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "                    # for groupNum in range(0, len(match.groups())):\n",
    "                        # groupNum = groupNum + 1\n",
    "                        # print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n",
    "#                 print(file_names_for_each_code_part)\n",
    "#                 file_names_for_each_code_part = list(set(file_names_for_each_code_part))            # Create a unique list\n",
    "#                 print(file_names_for_each_code_part)\n",
    "                \n",
    "                if file_names_for_each_code_part:                                                   # Ignore the empty list\n",
    "                    result_post_file_names.append(file_names_for_each_code_part)\n",
    "                    \n",
    "        elif OS_flag == \"windows\":\n",
    "            for code in code_sec:\n",
    "                regex = r\"(([a-zA-Z]:)|\\~)\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "                code = code.replace('&lt;', '<')\n",
    "                code = code.replace('&gt;', '>')\n",
    "                code = code.replace('&quot;', '\"')\n",
    "                matches = re.finditer(regex, code, re.MULTILINE)                            \n",
    "                file_names_for_each_code_part = []\n",
    "\n",
    "                for matchNum, match in enumerate(matches, start=1):\n",
    "                    file_names_for_each_code_part.append((match.groups()[3].strip(), match.groups()[6].strip()))\n",
    "#                     file_names_for_each_code_part.append(match.groups()[1].strip())\n",
    "                    # print (\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "                    # for groupNum in range(0, len(match.groups())):\n",
    "                        # groupNum = groupNum + 1\n",
    "                        # print (\"Group {groupNum} found at {start}-{end}: {group}\".format(groupNum = groupNum, start = match.start(groupNum), end = match.end(groupNum), group = match.group(groupNum)))\n",
    "#                 file_names_for_each_code_part = [s.strip() for s in file_names_for_each_code_part]  # Strip the list\n",
    "#                 file_names_for_each_code_part = list(set(file_names_for_each_code_part))            # create a unique list\n",
    "                if file_names_for_each_code_part:                                                     # Ignore the empty list\n",
    "                    result_post_file_names.append(file_names_for_each_code_part)\n",
    "            \n",
    "    except:\n",
    "        print(\"\\n Error(2): \\n\", code_sec)\n",
    "        return None, None\n",
    "\n",
    "    return OS_flag, result_post_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc583436-6446-47b3-8811-ee3b316c57cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unix',\n",
       " [[('estimator', 'train'),\n",
       "   ('estimator', '_train_model'),\n",
       "   ('estimator', '_train_model_default'),\n",
       "   ('estimator', '_call_model_fn'),\n",
       "   ('nn_ops', 'sparse_softmax_cross_entropy_with_logits')]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for Unix path\n",
    "# https://stackoverflow.com/questions/51839415/tensorflow-valueerror-rank-mismatch\n",
    "# df_w_Tens_tags.iloc[9][:]\n",
    "extract_pathnames_from_code_column(df_w_Tens_tags[\"Code\"][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8642e202-ad70-4f13-9440-57eeeb3fda8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example for Windows path\n",
    "# df_w_Tens_tags['Code'] = df_w_Tens_tags['Body'].apply(lambda row_body: extract_code_blocks(row_body))\n",
    "# print(df_w_Tens_tags[\"Code\"][9])\n",
    "# extract_pathnames_from_code_column(df_w_Tens_tags[\"Code\"][84])\n",
    "# extract_pathnames_from_code_column(df_w_Tens_tags[\"Code\"][606])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c61970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_Tens_tags[\"Body\"][606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dd38400-fb42-4dc7-8f9d-deb13a98c1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Bugy_py_files'] = df_w_Tens_tags['Code'].apply(lambda row_code_ex: extract_pathnames_from_code_column(row_code_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7d4de",
   "metadata": {},
   "source": [
    "Save the dataframe as csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45aa1a7c-db29-4ca2-9eda-379a44be2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_Tens_tags['Bugy_py_files'].to_csv('./amin_result_v2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7e0c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_has_trace_col(cal_tuple) -> bool:\n",
    "    if cal_tuple[0] == \"windows\" or cal_tuple[0] == \"unix\":\n",
    "        return True\n",
    "    elif cal_tuple[0] is None:\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Has_trace'] = df_w_Tens_tags['Bugy_py_files'].apply(lambda cell_tuple: create_has_trace_col(cell_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60aff5",
   "metadata": {},
   "source": [
    "#### Finding the number and type of LOC in the body of post:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33da7bf-c174-48ba-999c-766d91c33a7a",
   "metadata": {},
   "source": [
    "For example how many pairs did you find in a post and defining the OS of that stack trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c25a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_line_of_code(code_list: List) -> Tuple[int, int, int]:\n",
    "    line_count_trace_win   = 0\n",
    "    line_count_trace_unix  = 0\n",
    "    line_count_simple_code = 0\n",
    "    \n",
    "    for code in code_list:\n",
    "        regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        regex_windows = r\"(([a-zA-Z]:)|\\~)\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d*)\\W*in\\W+([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        # regex_unix    = r\"[^\\n\\&\\:\\|\\>\\<\\/\\ \\\"\\;\\&]*(\\/[^\\n\\&\\:\\|\\>\\<\\/]+)+\\/([^\\n\\&\\:\\|\\>\\<\\/]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d+)\\W*in\\W*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        # regex_windows = r\"[a-zA-Z]:\\\\?([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+\\\\)+([^\\<\\>\\:\\\"\\\\\\/\\/\\|\\?\\*\\n]+)(\\.pyc|\\.py)[^\\d\\n]+(\\d+)\\W*in\\W*([a-zA-Z_$][a-zA-Z_$0-9]*)\"\n",
    "        pattern_unix  = re.compile(regex_unix)\n",
    "        pattern_windows = re.compile(regex_windows)\n",
    "        if pattern_unix.search(code):\n",
    "            OS_flag = \"unix\"\n",
    "        elif pattern_windows.search(code):\n",
    "            OS_flag = \"windows\"\n",
    "        else:\n",
    "            OS_flag = \"nothing\"\n",
    "            \n",
    "        if OS_flag == \"unix\":\n",
    "            line_count_trace_unix += len(code.splitlines())\n",
    "        elif OS_flag == \"windows\":\n",
    "            line_count_trace_win += len(code.splitlines())\n",
    "        elif OS_flag == \"nothing\":\n",
    "            line_count_simple_code += len(code.splitlines()) \n",
    "        else:\n",
    "            print(\"Error!\")\n",
    "\n",
    "    return (line_count_trace_unix, line_count_trace_win, line_count_simple_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4054d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 0, 126)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finding_line_of_code(df_w_Tens_tags.loc[9, 'Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2f3958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Line_code_u_w_s'] = df_w_Tens_tags['Code'].apply(lambda code_list: finding_line_of_code(code_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3e57594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Line_code_uix'] = df_w_Tens_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a683106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_Tens_tags['Line_code_win'] = df_w_Tens_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99bf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has a code (Python code) inside the post\n",
    "df_w_Tens_tags['Line_code_simple_code'] = df_w_Tens_tags['Line_code_u_w_s'].apply(lambda loc_tuple: loc_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3534efd4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Code</th>\n",
       "      <th>Has_code</th>\n",
       "      <th>Text</th>\n",
       "      <th>Q_text_words_num</th>\n",
       "      <th>Bugy_py_files</th>\n",
       "      <th>Has_trace</th>\n",
       "      <th>Line_code_u_w_s</th>\n",
       "      <th>Line_code_uix</th>\n",
       "      <th>Line_code_win</th>\n",
       "      <th>Line_code_simple_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43574928</td>\n",
       "      <td>1</td>\n",
       "      <td>43575038.0</td>\n",
       "      <td>2017-04-23 18:30:08</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>How to use custom/non-default tf.Graph in Tens...</td>\n",
       "      <td>&lt;p&gt;I'm very new to &lt;code&gt;Tensorflow&lt;/code&gt; and...</td>\n",
       "      <td>&lt;python&gt;&lt;session&gt;&lt;graph&gt;&lt;parallel-processing&gt;&lt;...</td>\n",
       "      <td>[t = np.linspace(0,2*np.pi)\\nfig, ax = plt.sub...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I'm very new to &lt;code&gt;Tensorflow&lt;/code&gt; and I...</td>\n",
       "      <td>111</td>\n",
       "      <td>(None, [])</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0, 46)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52019226</td>\n",
       "      <td>1</td>\n",
       "      <td>52019631.0</td>\n",
       "      <td>2018-08-25 16:32:19</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Keras w/ Tensorflow intermediate layer extract...</td>\n",
       "      <td>&lt;p&gt;I am currently trying to leverage an interm...</td>\n",
       "      <td>&lt;python&gt;&lt;tensorflow&gt;&lt;keras&gt;&lt;deep-learning&gt;&lt;bat...</td>\n",
       "      <td>[model = load_model('model.h5')\\ninp = model.i...</td>\n",
       "      <td>True</td>\n",
       "      <td>[I am currently trying to leverage an intermed...</td>\n",
       "      <td>77</td>\n",
       "      <td>(None, [])</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0, 28)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  PostTypeId  AcceptedAnswerId         CreationDate  ViewCount  AnswerCount  CommentCount  Score                                              Title                                               Body                                               Tags                                               Code  Has_code                                               Text  Q_text_words_num Bugy_py_files  Has_trace Line_code_u_w_s  Line_code_uix  Line_code_win  Line_code_simple_code\n",
       "0  43574928           1        43575038.0  2017-04-23 18:30:08       1118            1             0      3  How to use custom/non-default tf.Graph in Tens...  <p>I'm very new to <code>Tensorflow</code> and...  <python><session><graph><parallel-processing><...  [t = np.linspace(0,2*np.pi)\\nfig, ax = plt.sub...      True  [I'm very new to <code>Tensorflow</code> and I...               111    (None, [])      False      (0, 0, 46)              0              0                     46\n",
       "1  52019226           1        52019631.0  2018-08-25 16:32:19        312            1             2      0  Keras w/ Tensorflow intermediate layer extract...  <p>I am currently trying to leverage an interm...  <python><tensorflow><keras><deep-learning><bat...  [model = load_model('model.h5')\\ninp = model.i...      True  [I am currently trying to leverage an intermed...                77    (None, [])      False      (0, 0, 28)              0              0                     28"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_Tens_tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fde1f5",
   "metadata": {},
   "source": [
    "#### Question Post's Length (body of the post): Defining the lists for plotting their comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd5dee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_num_words_w_tra  = []\n",
    "list_num_words_wo_tra = []\n",
    "\n",
    "for index1, row in df_w_Tens_tags.iterrows():\n",
    "    if row.Has_trace is True:\n",
    "        list_num_words_w_tra.append(row.Q_text_words_num)\n",
    "    elif row.Has_trace is False:\n",
    "        list_num_words_wo_tra.append(row.Q_text_words_num)\n",
    "    else:\n",
    "        print(\"Error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae0b5-da13-4ad7-b853-44783e21104b",
   "metadata": {},
   "source": [
    "#### OS Stack Traces: Defining the number of stack straces the belongs to the Unix or Windows OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd3530e5-831c-4db8-b250-089f05938c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found the 1681 of stackoverflow's posts that belong to the Windows OS.\n",
      "We found the 3755 of stackoverflow's posts that belong to the Unix OS.\n"
     ]
    }
   ],
   "source": [
    "counter_win  = 0\n",
    "counter_unix = 0\n",
    "# dim_win  = []\n",
    "# dim_unix = []\n",
    "\n",
    "for tp in df_w_Tens_tags[\"Bugy_py_files\"]:\n",
    "    if tp[0] == \"windows\":\n",
    "        counter_win += 1\n",
    "#         np_array = np.array(tuple[1], dtype=object)\n",
    "#         dim_win.append(np_array.shape)\n",
    "        \n",
    "    elif tp[0] == \"unix\":\n",
    "        counter_unix += 1\n",
    "#         np_array = np.array(tuple[1], dtype=object)\n",
    "#         dim_unix.append(np_array.shape)\n",
    "\n",
    "print(f\"We found the {counter_win} of stackoverflow's posts that belong to the Windows OS.\")\n",
    "print(f\"We found the {counter_unix} of stackoverflow's posts that belong to the Unix OS.\")\n",
    "# print(\"The dimensions of Windows labels is: \", set(dim_win))\n",
    "# print(\"The dimensions of Unix labels is: \", set(dim_unix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "862bb743-f63d-4f4f-9b62-e38bb4711f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "PostTypeId                 int64\n",
       "AcceptedAnswerId         float64\n",
       "CreationDate              object\n",
       "ViewCount                  int64\n",
       "AnswerCount                int64\n",
       "CommentCount               int64\n",
       "Score                      int64\n",
       "Title                     object\n",
       "Body                      object\n",
       "Tags                      object\n",
       "Code                      object\n",
       "Has_code                    bool\n",
       "Text                      object\n",
       "Q_text_words_num           int64\n",
       "Bugy_py_files             object\n",
       "Has_trace                   bool\n",
       "Line_code_u_w_s           object\n",
       "Line_code_uix              int64\n",
       "Line_code_win              int64\n",
       "Line_code_simple_code      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_Tens_tags.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4c57c-d11e-4e1d-ac85-9c155d748630",
   "metadata": {},
   "source": [
    "#### Define two lists for storing the information of the questions w or w/o stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a685f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_w_t  = 0\n",
    "count_wo_t = 0\n",
    "count_win  = 0\n",
    "count_unix = 0\n",
    "\n",
    "Question_with_trace_info = []\n",
    "Question_with_wo_trace_info = []\n",
    "\n",
    "def counting_w_or_wo_trace(row_id: int, \n",
    "                           row_cr: object, \n",
    "                           row_vc: int, \n",
    "                           row_ac: int, \n",
    "                           row_cc: int, \n",
    "                           row_sc: int, \n",
    "                           row_ac_an_id: float, \n",
    "                           row_t: object, \n",
    "                           has_code: bool) -> None:\n",
    "    \n",
    "    global count_w_t, count_wo_t, count_win, count_unix, Question_with_trace_info, Question_with_wo_trace_info\n",
    "\n",
    "    if has_code:\n",
    "        if row_t[0] is not None:\n",
    "            count_w_t = count_w_t + 1\n",
    "            Question_with_trace_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))\n",
    "            \n",
    "            if row_t[0] == 'unix':\n",
    "                count_unix = count_unix + 1\n",
    "            else:\n",
    "                count_win = count_win + 1\n",
    "        else:\n",
    "            count_wo_t = count_wo_t + 1\n",
    "            Question_with_wo_trace_info.append((row_id, row_cr, row_vc, row_ac, row_cc, row_sc, row_ac_an_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee29fdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = df_w_Tens_tags.apply(lambda row: counting_w_or_wo_trace(row.Id, \n",
    "                                                            row.CreationDate, \n",
    "                                                            row.ViewCount,\n",
    "                                                            row.AnswerCount,\n",
    "                                                            row.CommentCount,\n",
    "                                                            row.Score,\n",
    "                                                            row.AcceptedAnswerId,\n",
    "                                                            row.Bugy_py_files, \n",
    "                                                            row.Has_code), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f73aa-307c-4ca5-ad1f-9c80e0067c0f",
   "metadata": {},
   "source": [
    "#### Creating a string matrix of pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe9422-3706-4fc3-9135-8cbd87353226",
   "metadata": {
    "tags": []
   },
   "source": [
    "https://stackoverflow.com/questions/32037893/numpy-fix-array-with-rows-of-different-lengths-by-filling-the-empty-elements-wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3390d5ca-986e-4ddf-a48f-eb4e45ab46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_fillna(data: List) -> np.ndarray:\n",
    "    # Get lengths of each row of data\n",
    "    lens = np.array([len(i) for i in data])\n",
    "\n",
    "    # Mask of valid places in each row\n",
    "    mask = np.arange(lens.max()) < lens[:, None]\n",
    "\n",
    "    # Setup output array and put elements from data into masked positions\n",
    "    out = np.zeros(mask.shape, dtype='object')\n",
    "    out[mask] = np.concatenate(data)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "043411f3-4d8b-43b5-89e2-7a9b5d9e1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_2D_array_with_str = []\n",
    "\n",
    "# The below list store the post Id for each pattern (or row in _2D_array). \n",
    "# We have to mention that the index of _2D_array and _Id_array helps us to find the id pattern quickly.\n",
    "_Id_array = []\n",
    "\n",
    "for index1, row in df_w_Tens_tags.iterrows():\n",
    "    row_tuple = row.Bugy_py_files\n",
    "    row_id = row.Id\n",
    "    \n",
    "    # row: (some rows have multiple patterns)\n",
    "    # ('unix', [[('estimator', 'train'), ('estimator', '_train_model'), \n",
    "    #            ('estimator', '_train_model_default'), ('estimator', '_call_model_fn'), ('nn_ops', 'sparse_softmax_cross_entropy_with_logits')]])\n",
    "    \n",
    "    if row_tuple[0] is None: continue\n",
    "    \n",
    "    for element in row_tuple[1]:\n",
    "        _Id_array.append(row_id)\n",
    "        _2D_array_with_str.append(element)\n",
    "\n",
    "# _2D_array_pad = numpy_fillna(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "859d9ebd-f61a-4031-9d13-c424894396cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('estimator', 'train'),\n",
       " ('estimator', '_train_model'),\n",
       " ('estimator', '_train_model_default'),\n",
       " ('estimator', '_call_model_fn'),\n",
       " ('nn_ops', 'sparse_softmax_cross_entropy_with_logits')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2D_array_with_str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccb7b7f-c4a7-490f-aaf2-d1ffad28ebd9",
   "metadata": {},
   "source": [
    "#### Find the Id of a post based on its pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b61c1236-480b-49f7-b2e0-3999cebe59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = _2D_array_with_str[5940]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df93d4d6-50ee-464b-bba6-bc59d30009fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4fff9b0-4939-474b-9db2-03740e518292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(_Id_array), _Id_array[5941]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd127746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tmpDf = df_w_Tens_tags.drop_duplicates(\"Id\")[[\"Id\",\"Bugy_py_files\"]]\n",
    "# tmpDf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "011040c8-4e62-47f6-8b80-17452d5ab17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpDf.Bugy_py_files = tmpDf.Bugy_py_files.apply(lambda row : row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a246d875-46f5-4ed5-8919-e8d966d2c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpDf_not_empty = tmpDf[tmpDf.Bugy_py_files.map(lambda d: len(d)) > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76dc06c5-96a1-4ce2-a397-abc846c9833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpDf_not_empty[tmpDf_not_empty.Bugy_py_files.map(lambda d: d[0]==a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fbcc9bf-5289-4d28-95ea-4929db4305ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_w_Tens_tags[\"T\"].loc[df_w_Tens_tags['Id'] == 60535969]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fffa51f-6992-42c2-9cf0-fd1888ae4047",
   "metadata": {},
   "source": [
    "#### Creating a numerical matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ab766-8031-4eca-9cef-455c127c6283",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/python-pandas-factorize/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbea84-d201-4010-9759-c32f05b80aa9",
   "metadata": {},
   "source": [
    "##### Creating a dictionary based on pairs and assigning a unique number to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8257c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict pair : int\n",
    "\n",
    "dic = {} \n",
    "specific_val = 1\n",
    "for row in _2D_array_with_str:\n",
    "    for element in row:\n",
    "        if element not in dic:\n",
    "            dic[element] = specific_val\n",
    "            specific_val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82ffd8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique pairs is:  7350\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique pairs is: \", max(dic.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfa8c9-9b6c-4643-b0b7-6b39e7fe40e4",
   "metadata": {},
   "source": [
    "##### Converting strings on the _2D_array into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ff5062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_2D_array = _2D_array_with_str.copy()\n",
    "for i, row in enumerate(_2D_array):\n",
    "    for j in range(len(row)):\n",
    "        _2D_array[i][j] = dic[_2D_array[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec5559a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2D_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f97135b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqe_dic int : pair\n",
    "\n",
    "uniqe_dic = dict([(value, key) for key, value in dic.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a621bac-8178-438b-8464-73225fe218a7",
   "metadata": {},
   "source": [
    "By the below function we deleted duplicated rows in 2d_array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca3c46e1-7f42-4369-8ea3-6a25dbadc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_2d_array_dup(_2d_array: list) -> Tuple[int, list]:\n",
    "    \n",
    "    dup_count = 0\n",
    "    _2d_array_tmp = _2d_array.copy()\n",
    "    _2d_array_tmp_next = []\n",
    "    \n",
    "    idx = 0\n",
    "    while idx != len(_2d_array_tmp):\n",
    "        \n",
    "        for indx_previous in range(0, idx+1):\n",
    "            _2d_array_tmp_next.append(_2d_array_tmp[indx_previous])\n",
    "        \n",
    "        for indx_next in range(idx+1, len(_2d_array_tmp)):\n",
    "#             print(idx, indx_next)\n",
    "#             print(_2d_array_tmp)\n",
    "#             print(_2d_array_tmp_next)\n",
    "\n",
    "            if _2d_array_tmp[idx] == _2d_array_tmp[indx_next]:\n",
    "                dup_count += 1\n",
    "            else:\n",
    "                _2d_array_tmp_next.append(_2d_array_tmp[indx_next])\n",
    "#         print(_2d_array_tmp_next)\n",
    "#         print(len(_2d_array_tmp_next))\n",
    "#         break\n",
    "        _2d_array_tmp = _2d_array_tmp_next\n",
    "        _2d_array_tmp_next = []\n",
    "        idx+=1\n",
    "    \n",
    "    return dup_count, _2d_array_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd20b1db-3f52-4f69-ad94-f91eff4c5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplication_row, _2D_array_new = find_2d_array_dup(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "038074a7-a09a-4288-9368-db126c18d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"We decresed the number of patterns from {len(_2D_array)} to {len(_2D_array_new)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa324359",
   "metadata": {},
   "source": [
    "## Answering the second research question (RQ2): Finding Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31312935",
   "metadata": {},
   "source": [
    "## Contiguous Sequential Pattern Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4c26c",
   "metadata": {},
   "source": [
    "https://www.cc.gatech.edu/~hic/CS7616/pdf/lecture13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ff498",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Approach (1):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9bae7",
   "metadata": {},
   "source": [
    "The shortest yet efficient implementation of the famous frequent sequential pattern mining algorithm PrefixSpan, the famous frequent closed sequential pattern mining algorithm BIDE (in closed.py), and the frequent generator sequential pattern mining algorithm FEAT (in generator.py), as a unified and holistic algorithm framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96570036",
   "metadata": {},
   "source": [
    "https://github.com/chuanconggao/PrefixSpan-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5eaa5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35702190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prefixspan import PrefixSpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c509adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps = PrefixSpan(_2D_array_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df9fc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = ps.frequent(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b69e8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"/home-students/amghad/sample.txt\", \"w\")\n",
    "# str_list = repr(k)\n",
    "# file.write(str_list)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2979a",
   "metadata": {},
   "source": [
    "### Approach (2): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a8e0a",
   "metadata": {},
   "source": [
    "pymining is a small collection of data mining algorithms implemented in Python. I did not design any of the algorithms, but I use them in my own research so I thought other developers might be interested to use them as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94392e0f",
   "metadata": {},
   "source": [
    "https://github.com/bartdag/pymining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e8d57",
   "metadata": {},
   "source": [
    "### Approach (3): By this approach we simply check all possible status for each row (or pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec37188-5c46-407b-b193-55c54b2e1841",
   "metadata": {},
   "source": [
    "We want to create a dict based on the vectors on the numerical matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f60f00-0840-41a0-8398-8f863bc2bc68",
   "metadata": {},
   "source": [
    "By the below function, we tried to find and search the patterns for each vector based on the window_size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d8aae18-d1d3-4282-9bf7-f7fe45ca5d6b",
   "metadata": {},
   "source": [
    "Input Vector: [1, 2, 6, 3]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "822ce776-1a3b-476d-92e6-be663d91ff05",
   "metadata": {},
   "source": [
    "{0: [(2, [(1, 2), (2, 6), (6, 3)]),\n",
    "    (3, [(1, 2, 6), (2, 6, 3)]),\n",
    "    (4, [(1, 2, 6, 3)])]\n",
    " ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233612b-f3b4-4328-88ed-7843b13d0957",
   "metadata": {},
   "source": [
    "0: The index of vector <br>\n",
    "list: Contains tuples with different windows_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03fb9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dicc_new(dicc: dict, vec_id: int, list_: list) -> dict:\n",
    "    if vec_id not in dicc:\n",
    "        # key not exist\n",
    "        dicc[vec_id] = list_\n",
    "    else:\n",
    "        # key exist\n",
    "        for tuple_ in list_:\n",
    "            for item in dicc[vec_id]:\n",
    "                if item[0] == tuple_[0]:\n",
    "                    item[1].append(tuple_[1][0])\n",
    "                    break\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2a340-fad0-4464-a15b-01f01995d3b0",
   "metadata": {},
   "source": [
    "The \"low\" parameter can help us control the lower bound of the window_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c3380c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 10    # <~~~~~~~ define the lower bound threshold\n",
    "up = len(uniqe_dic)\n",
    "dicc = {}     \n",
    "\n",
    "# be careful about _2D_array types, Is it new or not?!\n",
    "for i_v, vector in enumerate(_2D_array):    \n",
    "    for index, element in enumerate(vector):\n",
    "        list_ = []\n",
    "        for wind_size in range(low, len(vector)+1-index):\n",
    "            list_.append((wind_size, [(*vector[index:index+wind_size], )]))\n",
    "        dicc = append_to_dicc_new(dicc, i_v, list_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f09aefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplication(dup_list: list) -> list:\n",
    "    final_list = []\n",
    "    for item in dup_list:\n",
    "        if item not in final_list:\n",
    "            final_list.append(item)\n",
    "        else:\n",
    "            indx = final_list.index(item)\n",
    "            counter = final_list[indx][0] + 1\n",
    "            pair = final_list[indx][1]\n",
    "            final_list.remove(item)\n",
    "            final_list.append((counter, pair))\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a41ac-d183-4807-a0d1-fa9328e359cf",
   "metadata": {},
   "source": [
    "dic_count is a dictionary that key is window_size, and value is a list that contains tuples. Each tuple shows a pair and the number of pair's iteration on the matrix."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4befab67-c057-41a7-84c5-aa6b89e363ef",
   "metadata": {},
   "source": [
    "{2: [(1, (5, 1)),\n",
    "  (1, (1, 6)),\n",
    "  (1, (1, 2)),\n",
    "  (1, (2, 6)),\n",
    "  (2, (6, 3)),\n",
    "  (1, (6, 1)),\n",
    "  (2, (1, 3)),\n",
    "  (3, (4, 5)),\n",
    "  (5, (3, 4)),\n",
    "  (2, (4, 3)),\n",
    "  (1, (3, 6)),\n",
    "  (1, (2, 3)),\n",
    "  (1, (3, 1)),\n",
    "  (2, (1, 4)),\n",
    "  (1, (4, 6))],\n",
    "  ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ef3ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_count = {}\n",
    "\n",
    "for vec_i, list_tuples in dicc.items():\n",
    "#     print(vec_i, list_tuples,\"\\n\")\n",
    "    for tuples_ in list_tuples:\n",
    "#         print(tuples_)\n",
    "        \n",
    "        if tuples_[0] not in dic_count:\n",
    "            lst_ = [(1, tuple_) for tuple_ in tuples_[1]] \n",
    "            \n",
    "            if len(lst_) != len(set(lst_)):\n",
    "                lst_ = remove_duplication(lst_)\n",
    "            \n",
    "            dic_count[tuples_[0]] = lst_  \n",
    "        else:\n",
    "            #(2, [(1, 3), (1, 4), (3, 4), (4, 5), (5, 1)]\n",
    "            #break\n",
    "            for tuple_ in tuples_[1]:\n",
    "                flag = 0 \n",
    "                for item in dic_count[tuples_[0]]:\n",
    "                    if item[1] == tuple_:\n",
    "                        counter = item[0] + 1\n",
    "                        dic_count[tuples_[0]].remove(item)\n",
    "                        dic_count[tuples_[0]].append((counter, item[1]))\n",
    "                        flag = 1\n",
    "                        break\n",
    "                # tuple is new\n",
    "                if flag == 0:\n",
    "                    dic_count[tuples_[0]].append((1, tuple_))\n",
    "#                 else: \n",
    "#                     print(\"Error100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "beee1f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "722f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dic = {}\n",
    "\n",
    "def get_top_patterns(dic_count, top):\n",
    "    \n",
    "    for win_size, list_tuples in dic_count.items():\n",
    "        \n",
    "        Set_ = {tuple_[0] for tuple_ in list_tuples}\n",
    "        top_list = heapq.nlargest(top, Set_)\n",
    "        \n",
    "        top_dic[win_size] = []\n",
    "        for item in list_tuples:\n",
    "            if item[0] in top_list:\n",
    "                top_dic[win_size].append(item)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee816038-8e18-4180-b2f2-7af6cd99fd07",
   "metadata": {},
   "source": [
    "The below function based on the dic_count dictionary trys to find x top patterns for each window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d07908ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_patterns(dic_count, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fa153b3-af93-4c74-907f-36fefcce2096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(77, (46, 137, 138, 139, 140, 70, 70, 46, 46, 137)),\n",
       " (77, (137, 138, 139, 140, 70, 70, 46, 46, 137, 138)),\n",
       " (77, (138, 139, 140, 70, 70, 46, 46, 137, 138, 139)),\n",
       " (78, (139, 140, 70, 70, 46, 46, 137, 138, 139, 140)),\n",
       " (77, (376, 377, 378, 379, 376, 380, 381, 382, 383, 384)),\n",
       " (78, (377, 378, 379, 376, 380, 381, 382, 383, 384, 385))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_dic[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7686e5-ef45-48fa-ac24-a10d5e69c1b4",
   "metadata": {},
   "source": [
    "The below code converts the numbers of pairs to the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7279c556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_dic = {}\n",
    "for wind_size, pairs_list in top_dic.items():\n",
    "    conv_dic[wind_size] = []\n",
    "    for pair in pairs_list:\n",
    "        t_tmp = ()\n",
    "        for pair_element in pair[1]:\n",
    "            i_to_str = uniqe_dic[pair_element]\n",
    "            if not i_to_str:\n",
    "                print(\"Error\")\n",
    "            t_tmp = t_tmp + (i_to_str,)\n",
    "        conv_dic[wind_size].append((pair[0], t_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2612f95-90c6-4e32-975d-9e9f0313e795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(77,\n",
       "  (('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'swig_import_helper'),\n",
       "   ('imp', 'load_module'),\n",
       "   ('imp', 'load_dynamic'),\n",
       "   ('__init__', 'module'),\n",
       "   ('__init__', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'module'))),\n",
       " (77,\n",
       "  (('pywrap_tensorflow_internal', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'swig_import_helper'),\n",
       "   ('imp', 'load_module'),\n",
       "   ('imp', 'load_dynamic'),\n",
       "   ('__init__', 'module'),\n",
       "   ('__init__', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'swig_import_helper'))),\n",
       " (77,\n",
       "  (('pywrap_tensorflow_internal', 'swig_import_helper'),\n",
       "   ('imp', 'load_module'),\n",
       "   ('imp', 'load_dynamic'),\n",
       "   ('__init__', 'module'),\n",
       "   ('__init__', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'swig_import_helper'),\n",
       "   ('imp', 'load_module'))),\n",
       " (78,\n",
       "  (('imp', 'load_module'),\n",
       "   ('imp', 'load_dynamic'),\n",
       "   ('__init__', 'module'),\n",
       "   ('__init__', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'module'),\n",
       "   ('pywrap_tensorflow_internal', 'swig_import_helper'),\n",
       "   ('imp', 'load_module'),\n",
       "   ('imp', 'load_dynamic'))),\n",
       " (77,\n",
       "  (('stack_context', 'null_wrapper'),\n",
       "   ('zmqstream', '_handle_events'),\n",
       "   ('zmqstream', '_handle_recv'),\n",
       "   ('zmqstream', '_run_callback'),\n",
       "   ('stack_context', 'null_wrapper'),\n",
       "   ('kernelbase', 'dispatcher'),\n",
       "   ('kernelbase', 'dispatch_shell'),\n",
       "   ('kernelbase', 'execute_request'),\n",
       "   ('ipkernel', 'do_execute'),\n",
       "   ('zmqshell', 'run_cell'))),\n",
       " (78,\n",
       "  (('zmqstream', '_handle_events'),\n",
       "   ('zmqstream', '_handle_recv'),\n",
       "   ('zmqstream', '_run_callback'),\n",
       "   ('stack_context', 'null_wrapper'),\n",
       "   ('kernelbase', 'dispatcher'),\n",
       "   ('kernelbase', 'dispatch_shell'),\n",
       "   ('kernelbase', 'execute_request'),\n",
       "   ('ipkernel', 'do_execute'),\n",
       "   ('zmqshell', 'run_cell'),\n",
       "   ('interactiveshell', 'run_cell')))]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_dic[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82a9a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.csv', 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in top_dic.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85825caa-0ea6-49f4-afb9-467ca6dcd2f8",
   "metadata": {},
   "source": [
    "dic_count is a dictionary that key is window_size, and value is a list that contains tuples. Each tuple shows a pair and the number of pair's iteration on the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f87b4-36e2-4376-8f3f-ba55164a1b72",
   "metadata": {},
   "source": [
    "For each window_size we count the number of patterns that we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65a66cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pattern_count = [len(value) for key, value in dic_count.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ffe1697",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x420 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pattern_window_size = dic_count.keys()\n",
    "y_pos = np.arange(len(pattern_window_size))\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 6), dpi=70)\n",
    "ax.barh(y_pos, pattern_count, align='center', alpha=0.5, log=True)\n",
    "\n",
    "# for i in ax.patches:\n",
    "#     plt.text(i.get_width()+0.2, i.get_y()+0.5,\n",
    "#              str(round((i.get_width()), 2)),\n",
    "#              fontsize = 10, fontweight ='bold',\n",
    "#              color ='grey')\n",
    "\n",
    "# Add Plot Title\n",
    "ax.set_title('Patterns\\' Count for each Window Size',loc ='center')\n",
    "# ax.set_yticks(y_pos, objects)\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Window Size')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8dc6b-c1d8-45fc-a851-184118ca1a3a",
   "metadata": {},
   "source": [
    "### Approach (4): CC-Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87d8aea6-501b-4a56-98ea-2cdad58ed6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_dicc_new(dicc, vec_id, list_):\n",
    "    if vec_id not in dicc:\n",
    "        # key not exist\n",
    "        dicc[vec_id] = list_\n",
    "    else:\n",
    "        # key exist\n",
    "        for tuple_ in list_:\n",
    "            for item in dicc[vec_id]:\n",
    "                if item[0] == tuple_[0]:\n",
    "                    item[1].append(tuple_[1][0])\n",
    "                    break\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9370071-2ec9-4fbb-8b33-8e66e38b8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching Pattern\n",
    "low = 10     # <~~~~~~~ define the lower bound threshold\n",
    "up = len(uniqe_dic)\n",
    "dicc = {}     \n",
    "\n",
    "for i_v, vector in enumerate(_2D_array):    \n",
    "    for index, element in enumerate(vector):\n",
    "        list_ = []\n",
    "        for wind_size in range(low, len(vector)+1-index):\n",
    "            list_.append((wind_size, [(*vector[index:index+wind_size], )]))\n",
    "        dicc = append_to_dicc_new(dicc, i_v, list_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a64a3b0e-ffa9-4999-96cf-5bdc766df1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting\n",
    "def remove_duplication(dup_list):\n",
    "    final_list = []\n",
    "    for item in dup_list:\n",
    "        if item not in final_list:\n",
    "            final_list.append(item)\n",
    "        else:\n",
    "            indx = final_list.index(item)\n",
    "            counter = final_list[indx][0] + 1\n",
    "            pair = final_list[indx][1]\n",
    "            final_list.remove(item)\n",
    "            final_list.append((counter, pair))\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca4b370c-9b01-4e16-a3a6-a7a58bc463e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_count = {}\n",
    "\n",
    "for vec_i, list_tuples in dicc.items():\n",
    "#     print(vec_i, list_tuples,\"\\n\")\n",
    "    for tuples_ in list_tuples:\n",
    "#         print(tuples_)\n",
    "        \n",
    "        if tuples_[0] not in dic_count:\n",
    "            lst_ = [(1, tuple_) for tuple_ in tuples_[1]] \n",
    "            \n",
    "            if len(lst_) != len(set(lst_)):\n",
    "                lst_ = remove_duplication(lst_)\n",
    "            \n",
    "            dic_count[tuples_[0]] = lst_  \n",
    "        else:\n",
    "            #(2, [(1, 3), (1, 4), (3, 4), (4, 5), (5, 1)]\n",
    "            #break\n",
    "            for tuple_ in tuples_[1]:\n",
    "                flag = 0 \n",
    "                for item in dic_count[tuples_[0]]:\n",
    "                    if item[1] == tuple_:\n",
    "                        counter = item[0] + 1\n",
    "                        dic_count[tuples_[0]].remove(item)\n",
    "                        dic_count[tuples_[0]].append((counter, item[1]))\n",
    "                        flag = 1\n",
    "                        break\n",
    "                # tuple is new\n",
    "                if flag == 0:\n",
    "                    dic_count[tuples_[0]].append((1, tuple_))\n",
    "#                 else: \n",
    "#                     print(\"Error100\")\n",
    "#     print(\"salam\", dic_count[2], \"\\n\\n\" )\n",
    "#     if vec_i == 1:\n",
    "#         break\n",
    "\n",
    "# _2d_array = [[1, 3, 4, 3, 4, 5, 1, 4],\n",
    "#              [1, 6, 3, 4, 5],\n",
    "#              [1, 2, 6, 3],\n",
    "#              [6, 1, 3, 4, 5],\n",
    "#              [3, 4, 3, 6],\n",
    "#              [2, 3, 1, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb0c9fd7-b3c5-4e61-84bd-bd84f14b392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subsequence(needle: list, haystack: list) -> bool:\n",
    "    # >>> is_subsequence([2, 3, 4], [1, 2, 3, 4, 5, 6])\n",
    "    return any(\n",
    "        haystack[i:i+len(needle)] == needle\n",
    "        for i in range(len(haystack) - len(needle) + 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "777e6228-2296-47e7-bc0a-aa9f658346a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen(dic_count: dict, threshold: int) -> list:\n",
    "    closed_list = []\n",
    "    for key, v_list in dic_count.items():\n",
    "        #print(key, v_list)\n",
    "        for item_tup in v_list:\n",
    "            tmp_flag = False\n",
    "            for key, v_list_search in dic_count.items():\n",
    "                for item_tup_search in v_list_search:\n",
    "                    #print(\"compare with: \", item_tup_search[1])\n",
    "                    if len(item_tup_search[1]) >= len(item_tup[1]) and is_subsequence(item_tup[1], item_tup_search[1]) and item_tup[1] != item_tup_search[1]:\n",
    "                        if item_tup[0] == item_tup_search[0]:\n",
    "                            tmp_flag = True\n",
    "            if not tmp_flag and item_tup[0] > threshold:\n",
    "\n",
    "                closed_list.append(item_tup)\n",
    "    return closed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfbd276c-0735-4163-910b-27bd57d50fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70d292da-2e31-4ae1-9590-255586e51611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen_v2(dic_count: dict) -> list:\n",
    "    closed_list = []\n",
    "    flag_first_step = True\n",
    "    for win_size in list(reversed(list(dic_count))):\n",
    "        # Just add the last or the biggest window_size to the list \n",
    "        if flag_first_step:\n",
    "            flag_first_step = False\n",
    "            for item in dic_count[win_size]:\n",
    "                closed_list.append(item)\n",
    "            continue\n",
    "        \n",
    "        # For other window sizes\n",
    "        for item_tup_new in dic_count[win_size]:\n",
    "            flag_visit = False\n",
    "            for item_tup_old in closed_list:\n",
    "                if item_tup_new[0] == item_tup_old[0] and is_subsequence(item_tup_new[1], item_tup_old[1]):\n",
    "                    flag_visit = True\n",
    "                    break\n",
    "            if not flag_visit:\n",
    "                closed_list.append(item_tup_new)\n",
    "\n",
    "    return len(closed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cbc205ce-b533-4d9e-81c6-623cc7d67941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CloConSeqGen_v3(dic_count: dict, threshold: int) -> list:\n",
    "    closed_list = []\n",
    "    flag_first_step = True\n",
    "    for win_size in list(reversed(list(dic_count))):\n",
    "        # Just add the last or the biggest window_size to the list \n",
    "        if flag_first_step:\n",
    "            for item in dic_count[win_size]:\n",
    "                if item[0] >= threshold:\n",
    "                    flag_first_step = False\n",
    "                    closed_list.append(item)\n",
    "            continue\n",
    "        \n",
    "        # For other window sizes\n",
    "        for item_tup_new in dic_count[win_size]:\n",
    "            flag_visit = False\n",
    "            for item_tup_old in closed_list:\n",
    "                if item_tup_new[0] == item_tup_old[0] and is_subsequence(item_tup_new[1], item_tup_old[1]):\n",
    "                    flag_visit = True\n",
    "                    break\n",
    "            if (not flag_visit) and (item_tup_new[0] >= threshold):\n",
    "                closed_list.append(item_tup_new)\n",
    "\n",
    "    return len(closed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "57c0af36-4426-4796-9124-a3fbffa9354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795\n",
      "1795\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(CloConSeqGen_v2(dic_count))\n",
    "print(CloConSeqGen_v3(dic_count, 1))\n",
    "print(CloConSeqGen_v3(dic_count, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69976aca-66ae-4651-b7cb-fe34429ec72a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Approach (5):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93385165-9c8d-4743-b74a-6040ac7930a6",
   "metadata": {},
   "source": [
    "In this method, we tried to find pattern based on the dic, so it is super time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a8e7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def append_to_dicc(dicc, indx_vec, pair_size, item):\n",
    "#     list_permut_tuples = dicc[indx_vec]\n",
    "#     flag = 0\n",
    "#     for tuple_per in list_permut_tuples:\n",
    "#         if tuple_per[0] == pair_size:\n",
    "#             flag = 1\n",
    "#             # check\n",
    "#             if item in set(tuple_per[1]):\n",
    "#                 print(\"Error1\")\n",
    "#             else:\n",
    "# #                 print(\"old\")\n",
    "#                 tuple_per[1].append(item)\n",
    "#             break\n",
    "#     if flag == 0:\n",
    "# #         arr = []\n",
    "# #         arr.append(item)\n",
    "# #         print(\"new\")\n",
    "#         dicc[indx_vec].append((pair_size, item))\n",
    "#     return dicc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4f30721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_extended_permut(uniqe_dic, list_tuples):\n",
    "#     list_ = []\n",
    "#     for element in list_tuples:\n",
    "#         for key in uniqe_dic:\n",
    "#             list_.append((*element, key))\n",
    "#     return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f6f303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_permut_from_dic(dicc, index_vec, pair_size):\n",
    "#     for tuple_item in dicc[index_vec]:\n",
    "#         if tuple_item[0] == pair_size:\n",
    "#             return tuple_item[1]\n",
    "#     return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6cc23194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low = 2\n",
    "# up = len(uniqe_dic)\n",
    "# dicc = {} \n",
    "\n",
    "# for m in range(low, up+1):\n",
    "    \n",
    "#     for i_v, vector in enumerate(_2D_array):\n",
    "# #         print(\"\\nvec \", vector)\n",
    "#         list_ = []\n",
    "#         flag = 0\n",
    "#         if m == low:\n",
    "#             permut_list = list(permutations(uniqe_dic.keys(), m))\n",
    "#         else:\n",
    "#             permut_pre = get_permut_from_dic(dicc, i_v, m-1)\n",
    "#             if not permut_pre:\n",
    "#                 # There is no pairs for the previous combination\n",
    "# #                 print(\"\\n\\nsalam\\n\\n\", m)\n",
    "#                 continue\n",
    "#             permut_list = get_extended_permut(uniqe_dic , permut_pre)\n",
    "        \n",
    "# #         print(\"Per list: \", permut_list)\n",
    "# #         print(\"Dicc curent: \", dicc)\n",
    "        \n",
    "#         for pair in permut_list:\n",
    "# #             print(pair)\n",
    "#             for idx, element_str in enumerate(vector):   \n",
    "#                 if element_str == pair[0]:\n",
    "#                     if (idx+len(pair)) <= len(vector): \n",
    "#                         for i_p in range(0, len(pair)):\n",
    "#                             if pair[i_p] != vector[idx+i_p]:\n",
    "#                                 flag = 1\n",
    "#                                 break\n",
    "#                         if flag == 0:\n",
    "#                             list_.append(pair)\n",
    "#                         flag = 0\n",
    "#         # insert to dic\n",
    "#         if m == low:\n",
    "#             dicc[i_v] = [(len(pair), list_)]\n",
    "#         else:\n",
    "#             # List not empty\n",
    "#             if list_:\n",
    "#                 #print(\"sa \", list_)\n",
    "#                 dicc = append_to_dicc(dicc, i_v, len(pair), list_)\n",
    "#             #print(dicc)\n",
    "\n",
    "# #         print(dicc)\n",
    "# #     if m == low+1:\n",
    "# #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "939d07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_2D_array_pad = numpy_fillna(_2D_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "947b7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_2D_array_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04890c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"The number of entire stack traces is {_2D_array_pad.shape[0]} and the maximum number of pairs in a stack trase is {_2D_array_pad.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bc342",
   "metadata": {},
   "source": [
    "## Answer time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448de367",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading Answer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b763dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pure_ans_data = working_directory_path + \"ansSample.csv\"\n",
    "# path_ans = Path(pure_ans_data)\n",
    "\n",
    "# if path_ans.suffix == \".csv\":\n",
    "#     df_ans = pd.read_csv(path_ans, encoding=encoding)\n",
    "# else:\n",
    "#     raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf259d-561a-4487-9908-da7e4da40191",
   "metadata": {},
   "source": [
    "## Create DF based on the questions contain stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31d5963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "522f93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_info\"] = Question_with_trace_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3f03ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51839415, '2018-08-14 10:35:10', 383, 1, 5, 0, nan)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Question_with_trace_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b3e2b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_id\"]          = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_status_w_stack[\"Q_create_time\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_status_w_stack[\"View_count\"]    = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_status_w_stack[\"Answer_count\"]  = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_status_w_stack[\"Comment_count\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_status_w_stack[\"Score\"]         = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_status_w_stack[\"Accepted_Answer_id\"] = df_status_w_stack['Q_info'].apply(lambda q_info: q_info[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "28deb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack = df_status_w_stack.drop(['Q_info'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba5793bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_create_time\"]      = pd.to_datetime(df_status_w_stack[\"Q_create_time\"])\n",
    "df_status_w_stack[\"First_acc_ans_time\"] = pd.to_datetime(df_status_w_stack[\"First_acc_ans_time\"])\n",
    "df_status_w_stack[\"First_ans_time\"]     = pd.to_datetime(df_status_w_stack[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd1bbb",
   "metadata": {},
   "source": [
    "#### Filling the Answers column: A list contains the id and time of answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b391f4-10d3-478f-9177-31720b7be11e",
   "metadata": {},
   "source": [
    "We have to prepare and find answers that has TF parrentID, so first we catch the questions and store as table in DB. Before this job we have to create a table with all answrs and apply inner join to those tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "aea577e1-c75c-4596-8382-750bf696f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack[\"Q_id\"].to_csv('./df_TF_w_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce455804-26e1-42f7-bf0e-654b7aea88f8",
   "metadata": {},
   "source": [
    "SELECT df_TF_w_stack.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_TF_w_stack\n",
    "INNER JOIN all_results\n",
    "ON df_TF_w_stack.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "510bf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"tf_w_stack_result_DB.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fd4de2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack['Answers'] = df_status_w_stack.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ba9770ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in df_status_w_stack.iterrows():\n",
    "    for index2, row_night in df_night.iterrows():\n",
    "            if row_night[\"ParentId\"] == row_status[\"Q_id\"]:\n",
    "                    row_status['Answers'].append((row_night[\"Id\"], row_night[\"CreationDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca861c44-b860-4875-b34c-e7672d130d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_w = pd.merge(df_status_w_stack, df_night, how='outer',left_on=['Q_id'], right_on=['ParentId']).reset_index(drop=True)\n",
    "# pd_tmp_w[\"Answer_tup\"] = pd_tmp_w.apply(lambda x: (x.Id, x.CreationDate), axis=1)\n",
    "# pd_tmp_new_w = pd_tmp_w.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"], dropna=False)[\"Answer_tup\"].agg(list).reset_index()\n",
    "# pd_tmp_new2_w = pd_tmp_new_w[pd_tmp_new_w.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack[\"Answers\"] = df_status_w_stack[\"Answers\"].apply(lambda answers_list: list(set(answers_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker_1(i, answers_list, answers_count):\n",
    "    global counter\n",
    "    if len(answers_list) != answers_count:\n",
    "        print(\"Error \", i, len(answers_list), answers_count)\n",
    "\n",
    "def checker_ans_and_ans_tup(row_indx: int, ans_count: int, ans_list: list) -> None:\n",
    "    if len(ans_list) != ans_count:\n",
    "        print(\"Error!: row:\", row_indx, \", \", ans_count, ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2f339",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_tmp_new2_w.apply(lambda row: checker_1(row.name, row.Answers, row.Answer_count), axis=1)\n",
    "# _ = pd_tmp_new2_w.apply(lambda row: checker_ans_and_ans_tup(row.name, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65557388-8a6d-45d4-adb5-c2087922d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2_w.insert(len(pd_tmp_new2_w.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8cf58a-4f04-4113-9231-8fd15569be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w = pd_tmp_new2_w.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a596f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3_w.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        # print(\"is empty\")\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3_w.at[index1,'First_ans_time'] = fr_time\n",
    "    pd_tmp_new3_w.at[index1,'First_acc_ans_time'] = acc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847107e7",
   "metadata": {},
   "source": [
    "Write df_status_w_stack to the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.to_csv('./status_df_w_stack_with_list_of_answers_col.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4253bbc",
   "metadata": {},
   "source": [
    "Read df_status_w_stack from the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f760c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack = pd.read_csv('./status_df_w_stack_with_list_of_answers_col.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a424d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack[\"Duration_ans\"] = df_status_w_stack.apply(lambda row: (row.First_ans_time-row.Q_create_time).days, axis=1)\n",
    "# df_status_w_stack[\"Duration_acc_ans\"] = df_status_w_stack.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).days, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_ans_time-row.Q_create_time).total_seconds()/3600, axis=1)\n",
    "pd_tmp_new3_w[\"Duration_acc_ans\"] = pd_tmp_new3_w.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).total_seconds()/3600, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_w_stack['Duration_ans'] = pd_tmp_new3_w['Duration_ans'].fillna(0)\n",
    "df_status_w_stack['Duration_acc_ans'] = pd_tmp_new3_w['Duration_acc_ans'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_w_stack.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d09fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_tmp_new3_w.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19800ec",
   "metadata": {},
   "source": [
    "## Create DF based on the questions do not have stack traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1af63a-072f-48b2-b976-8b06c14b3733",
   "metadata": {},
   "source": [
    "We have to prepare and find answers that has Pytorch parrentID, so first we catch the questions and store as table in DB. Before this job we have to create a table with all answrs and apply inner join to those tables:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "396dfd6e-4a1b-40fd-80ab-b73cdda684c4",
   "metadata": {},
   "source": [
    "SELECT df_tf_wo_stack.Q_id, all_results.Id, all_results.CreationDate, all_results.ParentId\n",
    "FROM df_tf_wo_stack\n",
    "INNER JOIN all_results\n",
    "ON df_tf_wo_stack.Q_id = all_results.ParentId;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fb38392c-b449-4cc7-bf6c-2061d31539fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack[\"Q_id\"].to_csv('./df_tf_wo_stack.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f26363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = working_directory_path + \"tf_wo_stack_result_DB.csv.csv\"\n",
    "path = Path(pure_data)\n",
    "\n",
    "if path.suffix == \".csv\":\n",
    "    df_night_wo = pd.read_csv(path, encoding=encoding)\n",
    "else:\n",
    "    raise ValueError(\"{data_file_path.suffix} extensions are not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c567d8-93cd-488a-9715-2c3b6a011077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2258f0-f3e4-4a6a-99a1-9413d666c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195bf92-32fc-45a2-8560-d3e654b35132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.drop_duplicates([\"Q_id\", \"Id\", \"ParentId\", \"CreationDate\"], ignore_index=False, inplace=True)\n",
    "df_night_wo = df_night_wo.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "927a0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack = pd.DataFrame(columns=['First_ans_time', 'First_acc_ans_time', 'Answers'])\n",
    "\n",
    "df_status_wo_stack[\"Q_info\"] = Question_with_wo_trace_info\n",
    "\n",
    "df_status_wo_stack[\"Q_id\"]          = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[0])\n",
    "df_status_wo_stack[\"Q_create_time\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[1])\n",
    "df_status_wo_stack[\"View_count\"]    = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[2])\n",
    "df_status_wo_stack[\"Answer_count\"]  = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[3])\n",
    "df_status_wo_stack[\"Comment_count\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[4])\n",
    "df_status_wo_stack[\"Score\"]         = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[5])\n",
    "df_status_wo_stack[\"Accepted_Answer_id\"] = df_status_wo_stack['Q_info'].apply(lambda q_info: q_info[6])\n",
    "\n",
    "df_status_wo_stack = df_status_wo_stack.drop(['Q_info'], axis='columns')\n",
    "\n",
    "df_status_wo_stack[\"Q_create_time\"] = pd.to_datetime(df_status_wo_stack[\"Q_create_time\"])\n",
    "df_status_wo_stack[\"First_acc_ans_time\"] = pd.to_datetime(df_status_wo_stack[\"First_acc_ans_time\"])\n",
    "df_status_wo_stack[\"First_ans_time\"]     = pd.to_datetime(df_status_wo_stack[\"First_ans_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe64a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02caaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack['Answers'] = df_status_wo_stack.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dca9f-f50d-4844-8636-0c9163cb68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night_wo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006ded-2978-4735-9e8d-1c6f818c5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca48d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # It is super time-consuming and never run!\n",
    "# for index1, row_status in df_status_wo_stack.iterrows():\n",
    "#     for index2, row_night in df_night_wo.iterrows():\n",
    "#         if row_night[\"ParentId\"] == row_status[\"Q_id\"]:\n",
    "#                 row_status['Answers'].append((row_night[\"Id\"], row_night[\"CreationDate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd65ef-8327-4d89-b46a-0b6c9e701df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp = pd.merge(df_status_wo_stack, df_night_wo, how='left',left_on=['Q_id'],right_on=['ParentId']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4bb1c-c844-4fb1-b291-4a243d589c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_tmp[\"Answer_tup\"] = pd_tmp.apply(lambda x: (x.Id, x.CreationDate), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399421d6-ecc5-41bf-872d-52d39610d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new = pd_tmp.groupby([\"First_ans_time\", \"First_acc_ans_time\", \"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"])[\"Answer_tup\"].agg(list).reset_index()\n",
    "pd_tmp_new = pd_tmp.groupby([\"Q_id_x\", \"Q_create_time\", \"View_count\", \"Comment_count\", \"Score\", \"Answer_count\", \"Accepted_Answer_id\"])[\"Answer_tup\"].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf8935-4cfb-4a8f-93ea-8a85965cf76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2 = pd_tmp_new[pd_tmp_new.Answer_count != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2daa7-d193-4d18-b974-b71b7d697cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker_ans_and_ans_tup(row_indx: int, ans_count: int, ans_list: list) -> None:\n",
    "    if len(ans_list) != ans_count:\n",
    "        print(\"Error!: \", row_indx, ans_count, ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2018458-7fd9-4ca3-9da1-5714b03e3e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We checked all Q_id_x are unique\n",
    "pd_tmp_new2.apply(lambda row: checker_ans_and_ans_tup(row.name, row.Answer_count, row.Answer_tup), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abeea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_status_wo_stack[\"Answers\"] = df_status_wo_stack[\"Answers\"].apply(lambda answers_list: list(set(answers_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdae5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_status_wo_stack.apply(lambda row: checker_1(row.name, row.Answers, row.Answer_count), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c2fbc-1102-4751-bb8f-8d7d484182fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status_wo_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f892ae5-e359-4a30-ae5e-255cc23ae8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb04af7-e1a0-459f-a6a9-220ec4df1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new2.insert(len(pd_tmp_new2.columns), 'First_ans_time', np.nan)\n",
    "pd_tmp_new2.insert(len(pd_tmp_new2.columns), 'First_acc_ans_time', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28955ecd-1434-4f76-bac1-6da683f872f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3 = pd_tmp_new2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index1, row_status in pd_tmp_new3.iterrows():   \n",
    "    flag = 0\n",
    "    fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "    acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "        \n",
    "    if not row_status[\"Answer_tup\"]:\n",
    "        # print(\"is empty\")\n",
    "        continue\n",
    "\n",
    "    for answer in row_status[\"Answer_tup\"]:\n",
    "        \n",
    "        anwer_time = pd.to_datetime(answer[1])\n",
    "        \n",
    "        if flag == 0:\n",
    "            fr_time = anwer_time\n",
    "            flag = 1\n",
    "        \n",
    "        if fr_time > anwer_time:\n",
    "            fr_time = anwer_time\n",
    "        \n",
    "        if row_status[\"Accepted_Answer_id\"] == answer[0]:\n",
    "            acc_time = anwer_time\n",
    "\n",
    "    pd_tmp_new3.at[index1,'First_ans_time'] = fr_time\n",
    "    pd_tmp_new3.at[index1,'First_acc_ans_time'] = acc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f34b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3[\"Duration_ans\"] = pd_tmp_new3.apply(lambda row: (row.First_ans_time-row.Q_create_time).days, axis=1)\n",
    "pd_tmp_new3[\"Duration_acc_ans\"] = pd_tmp_new3.apply(lambda row: (row.First_acc_ans_time-row.Q_create_time).days, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1467f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tmp_new3['Duration_ans'] = pd_tmp_new3['Duration_ans'].fillna(0)\n",
    "pd_tmp_new3['Duration_acc_ans'] = pd_tmp_new3['Duration_acc_ans'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tmp_new3.to_csv('./wo_otagh_toolani.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac7769",
   "metadata": {},
   "source": [
    "### Find the durarion of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085355a2-dd4a-4415-9d5d-2e2cb5ce2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to delete rows or posts that doesn't have answer, because their zero values affect the meadian value (or the box plot values):\n",
    "df_status_w_stack_filtered = df_status_w_stack[df_status_w_stack[\"Answer_count\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5d77b-b227-484c-ab06-c4f787606873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_status_w_stack_filtered[[\"Q_create_time\", \"First_ans_time\", \"Answer_count\", \"Duration_ans\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c912b0-89e2-4a49-8938-7b3e3da7b024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_status_w_stack_filtered[[\"Q_create_time\", \"First_ans_time\", \"Answer_count\", \"Duration_ans\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26bad1-7156-4b99-a52c-f95d4fb158db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example:\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Days'])\n",
    "df_1['Days'] = df_status_w_stack_filtered['Duration_ans']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Days'])\n",
    "df_2['Days'] = pd_tmp_new3['Duration_ans']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "resultComment = pd.concat([df_1, df_2])\n",
    "resultComment['Type'] = \"First Answer\"\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Days'])\n",
    "df_1['Days'] = df_status_w_stack_filtered['Duration_acc_ans']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Days'])\n",
    "df_2['Days'] = pd_tmp_new3['Duration_acc_ans']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "resultAnswer = pd.concat([df_1, df_2])\n",
    "resultAnswer['Type'] = \"First Accepted Answer\"\n",
    "# ###################################################################################\n",
    "\n",
    "result = pd.concat([resultComment, resultAnswer], ignore_index=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Days\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5,\n",
    "              )\n",
    "\n",
    "plt.ylim(-200,250)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('TensorFlow Questions')\n",
    "# fig.suptitle('TensorFlow Questions', prop={\"size\":10})\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a19bd-5cb2-474f-8b7c-820d69f248b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_status_w_stack['Duration_ans'].to_csv('./fig1_w_first_answer.csv', encoding='utf-8')\n",
    "pd_tmp_new3['Duration_ans'].to_csv('./fig1_wo_first_answer.csv', encoding='utf-8')\n",
    "df_status_w_stack['Duration_acc_ans'].to_csv('./fig1_w_first_acc_answer.csv', encoding='utf-8')\n",
    "pd_tmp_new3['Duration_acc_ans'].to_csv('./fig1_wo_first_acc_answer.csv', encoding='utf-8')\n",
    "result.to_csv('./fig1_result.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da7730-b0c5-4fd5-8b69-d5a0d22ca9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb65388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Questions (with stack traces)', 'Days'])\n",
    "df_1['Days'] = df_status_w_stack['Duration_ans']\n",
    "df_1['Questions (with stack traces)'] = df_1['Questions (with stack traces)'].apply(lambda x: \"First Answer\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions (with stack traces)', 'Days'])\n",
    "df_2['Days'] = df_status_w_stack['Duration_acc_ans']\n",
    "df_2['Questions (with stack traces)'] = df_2['Questions (with stack traces)'].apply(lambda x: \"First Accepted Answer\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=result[\"Questions (with stack traces)\"], y=result[\"Days\"], \n",
    "               # palette=\"Set2\",\n",
    "               # split=True,\n",
    "               # scale=\"width\", \n",
    "               # inner=\"stick\",\n",
    "              )\n",
    "\n",
    "plt.ylim(-250,500)\n",
    "\n",
    "fig.suptitle('Answers Duration (with stack traces)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b540d9-50f5-4867-be9a-e13e9bd585ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Questions (W/O stack traces)', 'Days'])\n",
    "df_1['Days'] = pd_tmp_new3['Duration_ans']\n",
    "df_1['Questions (W/O stack traces)'] = df_1['Questions (W/O stack traces)'].apply(lambda x: \"First Answer\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions (W/O stack traces)', 'Days'])\n",
    "df_2['Days'] = pd_tmp_new3['Duration_acc_ans']\n",
    "df_2['Questions (W/O stack traces)'] = df_2['Questions (W/O stack traces)'].apply(lambda x: \"First Accepted Answer\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=result[\"Questions (W/O stack traces)\"], y=result[\"Days\"])\n",
    "\n",
    "plt.ylim(-250,500)\n",
    "\n",
    "fig.suptitle('Answers Duration (W/O stack traces)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd473e",
   "metadata": {},
   "source": [
    "## Statistics Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "865c91d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Numbers with all ML tags:  163194\n"
     ]
    }
   ],
   "source": [
    "print(\"Question Numbers with all ML tags: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1ac51430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Numbers (with Tensorflow tags):  39690\n"
     ]
    }
   ],
   "source": [
    "print(\"Question Numbers (with Tensorflow tags): \", df_w_Tens_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "817104d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Numbers (without Tensorflow tags):  123504\n"
     ]
    }
   ],
   "source": [
    "print(\"Question Numbers (without Tensorflow tags): \", df.shape[0] - df_w_Tens_tags.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ada499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Question Numbers (with code):  32368\n",
      "Tensorflow Question Numbers (without code):  7322\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Question Numbers (with code): \", count__question_w_code)\n",
    "print(\"Tensorflow Question Numbers (without code): \", count__question_wo_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "356dcb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Question Numbers (with code) have stack trace:  5436\n",
      "Tensorflow Question Numbers (with code) that doesn't have stack trace:  26905\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Question Numbers (with code) have stack trace: \", count_w_t)\n",
    "print(\"Tensorflow Question Numbers (with code) that doesn't have stack trace: \",count_wo_t-27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1cebaf5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Question Numbers (with stack trace:) on Unix based systems:  3755\n",
      "Tensorflow Question Numbers (with stack trace:) on Windows based systems:  1681\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Question Numbers (with stack trace:) on Unix based systems: \", count_unix)\n",
    "print(\"Tensorflow Question Numbers (with stack trace:) on Windows based systems: \", count_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3777daa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of line codes in the body part (w/o stack trace) is 1232195.\n",
      "The total LOC amongst stack traces is 142270 (Unix-based reports).\n",
      "The total LOC amongst stack traces is 79637 (Windows-based reports).\n",
      "The total LOC amongst stack traces is 221907.\n"
     ]
    }
   ],
   "source": [
    "line_count_unix   = 0\n",
    "line_count_win    = 0\n",
    "line_count_simple = 0\n",
    "\n",
    "for tuple in df_w_Tens_tags[\"Line_code_u_w_s\"]:\n",
    "    line_count_unix   += tuple[0]\n",
    "    line_count_win    += tuple[1]\n",
    "    line_count_simple += tuple[2]\n",
    "        \n",
    "print(f\"The total number of line codes in the body part (w/o stack trace) is {line_count_simple}.\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_unix} (Unix-based reports).\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_win} (Windows-based reports).\")\n",
    "print(f\"The total LOC amongst stack traces is {line_count_unix+line_count_win}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "13260028-8d85-4f82-8d22-ca47a7e5b65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 7350 unique pairs in stack traces posts related to the Tensorflow frameworks.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We found {max(dic.values())} unique pairs in stack traces posts related to the Tensorflow frameworks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8389ab17-d750-4184-96ac-18b2eda3a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pst:  39,690 \n",
      "Pst_wc:  82 \n",
      "Pst_woc: 18 \n",
      "CB: 70,621 \n",
      "CB_ws: 17 \n",
      "CB_wos: 83 \n",
      "ST: 5,436 \n",
      "U: 70 \n",
      "W: 30\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(\"Pst: \", '{:,}'.format(df_w_Tens_tags.shape[0]), \"\\nPst_wc: \", math.ceil(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \"\\nPst_woc:\", 100-math.ceil(count__question_w_code*100/(count__question_w_code+count__question_wo_code)), \"\\nCB:\", '{:,}'.format(count__num_codes), \"\\nCB_ws:\", math.ceil(count_w_t*100/(count_w_t+count_wo_t)), \"\\nCB_wos:\", 100-(math.ceil(count_w_t*100/(count_w_t+count_wo_t))) , \"\\nST:\", '{:,}'.format(count_w_t), \"\\nU:\", math.ceil(count_unix*100/count_w_t), \"\\nW:\",100-math.ceil(count_unix*100/count_w_t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01a48e",
   "metadata": {},
   "source": [
    "## Graphical Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f3688",
   "metadata": {},
   "source": [
    "### LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cdecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_wo_trace = df_w_Tens_tags[\"Line_code_simple_code\"]\n",
    "code_w_trace_w = df_w_Tens_tags[\"Line_code_win\"]\n",
    "code_w_trace_u = df_w_Tens_tags[\"Line_code_uix\"]\n",
    "code_w_trace = df_w_Tens_tags[\"Line_code_win\"] + df_w_Tens_tags[\"Line_code_uix\"]\n",
    "\n",
    "df_1 = pd.DataFrame(columns=['Questions', 'LOC (in each question post)'])\n",
    "df_1['LOC (in each question post)'] = code_wo_trace\n",
    "df_1['Questions'] = df_1['Questions'].apply(lambda x: \"Code W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Questions', 'LOC (in each question post)'])\n",
    "df_2['LOC (in each question post)'] = code_w_trace\n",
    "df_2['Questions'] = df_2['Questions'].apply(lambda x: \"Code With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"LOC (in each question post)\", \n",
    "               data=result, \n",
    "               hue=\"Questions\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(-15, 100)\n",
    "# plt.xlim(-1, 1)\n",
    "\n",
    "fig.suptitle('Comparing the LOC between regular code and stack trace')\n",
    "\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":8})\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf06607",
   "metadata": {},
   "source": [
    "### Question Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92381996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Length', 'Words (in each question post)'])\n",
    "df_1['Words (in each question post)'] = list_num_words_wo_tra\n",
    "df_1['Question Length'] = df_1['Question Length'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Length', 'Words (in each question post)'])\n",
    "df_2['Words (in each question post)'] = list_num_words_w_tra\n",
    "df_2['Question Length'] = df_2['Question Length'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(4, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Words (in each question post)\", \n",
    "               data=result, \n",
    "               hue=\"Question Length\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(0, 300)\n",
    "# plt.xlim(-1, 1)\n",
    "\n",
    "fig.suptitle('Comparing the Question Length')\n",
    "\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":8})\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4fb36",
   "metadata": {},
   "source": [
    "### Plotting Score, View, Answer, Comment Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sturges_rule_number(n_obser: int) -> int:\n",
    "    '''\n",
    "    Sturges Rule is the most common method for determining the optimal number of bins.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    n_obser : int\n",
    "        The total number of observations in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    Use   for returning a value: Symbols that mean ceiling  i.e. round the answer up to\n",
    "    the nearest integer.\n",
    "    '''\n",
    "    # return round(1 + math.log2(n_obser))\n",
    "    return round(np.ceil(1 + (3.322 * np.log10(n_obser))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('View Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nView Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['View_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['View_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='purple', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(False)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('View Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nView Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['View_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['View_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='purple', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=15)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['View_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['View_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.7)\n",
    "\n",
    "plt.ylim(-2500,13000)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('View Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8319c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Answer Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nAnswer Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Answer_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Answer_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='g', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Answer Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nAnswer Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Answer_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Answer_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='g', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Answer_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Answer_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-.5,4.1)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Answer Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Comment Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nComment Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Comment_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Comment_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='b', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Comment Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nComment Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Comment_count']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Comment_count'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='b', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a20d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Comment_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Comment_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-1.1,10)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Comment Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d464c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Comment_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Comment_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "resultComment = pd.concat([df_1, df_2])\n",
    "resultComment['Type'] = \"Comment Count\"\n",
    "# ###################################################################################\n",
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Answer_count']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Answer_count']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "resultAnswer = pd.concat([df_1, df_2])\n",
    "resultAnswer['Type'] = \"Answer Count\"\n",
    "# ###################################################################################\n",
    "# df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_1['Frequency'] = df_status_wo_stack['View_count']\n",
    "# df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "# df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_2['Frequency'] = df_status_w_stack['View_count']\n",
    "# df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "# resultView = pd.concat([df_1, df_2])\n",
    "# resultView['Type'] = \"View Count\"\n",
    "# ###################################################################################\n",
    "# df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_1['Frequency'] = df_status_wo_stack['Score']\n",
    "# df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "# df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "# df_2['Frequency'] = df_status_w_stack['Score']\n",
    "# df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "# resultScore = pd.concat([df_1, df_2])\n",
    "# resultScore['Type'] = \"Score Count\"\n",
    "# ###################################################################################\n",
    "result = pd.concat([resultComment, resultAnswer], ignore_index=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-1,6)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('TensorFlow Questions')\n",
    "# fig.suptitle('TensorFlow Questions', prop={\"size\":10})\n",
    "# plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,15])\n",
    "\n",
    "plt.subplot(211)\n",
    "\n",
    "plt.title('Score Count (With Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nScore Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_w_stack['Score']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_w_stack['Score'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='orange', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.subplot(212)\n",
    "\n",
    "plt.title('Score Count (W/O Stack Traces)', fontsize=25)\n",
    "plt.xlabel('\\nScore Range', fontsize=20)\n",
    "plt.ylabel('Frequency', fontsize=20)\n",
    "\n",
    "n_bins = get_sturges_rule_number(len(df_status_wo_stack['Score']))\n",
    "\n",
    "n, bins, patches = plt.hist(df_status_wo_stack['Score'], \n",
    "                             bins=n_bins, \n",
    "                             log=True, \n",
    "                             align='right', \n",
    "                             color='orange', \n",
    "                             edgecolor='black')\n",
    "\n",
    "# define minor ticks and draw a grid with them\n",
    "minor_locator = AutoMinorLocator(2)\n",
    "plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# plt.grid(which='minor', color='white', lw = 0.5)\n",
    "# x ticks\n",
    "xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "dist = (xticks[1] - xticks[0])/2\n",
    "xticks = [e+dist for e in xticks]\n",
    "xticks_labels = [ \"{:.1f}\\nto\\n{:.1f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "plt.xticks(xticks, labels = xticks_labels, fontsize=18)\n",
    "\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_1['Frequency'] = df_status_wo_stack['Score']\n",
    "df_1['Question Type'] = df_1['Question Type'].apply(lambda x: \"W/O Stack Traces\")\n",
    "\n",
    "df_2 = pd.DataFrame(columns=['Question Type', 'Frequency'])\n",
    "df_2['Frequency'] = df_status_w_stack['Score']\n",
    "df_2['Question Type'] = df_2['Question Type'].apply(lambda x: \"With Stack Traces\")\n",
    "\n",
    "result = pd.concat([df_1, df_2])\n",
    "result['Type'] = \"Question Type\"\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "sns.violinplot(x=\"Type\", \n",
    "               y=\"Frequency\", \n",
    "               data=result, \n",
    "               hue=\"Question Type\", \n",
    "               palette=\"Set2\", #colorblind\n",
    "               split=True, \n",
    "               scale=\"count\",\n",
    "               inner=\"quartile\",\n",
    "               scale_hue=False,\n",
    "               width=.5)\n",
    "\n",
    "plt.ylim(-7,15)\n",
    "# plt.xlim(-1,1)\n",
    "\n",
    "fig.suptitle('Score Count')\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "# plt.plot(legend=None)\n",
    "plt.legend(loc='upper right', prop={\"size\":10})\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# facecolor = '#EAEAEA'\n",
    "# color_bars = '#3475D0'\n",
    "# txt_color1 = '#252525'\n",
    "# txt_color2 = '#004C74'\n",
    "# fig, ax = plt.subplots(1, figsize=(20,6), facecolor=facecolor)\n",
    "# ax.set_facecolor(facecolor)\n",
    "# n, bins, patches = plt.hist(df_status_w_stack['Score'], \n",
    "#                              bins=n_bins, color=color_bars, log=True)\n",
    "# #grid\n",
    "# minor_locator = AutoMinorLocator(2)\n",
    "# plt.gca().xaxis.set_minor_locator(minor_locator)\n",
    "# # plt.grid(which='minor', color=facecolor, lw = 0.5)\n",
    "# xticks = [(bins[idx+1] + value)/2 for idx, value in enumerate(bins[:-1])]\n",
    "# xticks_labels = [ \"{:.0f}-{:.0f}\".format(value, bins[idx+1]) for idx, value in enumerate(bins[:-1])]\n",
    "# plt.xticks(xticks, labels=xticks_labels, c=txt_color1, fontsize=13)\n",
    "\n",
    "# # remove major and minor ticks from the x axis, but keep the labels\n",
    "# ax.tick_params(axis='x', which='both',length=0)\n",
    "# # remove y ticks\n",
    "# plt.yticks([])\n",
    "\n",
    "# # Hide the right and top spines\n",
    "# ax.spines['bottom'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# for idx, value in enumerate(n):\n",
    "#     if value > 0:\n",
    "#         plt.text(xticks[idx], value+5, int(value), ha='center', fontsize=16, c=txt_color1)\n",
    "\n",
    "# plt.title('\\nTensorFlow - Score Count\\n', loc = 'center', fontsize = 20, c=txt_color1)\n",
    "# plt.xlabel('\\nScore Range', c=txt_color2, fontsize=14)\n",
    "# plt.ylabel('\\nFrequency', c=txt_color2, fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig('costs.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "\n",
    "# flag = 0\n",
    "# fr_time = pd.to_datetime(datetime.datetime.now())\n",
    "# acc_time = pd.to_datetime(datetime.datetime.now())\n",
    "\n",
    "# for answer in tt:\n",
    "#     anwer_time = pd.to_datetime(answer[1])\n",
    "#     if flag == 0:\n",
    "#         fr_time = anwer_time\n",
    "#         flag = 1\n",
    "    \n",
    "#     if fr_time > anwer_time:\n",
    "#         fr_time = anwer_time\n",
    "    \n",
    "#     if int(60535969) == answer[0]:\n",
    "#         acc_time = anwer_time\n",
    "\n",
    "# print(fr_time)\n",
    "# print(acc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# gs = fig.add_gridspec(1, 2)\n",
    "\n",
    "# min_ = min(min(df_status_w_stack['View_count']), min(df_status_wo_stack['View_count']))\n",
    "# max_ = max(max(df_status_w_stack['View_count']), max(df_status_wo_stack['View_count']))\n",
    "\n",
    "# ax1 = fig.add_subplot(gs[0, 0])\n",
    "# sns.violinplot(data=df_status_w_stack['View_count'])\n",
    "# ax1.set_xlabel(\"with Stack Traces\")\n",
    "# ax1.set_ylabel(\"Frequency\")\n",
    "# ax1 = plt.ylim(min_,max_)\n",
    "\n",
    "# ax2 = fig.add_subplot(gs[0, 1])\n",
    "# sns.violinplot(data=df_status_wo_stack['View_count'])\n",
    "# ax2.set_xlabel(\"w/o Stack Traces\")\n",
    "# ax2.set_ylabel(\"Frequency\")\n",
    "# ax2 = plt.ylim(min_,max_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
